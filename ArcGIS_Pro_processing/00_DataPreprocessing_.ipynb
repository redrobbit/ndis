{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd0J3LTrWg3R"
      },
      "source": [
        "# NDIS Database Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GIIQX9ZWg3V"
      },
      "source": [
        "## Geohazard & Infrastructure database compilation\n",
        "\n",
        "This notebook documents the preprocessing pipeline for the Natural Disaster Information System (NDIS), a decision-support tool for planning RPAS (Remotely Piloted Aircraft Systems) missions in geohazard monitoring.\n",
        "\n",
        "The preprocessing integrates six core datasets, each representing a distinct geohazard type:\n",
        "1. Volcano\n",
        "2. Landslide\n",
        "3. Tsunami\n",
        "4. Fault\n",
        "5. Earthquake\n",
        "6. Nuclear Power Plant\n",
        "\n",
        "To ensure consistency across hazard types, raw datasets were parsed and harmonized into a unified schema. This involved:\n",
        "- Converting spatial geometries to a common coordinate system\n",
        "- Standardizing key fields such as intensity, duration, and economic loss\n",
        "- Mapping hazard-specific attributes (e.g., magnitude, VEI) into shared analytical fields\n",
        "- Handling missing values using severity-based proxies or simulation logic\n",
        "\n",
        "Geospatial preprocessing steps include:\n",
        "- Buffering and clipping to Exclusive Economic Zone (EEZ) boundaries\n",
        "- Zonal statistics for population exposure within hazard zones\n",
        "- Distance-based feature engineering (e.g., proximity to roads or coastlines)\n",
        "\n",
        "All spatial analysis was performed in **ArcGIS Pro**, which also supported early-stage logic testing and scenario validation. The final decision logic, including RPAS and sensor recommendations, was implemented using a staggered rule-based workflow. Although machine learning models (e.g., decision trees) were evaluated, they were not used in the operational version due to limited generalizability.\n",
        "\n",
        "This notebook serves as a reproducible reference for harmonized data preparation and logic integration in the NDIS system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfsa3e7uWg3Y"
      },
      "outputs": [],
      "source": [
        "from arcgis.gis import GIS\n",
        "gis = GIS(\"home\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBbBjNR7Wg3a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "#ArcGIS packages\n",
        "import arcpy\n",
        "#from arcgis.mapping import WebScene\n",
        "from arcgis.gis import GIS\n",
        "from arcgis.features import FeatureLayer\n",
        "from IPython.display import display\n",
        "from arcgis.features import GeoAccessor\n",
        "from arcgis import *\n",
        "from arcpy.sa import Int\n",
        "# Raster processing for dataframe\n",
        "from rasterstats import zonal_stats\n",
        "import rasterio\n",
        "\n",
        "# basic packages\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import timeit\n",
        "import random\n",
        "import string\n",
        "from playsound import playsound\n",
        "import gc # Force Garbage Collection. This helps reduce memory leaks in long loops.\n",
        "import warnings\n",
        "\n",
        "# Data management\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point  # to get points from long lat\n",
        "\n",
        "# Request service\n",
        "#from requests import Request\n",
        "import json\n",
        "import re\n",
        "from functools import reduce\n",
        "#from owslib.wfs import WebFeatureService\n",
        "import sqlite3\n",
        "\n",
        "# Plotting packages\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK-mzvB3Wg3b"
      },
      "source": [
        "# Get Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPq0KNioWg3c"
      },
      "source": [
        "## <font color='red'> 1. Volcano data </font>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b>\n",
        "    Citation: Global Volcanism Program, 2013. Volcanoes of the World, v. 4.11.0 (08 Jul 2022). Venzke, E (ed.). Smithsonian Institution. Downloaded 13 Jul 2022. https://doi.org/10.5479/si.GVP.VOTW4-2013.\n",
        "\n",
        "Further info: https://volcano.si.edu/database/webservices.cfm\n",
        "\n",
        "Service Layer: http://webservices.volcano.si.edu/geoserver/GVP-VOTW/ows?service=WFS&version=1.0.0&request=describefeaturetype&typeName=GVP-VOTW:E3WebApp_HoloceneVolcanoes\n",
        "    \n",
        "    Significant Volcano Eruption:\n",
        "    Citation: National Geophysical Data Center / World Data Service (NGDC/WDS): Significant Earthquake Database. National Geophysical Data Center, NOAA. doi:10.7289/V5TD9V7K\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpI0-JiPWg3d"
      },
      "outputs": [],
      "source": [
        "# Set the path to this geodatabase\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"  # Update the path accordingly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNkLZhSkWg3e",
        "outputId": "12b45a39-8236-426c-c041-7fd5a3f08fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spatial Reference of volc84:\n",
            "  Name: GCS_WGS_1984\n",
            "  WKID: 4326\n",
            "  WKT: GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\n"
          ]
        }
      ],
      "source": [
        "# Set the path to this geodatabase\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"  # Update the path accordingly\n",
        "\n",
        "# Set the workspace to geodatabase\n",
        "arcpy.env.workspace = gdb_path\n",
        "\n",
        "# Specify the feature class name\n",
        "feature_class_name = \"volc84\"\n",
        "feature_class_path = f\"{gdb_path}\\\\{feature_class_name}\"\n",
        "\n",
        "# Describe the feature class\n",
        "desc = arcpy.Describe(feature_class_path)\n",
        "\n",
        "# Check the spatial reference\n",
        "spatial_reference = desc.spatialReference\n",
        "\n",
        "# Print the spatial reference details\n",
        "print(f\"Spatial Reference of {feature_class_name}:\")\n",
        "print(f\"  Name: {spatial_reference.name}\")\n",
        "print(f\"  WKID: {spatial_reference.factoryCode}\")\n",
        "print(f\"  WKT: {spatial_reference.exportToString()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFjSDMs-Wg3f",
        "outputId": "26f2b22b-923a-4df4-8c03-2f5b21f75c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1324 entries, 0 to 1323\n",
            "Data columns (total 20 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   OBJECTID          1324 non-null   int64  \n",
            " 1   Shape             1324 non-null   object \n",
            " 2   GmlID             1324 non-null   object \n",
            " 3   VolcanoNumber     1324 non-null   int64  \n",
            " 4   VolcanoName       1324 non-null   object \n",
            " 5   Country           1324 non-null   object \n",
            " 6   Remarks           1324 non-null   object \n",
            " 7   VolcanoType       1324 non-null   object \n",
            " 8   LastEruption      857 non-null    float64\n",
            " 9   Elevation         1324 non-null   int64  \n",
            " 10  TectonicSetting   1319 non-null   object \n",
            " 11  Within_5km        1291 non-null   float64\n",
            " 12  Within_10km       1291 non-null   float64\n",
            " 13  Within_30km       1291 non-null   float64\n",
            " 14  Within_100km      1291 non-null   float64\n",
            " 15  VPImageFileName   1252 non-null   object \n",
            " 16  VPImageCaption    1252 non-null   object \n",
            " 17  VPImageCredit     1252 non-null   object \n",
            " 18  LatitudeDecimal   1324 non-null   float64\n",
            " 19  LongitudeDecimal  1324 non-null   float64\n",
            "dtypes: float64(7), int64(3), object(10)\n",
            "memory usage: 207.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Use arcpy to create a list of fields\n",
        "fields = [f.name for f in arcpy.ListFields(f\"{gdb_path}\\\\{feature_class_name}\")]\n",
        "\n",
        "# Use arcpy to create a search cursor and load the data into a list of dictionaries\n",
        "data = []\n",
        "with arcpy.da.SearchCursor(f\"{gdb_path}\\\\{feature_class_name}\", fields) as cursor:\n",
        "    for row in cursor:\n",
        "        data.append(dict(zip(fields, row)))\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "volc = pd.DataFrame(data)\n",
        "volc.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9d-wVojWg3f"
      },
      "outputs": [],
      "source": [
        "# Assuming 'Shape' column contains tuples (x, y), get the geometry for volcano database\n",
        "volc['geometry'] = volc['Shape'].apply(lambda geom: Point(geom) if geom is not None else None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tRXcZUFWg3g"
      },
      "outputs": [],
      "source": [
        "# Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n",
        "#volc.set_crs(epsg=4326, inplace=True)\n",
        "#print(volc.crs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0mJ-dkSWg3g",
        "outputId": "2341c65d-8f68-4fd1-cc7e-1ee965f26033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 1324 entries, 0 to 1323\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype   \n",
            "---  ------            --------------  -----   \n",
            " 0   OBJECTID          1324 non-null   int64   \n",
            " 1   Shape             1324 non-null   object  \n",
            " 2   GmlID             1324 non-null   object  \n",
            " 3   VolcanoNumber     1324 non-null   int64   \n",
            " 4   VolcanoName       1324 non-null   object  \n",
            " 5   Country           1324 non-null   object  \n",
            " 6   Remarks           1324 non-null   object  \n",
            " 7   VolcanoType       1324 non-null   object  \n",
            " 8   LastEruption      857 non-null    float64 \n",
            " 9   Elevation         1324 non-null   int64   \n",
            " 10  TectonicSetting   1319 non-null   object  \n",
            " 11  Within_5km        1291 non-null   float64 \n",
            " 12  Within_10km       1291 non-null   float64 \n",
            " 13  Within_30km       1291 non-null   float64 \n",
            " 14  Within_100km      1291 non-null   float64 \n",
            " 15  VPImageFileName   1252 non-null   object  \n",
            " 16  VPImageCaption    1252 non-null   object  \n",
            " 17  VPImageCredit     1252 non-null   object  \n",
            " 18  LatitudeDecimal   1324 non-null   float64 \n",
            " 19  LongitudeDecimal  1324 non-null   float64 \n",
            " 20  geometry          1324 non-null   geometry\n",
            "dtypes: float64(7), geometry(1), int64(3), object(10)\n",
            "memory usage: 217.3+ KB\n"
          ]
        }
      ],
      "source": [
        "# Create a GeoDataFrame\n",
        "volc = gpd.GeoDataFrame(volc, geometry='geometry')\n",
        "volc.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc5QUYRaWg3g",
        "outputId": "06bf0105-266d-4adc-d97e-b8889963d35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 1324 entries, 0 to 1323\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   HazardID    1324 non-null   int64   \n",
            " 1   latitude    1324 non-null   float64 \n",
            " 2   longitude   1324 non-null   float64 \n",
            " 3   geometry    1324 non-null   geometry\n",
            " 4   HazardType  1324 non-null   int64   \n",
            "dtypes: float64(2), geometry(1), int64(2)\n",
            "memory usage: 51.8 KB\n"
          ]
        }
      ],
      "source": [
        "# Extract column needed for the basic NDIS database to compile with other geohazards dataset.\n",
        "# Volcano Number --> HazardID, longitude, latitude, HazardType (in numerical coded added after extraction). Volcano is 1.\n",
        "vo_df = volc[['VolcanoNumber','LatitudeDecimal','LongitudeDecimal','geometry']].copy()\n",
        "vo_df.rename(columns = {'VolcanoNumber':'HazardID','LatitudeDecimal':'latitude','LongitudeDecimal':'longitude'}, inplace = True)\n",
        "vo_df['HazardType'] = 1\n",
        "vo_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MqKTVOVWg3h"
      },
      "source": [
        "## <font color='red'> 2. Landslide Data </font>\n",
        "Retrieved from NASA\n",
        "\n",
        "Title: Global Landslide Catalog | Type: Feature Service | Owner: krolikie@unhcr.org_unhcr\n",
        "https://maps.nccs.nasa.gov/arcgis/apps/MapAndAppGallery/index.html?appid=574f26408683485799d02e857e5d9521\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b>\n",
        "    Citation: Kirschbaum, D.B., Stanley, T., & Zhou, Y. (2015). Spatial and temporal analysis of a global landslide catalog. Geomorphology, 249, 4-15. doi:10.1016/j.geomorph.2015.03.016\n",
        "\n",
        "    Kirschbaum, D.B., Adler, R., Hong, Y., Hill, S., & Lerner-Lam, A. (2010). A global landslide catalog for hazard applications: method, results, and limitations. Natural Hazards, 52, 561-575. doi:10.1007/s11069-009-9401-4\n",
        "\n",
        "Further info:\n",
        "https://gpm.nasa.gov/landslides/data.html\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fe12OzMWg3h",
        "outputId": "67a519d7-dd63-410a-872b-8f2510567115"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Geographic Coordinate System)\">name (Geographic Coordinate System)</td><td title=\"GCS_WGS_1984\">GCS_WGS_1984</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"4326\">4326</td></tr><tr><td id = \"td0\" title=\"angularUnitName (Angular Unit)\">angularUnitName (Angular Unit)</td><td title=\"Degree\">Degree</td></tr><tr><td id = \"td0\" title=\"datumName (Datum)\">datumName (Datum)</td><td title=\"D_WGS_1984\">D_WGS_1984</td></tr></table>"
            ],
            "text/plain": [
              "<geoprocessing spatial reference object at 0x261599c68b0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# After the file is downloaded, load the following from local path and check the GCS\n",
        "ls_spatial_ref = arcpy.Describe(r\"D:/NDIS_Database/04_Landslide/nasa_coolr_reports_point.shp\").spatialReference\n",
        "ls_spatial_ref"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYEZVhdaWg3h",
        "outputId": "564f7f7f-dd92-4ecf-a171-a0171c31eed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 14723 entries, 0 to 14722\n",
            "Data columns (total 30 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   src_name    14718 non-null  object  \n",
            " 1   src_link    13879 non-null  object  \n",
            " 2   ev_date     13087 non-null  object  \n",
            " 3   ev_time     6555 non-null   object  \n",
            " 4   ev_title    14026 non-null  object  \n",
            " 5   ev_desc     12176 non-null  object  \n",
            " 6   loc_desc    13195 non-null  object  \n",
            " 7   loc_acc     14693 non-null  object  \n",
            " 8   ls_cat      14720 non-null  object  \n",
            " 9   ls_trig     14720 non-null  object  \n",
            " 10  ls_size     14719 non-null  object  \n",
            " 11  ls_setting  14713 non-null  object  \n",
            " 12  fatalities  14723 non-null  int64   \n",
            " 13  injuries    14723 non-null  int64   \n",
            " 14  storm_name  666 non-null    object  \n",
            " 15  photo_link  2228 non-null   object  \n",
            " 16  comments    2560 non-null   object  \n",
            " 17  ev_imp_src  14723 non-null  object  \n",
            " 18  ev_imp_id   11689 non-null  object  \n",
            " 19  latitude    14723 non-null  float64 \n",
            " 20  longitude   14723 non-null  float64 \n",
            " 21  ctry_name   14645 non-null  object  \n",
            " 22  ctry_code   14645 non-null  object  \n",
            " 23  div_name    14641 non-null  object  \n",
            " 24  gaz_point   14697 non-null  object  \n",
            " 25  gaz_dist    14723 non-null  float64 \n",
            " 26  sub_date    13591 non-null  object  \n",
            " 27  edit_date   22 non-null     object  \n",
            " 28  ev_id       14723 non-null  int64   \n",
            " 29  geometry    14723 non-null  geometry\n",
            "dtypes: float64(3), geometry(1), int64(3), object(23)\n",
            "memory usage: 3.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Read the shapefile from local disk\n",
        "landslide_df = gpd.read_file(r\"D:/NDIS_Database/04_Landslide/nasa_coolr_reports_point.shp\")\n",
        "landslide_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMeolhaCWg3i",
        "outputId": "c5e90252-4871-44b6-8636-00143ea03199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 14723 entries, 0 to 14722\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   HazardID    14723 non-null  int64   \n",
            " 1   latitude    14723 non-null  float64 \n",
            " 2   longitude   14723 non-null  float64 \n",
            " 3   geometry    14723 non-null  geometry\n",
            " 4   HazardType  14723 non-null  int64   \n",
            "dtypes: float64(2), geometry(1), int64(2)\n",
            "memory usage: 575.2 KB\n"
          ]
        }
      ],
      "source": [
        "# Extract column needed for the basic NDIS database to compile with other geohazards dataset.\n",
        "# Volcano Number --> HazardID, longitude, latitude, HazardType (in numerical coded added after extraction). Volcano is 1.\n",
        "ls_df = landslide_df[['ev_id','latitude','longitude', 'geometry']].copy()\n",
        "ls_df.rename(columns = {'ev_id':'HazardID'}, inplace = True)\n",
        "ls_df['HazardType'] = 2\n",
        "ls_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7KP-TG-Wg3i",
        "outputId": "8bd7b87b-500b-4ab1-946a-84aba6043be4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Geographic 2D CRS: EPSG:4326>\n",
              "Name: WGS 84\n",
              "Axis Info [ellipsoidal]:\n",
              "- Lat[north]: Geodetic latitude (degree)\n",
              "- Lon[east]: Geodetic longitude (degree)\n",
              "Area of Use:\n",
              "- name: World.\n",
              "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
              "Datum: World Geodetic System 1984 ensemble\n",
              "- Ellipsoid: WGS 84\n",
              "- Prime Meridian: Greenwich"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ls_df.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR0tnrbmWg3j"
      },
      "source": [
        "## <font color='red'> 3. Tsunami Data </font>\n",
        "\n",
        "Data retrieved from NCEI NOAA - Global Historical Tsunami Database\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b>\n",
        "    A feature layer displaying historical tsunami events from NCEI's Global Historical Tsunami Database. The Global Historical Tsunami Database consists of two related files containing information on tsunami events from 2000 B.C. to the present in the Atlantic, Indian, and Pacific Oceans; and the Mediterranean and Caribbean Seas.\n",
        "    \n",
        "    Citation: National Geophysical Data Center / World Data Service: NCEI/WDS Global Historical Tsunami Database. NOAA National Centers for Environmental Information. doi:10.7289/V5PN93H7 [4 August 2023]\n",
        "\n",
        "Further info: https://ngdc.noaa.gov/hazard/hazards.shtml\n",
        "\n",
        "Documentation: https://data.noaa.gov/metaview/page?xml=NOAA/NESDIS/NGDC/MGG/Hazards/iso/xml/G02151.xml&view=getDataView\n",
        "\n",
        "Layer info: https://www.arcgis.com/home/item.html?id=5a44c3d4d465498993120b70ab568876\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg4a9TznWg3j",
        "outputId": "51cef5fd-6bf9-4fcb-a3c4-8731505af50e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spatial Reference of tsunami:\n",
            "  Name: WGS_1984_Web_Mercator_Auxiliary_Sphere\n",
            "  WKID: 3857\n",
            "  WKT:  PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Mercator_Auxiliary_Sphere\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],PARAMETER[\"Standard_Parallel_1\",0.0],PARAMETER[\"Auxiliary_Sphere_Type\",0.0],UNIT[\"Meter\",1.0]];-20037700 -30241100 10000;-100000 10000;-100000 10000;0.001;0.001;0.001;IsHighPrecision\n"
          ]
        }
      ],
      "source": [
        "# Specify the feature class name\n",
        "feature_class_tsunami = \"tsunami\"  # Check for content pane\n",
        "tsunami_path = f\"{gdb_path}\\\\{feature_class_tsunami}\"\n",
        "\n",
        "# Describe the feature class\n",
        "desc_tsun = arcpy.Describe(tsunami_path)\n",
        "\n",
        "# Check the spatial reference\n",
        "tsunami_sr = desc_tsun.spatialReference\n",
        "\n",
        "# Print the spatial reference details\n",
        "print(f\"Spatial Reference of {feature_class_tsunami}:\")\n",
        "print(f\"  Name: {tsunami_sr.name}\")\n",
        "print(f\"  WKID: {tsunami_sr.factoryCode}\")\n",
        "print(f\"  WKT:  {tsunami_sr.exportToString()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9jCxo7KWg3k",
        "outputId": "651c6e4b-9a88-4617-8c9a-c41713ccbfe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2534 entries, 0 to 2533\n",
            "Data columns (total 76 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   OBJECTID                       2534 non-null   int64  \n",
            " 1   Shape                          2534 non-null   object \n",
            " 2   DEATHS                         252 non-null    float64\n",
            " 3   DEATHS_DESCRIPTION             346 non-null    object \n",
            " 4   CAUSE                          2532 non-null   object \n",
            " 5   EVENT_VALIDITY                 2534 non-null   object \n",
            " 6   COUNTRY                        2534 non-null   object \n",
            " 7   MAX_EVENT_RUNUP                1269 non-null   float64\n",
            " 8   NUM_RUNUP                      2534 non-null   int64  \n",
            " 9   YEAR                           2534 non-null   int64  \n",
            " 10  MONTH                          2422 non-null   float64\n",
            " 11  DAY                            2339 non-null   float64\n",
            " 12  HOUR                           1492 non-null   float64\n",
            " 13  MINUTE                         1416 non-null   float64\n",
            " 14  SECOND                         1017 non-null   float64\n",
            " 15  DATE_STRING                    2534 non-null   object \n",
            " 16  EVENT_DATE                     2505 non-null   object \n",
            " 17  LATITUDE                       2534 non-null   float64\n",
            " 18  LONGITUDE                      2534 non-null   float64\n",
            " 19  LOCATION_NAME                  2533 non-null   object \n",
            " 20  AREA                           233 non-null    object \n",
            " 21  REGION_CODE                    2533 non-null   float64\n",
            " 22  REGION                         2533 non-null   object \n",
            " 23  CAUSE_CODE                     2532 non-null   float64\n",
            " 24  EVENT_VALIDITY_CODE            2534 non-null   int64  \n",
            " 25  EQ_MAG_UNK                     76 non-null     float64\n",
            " 26  EQ_MAG_MB                      422 non-null    float64\n",
            " 27  EQ_MAG_MS                      1371 non-null   float64\n",
            " 28  EQ_MAG_MW                      631 non-null    float64\n",
            " 29  EQ_MAG_ML                      40 non-null     float64\n",
            " 30  EQ_MAG_MFA                     9 non-null      float64\n",
            " 31  EQ_MAGNITUDE                   1643 non-null   float64\n",
            " 32  EQ_MAGNITUDE_RANK              1643 non-null   float64\n",
            " 33  EQ_DEPTH                       1042 non-null   float64\n",
            " 34  TS_MT_ABE                      1 non-null      float64\n",
            " 35  TS_MT_II                       709 non-null    float64\n",
            " 36  TS_INTENSITY                   1147 non-null   float64\n",
            " 37  DAMAGE_MILLIONS_DOLLARS        47 non-null     float64\n",
            " 38  DAMAGE_AMOUNT_ORDER            637 non-null    float64\n",
            " 39  DAMAGE_DESCRIPTION             637 non-null    object \n",
            " 40  HOUSES_DESTROYED               99 non-null     float64\n",
            " 41  HOUSES_AMOUNT_ORDER            279 non-null    float64\n",
            " 42  HOUSES_DESCRIPTION             279 non-null    object \n",
            " 43  DEATHS_AMOUNT_ORDER            2534 non-null   float64\n",
            " 44  INJURIES                       71 non-null     float64\n",
            " 45  INJURIES_AMOUNT_ORDER          83 non-null     float64\n",
            " 46  INJURIES_DESCRIPTION           83 non-null     object \n",
            " 47  MISSING                        7 non-null      float64\n",
            " 48  MISSING_AMOUNT_ORDER           8 non-null      float64\n",
            " 49  MISSING_DESCRIPTION            8 non-null      object \n",
            " 50  DAMAGE_MILLIONS_DOLLARS_TOTAL  161 non-null    float64\n",
            " 51  DAMAGE_AMOUNT_ORDER_TOTAL      1276 non-null   float64\n",
            " 52  DAMAGE_TOTAL_DESCRIPTION       1276 non-null   object \n",
            " 53  HOUSES_DESTROYED_TOTAL         259 non-null    float64\n",
            " 54  HOUSES_AMOUNT_ORDER_TOTAL      704 non-null    float64\n",
            " 55  HOUSES_TOTAL_DESCRIPTION       704 non-null    object \n",
            " 56  DEATHS_TOTAL                   645 non-null    float64\n",
            " 57  DEATHS_AMOUNT_ORDER_TOTAL      795 non-null    float64\n",
            " 58  DEATHS_TOTAL_DESCRIPTION       795 non-null    object \n",
            " 59  INJURIES_TOTAL                 311 non-null    float64\n",
            " 60  INJURIES_AMOUNT_ORDER_TOTAL    367 non-null    float64\n",
            " 61  INJURIES_TOTAL_DESCRIPTION     367 non-null    object \n",
            " 62  MISSING_TOTAL                  15 non-null     float64\n",
            " 63  MISSING_AMOUNT_ORDER_TOTAL     18 non-null     float64\n",
            " 64  MISSING_TOTAL_DESCRIPTION      18 non-null     object \n",
            " 65  HOUSES_DAMAGED                 16 non-null     float64\n",
            " 66  HOUSES_DAMAGED_AMOUNT_ORDER    63 non-null     float64\n",
            " 67  HOUSES_DAM_DESCRIPTION         63 non-null     object \n",
            " 68  HOUSES_DAMAGED_TOTAL           103 non-null    float64\n",
            " 69  HOUSES_DAM_AMOUNT_ORDER_TOTAL  277 non-null    float64\n",
            " 70  HOUSES_DAM_TOTAL_DESCRIPTION   277 non-null    object \n",
            " 71  CAUSE_SYMBOL                   2534 non-null   float64\n",
            " 72  URL                            2534 non-null   object \n",
            " 73  COMMENTS                       2372 non-null   object \n",
            " 74  ID                             2534 non-null   int64  \n",
            " 75  MAP_SYMBOL                     2534 non-null   int64  \n",
            "dtypes: float64(47), int64(6), object(23)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ],
      "source": [
        "# Use arcpy to create a list of fields\n",
        "ts_fields = [f.name for f in arcpy.ListFields(f\"{gdb_path}\\\\{feature_class_tsunami}\")]\n",
        "\n",
        "# Use arcpy to create a search cursor and load the data into a list of dictionaries\n",
        "ts_data = []\n",
        "with arcpy.da.SearchCursor(f\"{gdb_path}\\\\{feature_class_tsunami}\", ts_fields) as cursor:\n",
        "    for row in cursor:\n",
        "        ts_data.append(dict(zip(ts_fields, row)))\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "tsun = pd.DataFrame(ts_data)\n",
        "tsun.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEaaaDusWg3l",
        "outputId": "387239c2-dd39-4d1f-f141-c1ee4af36d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2534 entries, 0 to 2533\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   HazardID    2534 non-null   int64  \n",
            " 1   longitude   2534 non-null   float64\n",
            " 2   latitude    2534 non-null   float64\n",
            " 3   HazardType  2534 non-null   int64  \n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 79.3 KB\n"
          ]
        }
      ],
      "source": [
        "ts_df = tsun[['ID','LONGITUDE', 'LATITUDE']].copy()\n",
        "ts_df.rename(columns = {'ID':'HazardID','LONGITUDE':'longitude', 'LATITUDE':'latitude'}, inplace=True)\n",
        "ts_df['HazardType'] = 3\n",
        "ts_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xggilEQTWg3l",
        "outputId": "2109786c-82b1-4cd2-96b9-7aa515358bec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Geographic 2D CRS: EPSG:4326>\n",
              "Name: WGS 84\n",
              "Axis Info [ellipsoidal]:\n",
              "- Lat[north]: Geodetic latitude (degree)\n",
              "- Lon[east]: Geodetic longitude (degree)\n",
              "Area of Use:\n",
              "- name: World.\n",
              "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
              "Datum: World Geodetic System 1984 ensemble\n",
              "- Ellipsoid: WGS 84\n",
              "- Prime Meridian: Greenwich"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate points geometry from longitude and latitude\n",
        "ts_df['geometry'] = ts_df.apply(lambda x: Point(x['longitude'], x['latitude']), axis=1)\n",
        "\n",
        "# Create a GeoDataFrame\n",
        "ts_df = gpd.GeoDataFrame(ts_df, geometry='geometry')\n",
        "\n",
        "# Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n",
        "ts_df.set_crs(epsg=4326, inplace=True)\n",
        "\n",
        "ts_df.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDCB90tsWg3m"
      },
      "source": [
        "## <font color='red'> 4. Fault Data </font>\n",
        "\n",
        "GEM Global Active Faults Database (GAF-DB)\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b>\n",
        "    A feature layer displaying historical tsunami events from NCEI's Global Historical Tsunami Database. The Global Historical Tsunami Database consists of two related files containing information on tsunami events from 2000 B.C. to the present in the Atlantic, Indian, and Pacific Oceans; and the Mediterranean and Caribbean Seas.\n",
        "    \n",
        "    Citation: The GEM GAF-DB has been published in Earthquake Spectra.\n",
        "    Styron, Richard, and Marco Pagani. “The GEM Global Active Faults Database.” Earthquake Spectra, vol. 36, no. 1_suppl, Oct. 2020, pp. 160–180, doi:10.1177/8755293020944182.\n",
        "\n",
        "The link to the publication is here: https://journals.sagepub.com/doi/abs/10.1177/8755293020944182\n",
        "\n",
        "Documentation: https://github.com/GEMScienceTools/gem-global-active-faults\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ypqMsefWg3m",
        "outputId": "cf7c002b-a9ad-404b-8a8a-915a249047eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Geographic Coordinate System)\">name (Geographic Coordinate System)</td><td title=\"GCS_WGS_1984\">GCS_WGS_1984</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"4326\">4326</td></tr><tr><td id = \"td0\" title=\"angularUnitName (Angular Unit)\">angularUnitName (Angular Unit)</td><td title=\"Degree\">Degree</td></tr><tr><td id = \"td0\" title=\"datumName (Datum)\">datumName (Datum)</td><td title=\"D_WGS_1984\">D_WGS_1984</td></tr></table>"
            ],
            "text/plain": [
              "<geoprocessing spatial reference object at 0x261605ccfd0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtain Spatial Reference information for harmonized processing\n",
        "\n",
        "af_spatial_ref = arcpy.Describe(r\"D:/NDIS_Database/05_Fault/fault_points_wgs84.shp\").spatialReference\n",
        "af_spatial_ref"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJwnZCtFWg3n",
        "outputId": "d7888ec1-1bea-4d1a-fa21-15234555f030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 172823 entries, 0 to 172822\n",
            "Data columns (total 27 columns):\n",
            " #   Column      Non-Null Count   Dtype   \n",
            "---  ------      --------------   -----   \n",
            " 0   Id          172823 non-null  int64   \n",
            " 1   ORIG_FID    172823 non-null  int64   \n",
            " 2   average_di  79883 non-null   object  \n",
            " 3   average_ra  51397 non-null   object  \n",
            " 4   catalog_id  172823 non-null  object  \n",
            " 5   catalog_na  172823 non-null  object  \n",
            " 6   dip_dir     35041 non-null   object  \n",
            " 7   lower_seis  53437 non-null   object  \n",
            " 8   name        44202 non-null   object  \n",
            " 9   net_slip_r  110314 non-null  object  \n",
            " 10  slip_type   169593 non-null  object  \n",
            " 11  upper_seis  60927 non-null   object  \n",
            " 12  reference   25748 non-null   object  \n",
            " 13  epistemic_  72806 non-null   object  \n",
            " 14  accuracy    19508 non-null   object  \n",
            " 15  activity_c  69506 non-null   object  \n",
            " 16  fs_name     20954 non-null   object  \n",
            " 17  last_movem  8338 non-null    object  \n",
            " 18  downthrown  11368 non-null   object  \n",
            " 19  vert_sep_r  1434 non-null    object  \n",
            " 20  strike_sli  49459 non-null   object  \n",
            " 21  exposure_q  31349 non-null   object  \n",
            " 22  shortening  48621 non-null   object  \n",
            " 23  notes       5873 non-null    object  \n",
            " 24  downthro_1  5581 non-null    object  \n",
            " 25  fault_type  0 non-null       object  \n",
            " 26  geometry    172823 non-null  geometry\n",
            "dtypes: geometry(1), int64(2), object(24)\n",
            "memory usage: 35.6+ MB\n"
          ]
        }
      ],
      "source": [
        "# Prior to loading this file, fault data has been processes using Geoprocessing (via GUI) using Generate Points Along Lines tool.\n",
        "# Read the shapefile from local disk\n",
        "fault_df = gpd.read_file(r\"D:/NDIS_Database/05_Fault/fault_points_wgs84.shp\")\n",
        "fault_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6cyuWhPWg3n"
      },
      "outputs": [],
      "source": [
        "# extract the longitude and latitude from the geometry field using the .x and .y attributes of the geometry column\n",
        "if fault_df.geometry is not None:\n",
        "    # Create new fields for longitude and latitude\n",
        "    fault_df[\"longitude\"] = fault_df.geometry.x\n",
        "    fault_df[\"latitude\"]  = fault_df.geometry.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml0W_nq8Wg3n"
      },
      "outputs": [],
      "source": [
        "faultdb = fault_df[['ORIG_FID', 'longitude','latitude', 'geometry']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYTi-YZGWg3o"
      },
      "source": [
        "### Assign ID\n",
        "\n",
        "Add numeric prefix (177) and zero-padding the original index\n",
        "\n",
        "Preserves traceability to original ORIG_FID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQTJQu0zWg3o",
        "outputId": "89615ed6-f436-47ff-f045-6b9eb07d9bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13695\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(max(fault_df['ORIG_FID'].unique()))\n",
        "print(min(fault_df['ORIG_FID'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE6qatT1Wg3o"
      },
      "outputs": [],
      "source": [
        "fault_df = fault_df.copy()\n",
        "\n",
        "# Use 7-digit global index padded with zeros → ensures 10-digit result with '177' prefix\n",
        "fault_df[\"HazardID\"] = fault_df.reset_index().index.map(lambda i: f\"177{str(i).zfill(7)}\")\n",
        "\n",
        "# Check length and uniqueness\n",
        "assert fault_df[\"HazardID\"].str.len().max() == 10, \"HazardID exceeds 10 digits!\"\n",
        "assert fault_df[\"HazardID\"].is_unique, \"HazardID values are not unique!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ57AbmVWg3p",
        "outputId": "610b0be2-95f5-4537-adb1-0af7c7d84cfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "172823"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(fault_df['HazardID'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEp62VYOWg3p",
        "outputId": "d6f213f7-c869-4b6f-dce9-f483daffd65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1770172822\n",
            "1770000000\n"
          ]
        }
      ],
      "source": [
        "print(max(fault_df['HazardID'].unique()))\n",
        "print(min(fault_df['HazardID'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96bGL6QNWg3q"
      },
      "outputs": [],
      "source": [
        "# Mapping table to preserve tracability to ORIG_ID\n",
        "fault_df[[\"HazardID\", \"ORIG_FID\"]].to_csv(r\"D:\\NDIS_Database\\05_Fault\\fault_id_mapping.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK01RFDHWg3q",
        "outputId": "ac728944-0504-4929-f167-49f7b602c3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 172823 entries, 0 to 172822\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count   Dtype   \n",
            "---  ------      --------------   -----   \n",
            " 0   HazardID    172823 non-null  object  \n",
            " 1   longitude   172823 non-null  float64 \n",
            " 2   latitude    172823 non-null  float64 \n",
            " 3   geometry    172823 non-null  geometry\n",
            " 4   HazardType  172823 non-null  int64   \n",
            "dtypes: float64(2), geometry(1), int64(1), object(1)\n",
            "memory usage: 6.6+ MB\n"
          ]
        }
      ],
      "source": [
        "# Extract column needed for the basic NDIS database to compile with other geohazards dataset.\n",
        "# Volcano Number --> HazardID, longitude, latitude, HazardType (in numerical coded added after extraction). Volcano is 1.\n",
        "faultdb = fault_df[['HazardID', 'longitude','latitude', 'geometry']].copy()\n",
        "faultdb['HazardType'] = 4\n",
        "faultdb.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdFbDkP6Wg3q"
      },
      "source": [
        "## <font color='red'> 5. Earthquake Data </font>\n",
        "\n",
        "### <font color='green'> Historcal part: </font>\n",
        "\n",
        "### GHEC Catalog\n",
        "\n",
        "GEM provides Global Historical Earthquake Catalogue (GHEC) from 1000 to 1903 (Albini, 2014). (https://platform.openquake.org/maps/80/download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfeYGjHiWg3r"
      },
      "source": [
        "### SHEEC (SHARE European Earthquake Catalogue)\n",
        "\n",
        "SHEEC catalogue covers the year 1000-1899 for Europe region specifically. It consists of data with magnitude ranges from 1.7 to 8.5 (Stucchi et al., 2012). The data could be downloaded at https: //www.emidius.eu/SHEEC/sheec_1000_1899.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b19zjnhmWg39"
      },
      "source": [
        "### <font color='green'> Instrumental part: </font>\n",
        "\n",
        "### ISC Bulletin/ISC Global\n",
        "The ISC Bulletin has now been completely rebuilt for the period 1964-2010. As a result, the ISC hypocentre solutions and magnitudes for the entire period of 1964-latest are based on the ak135 velocity model and the location procedure that is currently used in operations.\n",
        "(http://www.isc.ac.uk/iscbulletin/search/catalogue/)\n",
        "\n",
        "The Bulletin of the International Seismological Centre relies on contributions from seismological agencies around the world. To date, a total of 573 agencies have contributed to the ISC Bulletin, throughout its history. For more information about the agency (http://www.isc.ac.uk/iscbulletin/agencies/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27UpMagMWg39"
      },
      "source": [
        "### ISC-GEM Catalogue\n",
        "\n",
        "The ISC-GEM Global Instrumental Earthquake Catalogue (1904-2016) is the result of a special effort to adapt and substantially extend and improve currently existing bulletin data for large earthquakes (magnitude 5.5 and above, plus continental events down to magnitude 5.0).\n",
        "(http://www.isc.ac.uk/iscgem/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gecA4-gMWg39"
      },
      "source": [
        "### Load data from local layer file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2f0C-pRWg3-",
        "outputId": "d513ba8b-050e-4037-ba8b-c09e77ea384a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1742244 entries, 0 to 1742243\n",
            "Data columns (total 10 columns):\n",
            " #   Column     Dtype  \n",
            "---  ------     -----  \n",
            " 0   eventID    float64\n",
            " 1   longitude  float64\n",
            " 2   latitude   float64\n",
            " 3   magnitude  float64\n",
            " 4   year       int64  \n",
            " 5   month      int64  \n",
            " 6   day        int64  \n",
            " 7   hour       int64  \n",
            " 8   minute     int64  \n",
            " 9   second     float64\n",
            "dtypes: float64(5), int64(5)\n",
            "memory usage: 132.9 MB\n"
          ]
        }
      ],
      "source": [
        "# Fix ID (identifier) of the earthquake events ID\n",
        "# Load CSV files\n",
        "df1 = pd.read_csv(r\"D:\\NDIS_Database\\02_Earthquake\\eq_1000_2023.csv\") # Dataset with incorrect eventID\n",
        "df2 = pd.read_csv(r\"D:\\NDIS_Database\\02_Earthquake\\GHEC1000_1903\\eq1000.csv\") # Dataset with correct GEHid\n",
        "\n",
        "# Rename columns in df2 to match df1 (update the mapping if needed)\n",
        "rename_mapping = {\n",
        "    \"Lat\": \"latitude\",\n",
        "    \"Lon\": \"longitude\",\n",
        "    \"Year\": \"year\",\n",
        "    \"Mo\": \"month\",\n",
        "    \"Da\": \"day\"\n",
        "}\n",
        "\n",
        "df2.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "# Define matching fields\n",
        "key_fields = [\"longitude\", \"latitude\", \"year\", \"month\", \"day\"]\n",
        "\n",
        "# Merge on key fields\n",
        "merged_df = df1.merge(df2[key_fields + [\"GEHid\"]], on=key_fields, how=\"left\")\n",
        "\n",
        "# Replace eventID with GEHid where a match is found\n",
        "merged_df[\"eventID\"] = merged_df[\"GEHid\"].combine_first(merged_df[\"eventID\"])\n",
        "\n",
        "# Drop the temporary GEHid column\n",
        "merged_df.drop(columns=[\"GEHid\"], inplace=True)\n",
        "\n",
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEEun_X2Wg3-",
        "outputId": "e1b3c2f2-7386-42da-9fc8-38675eec6576"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventID</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>magnitude</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>210.0</td>\n",
              "      <td>4.2370</td>\n",
              "      <td>50.1830</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1000</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360.0</td>\n",
              "      <td>38.8000</td>\n",
              "      <td>37.1000</td>\n",
              "      <td>6.20</td>\n",
              "      <td>1003</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>600.0</td>\n",
              "      <td>13.8310</td>\n",
              "      <td>41.4880</td>\n",
              "      <td>5.20</td>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500.0</td>\n",
              "      <td>11.8790</td>\n",
              "      <td>43.4630</td>\n",
              "      <td>5.20</td>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6849.0</td>\n",
              "      <td>47.4000</td>\n",
              "      <td>34.6000</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1008</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742239</th>\n",
              "      <td>626591656.0</td>\n",
              "      <td>26.1016</td>\n",
              "      <td>31.0996</td>\n",
              "      <td>4.60</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>10.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742240</th>\n",
              "      <td>626591734.0</td>\n",
              "      <td>-117.7490</td>\n",
              "      <td>32.9930</td>\n",
              "      <td>4.89</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742241</th>\n",
              "      <td>626593372.0</td>\n",
              "      <td>70.1037</td>\n",
              "      <td>41.0890</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>54</td>\n",
              "      <td>34.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742242</th>\n",
              "      <td>626593693.0</td>\n",
              "      <td>93.4950</td>\n",
              "      <td>9.1320</td>\n",
              "      <td>5.28</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742243</th>\n",
              "      <td>626593692.0</td>\n",
              "      <td>147.2030</td>\n",
              "      <td>14.6510</td>\n",
              "      <td>6.27</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>14.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1742244 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             eventID  longitude  latitude  magnitude  year  month  day  hour  \\\n",
              "0              210.0     4.2370   50.1830       3.70  1000      3   29     0   \n",
              "1              360.0    38.8000   37.1000       6.20  1003      3   21     0   \n",
              "2              600.0    13.8310   41.4880       5.20  1005      1    1     0   \n",
              "3              500.0    11.8790   43.4630       5.20  1005      1    1     0   \n",
              "4             6849.0    47.4000   34.6000       7.00  1008      4   27    18   \n",
              "...              ...        ...       ...        ...   ...    ...  ...   ...   \n",
              "1742239  626591656.0    26.1016   31.0996       4.60  2023      8    3     2   \n",
              "1742240  626591734.0  -117.7490   32.9930       4.89  2023      8    3     7   \n",
              "1742241  626593372.0    70.1037   41.0890       4.00  2023      8    3    10   \n",
              "1742242  626593693.0    93.4950    9.1320       5.28  2023      8    3    11   \n",
              "1742243  626593692.0   147.2030   14.6510       6.27  2023      8    3    15   \n",
              "\n",
              "         minute  second  \n",
              "0             0    0.00  \n",
              "1             0    0.00  \n",
              "2             0    0.00  \n",
              "3             0    0.00  \n",
              "4             0    0.00  \n",
              "...         ...     ...  \n",
              "1742239      18   10.94  \n",
              "1742240      30    0.00  \n",
              "1742241      54   34.32  \n",
              "1742242      39    4.00  \n",
              "1742243      45   14.00  \n",
              "\n",
              "[1742244 rows x 10 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5isKuENWg3-",
        "outputId": "7e436a9c-6082-4ab2-a070-7bd2ddb0dca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1742244 entries, 0 to 1742243\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Dtype  \n",
            "---  ------      -----  \n",
            " 0   HazardID    float64\n",
            " 1   longitude   float64\n",
            " 2   latitude    float64\n",
            " 3   HazardType  int64  \n",
            "dtypes: float64(3), int64(1)\n",
            "memory usage: 53.2 MB\n"
          ]
        }
      ],
      "source": [
        "eq_df = merged_df[['eventID','longitude', 'latitude']].copy()\n",
        "eq_df.rename(columns = {'eventID':'HazardID'}, inplace = True)\n",
        "eq_df['HazardType'] = 5\n",
        "eq_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GelhC2YyWg3_",
        "outputId": "26e4a237-230c-44f7-a86f-0e07527e4f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of NaN values present: 0\n"
          ]
        }
      ],
      "source": [
        "nan_in_eq = eq_df.isnull().sum().sum()\n",
        "\n",
        "# printing the number of values present in\n",
        "# the whole dataframe\n",
        "print('Number of NaN values present: ' + str(nan_in_eq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZDPf1jtWg3_",
        "outputId": "0a0a8676-a97c-46e1-9809-37929636aaf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Geographic 2D CRS: EPSG:4326>\n",
              "Name: WGS 84\n",
              "Axis Info [ellipsoidal]:\n",
              "- Lat[north]: Geodetic latitude (degree)\n",
              "- Lon[east]: Geodetic longitude (degree)\n",
              "Area of Use:\n",
              "- name: World.\n",
              "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
              "Datum: World Geodetic System 1984 ensemble\n",
              "- Ellipsoid: WGS 84\n",
              "- Prime Meridian: Greenwich"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate points geometry from longitude and latitude\n",
        "eq_df['geometry'] = eq_df.apply(lambda x: Point(x['longitude'], x['latitude']), axis=1)\n",
        "\n",
        "# Create a GeoDataFrame\n",
        "eq_df = gpd.GeoDataFrame(eq_df, geometry='geometry')\n",
        "\n",
        "# Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n",
        "eq_df.set_crs(epsg=4326, inplace=True)\n",
        "\n",
        "eq_df.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00B5lJrkWg3_",
        "outputId": "45fbae9b-a632-4c72-8065-e1e875bc93a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 1742244 entries, 0 to 1742243\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Dtype   \n",
            "---  ------      -----   \n",
            " 0   HazardID    float64 \n",
            " 1   longitude   float64 \n",
            " 2   latitude    float64 \n",
            " 3   HazardType  int64   \n",
            " 4   geometry    geometry\n",
            "dtypes: float64(3), geometry(1), int64(1)\n",
            "memory usage: 66.5 MB\n"
          ]
        }
      ],
      "source": [
        "eq_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "517G0zY9Wg4A"
      },
      "source": [
        "-------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjvqiHDIWg4A"
      },
      "source": [
        "# NEW ENTRY NUCLEAR POWER PLANT ☢️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE3fYNp_Wg4A",
        "outputId": "3b36d824-2764-417d-a9e8-6ede791a75d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1541 entries, 0 to 1540\n",
            "Data columns (total 38 columns):\n",
            " #   Column                                    Non-Null Count  Dtype  \n",
            "---  ------                                    --------------  -----  \n",
            " 0   Date Last Researched                      1541 non-null   object \n",
            " 1   Country/Area                              1541 non-null   object \n",
            " 2   Project Name                              1541 non-null   object \n",
            " 3   Unit Name                                 1541 non-null   object \n",
            " 4   Project Name in Local Language / Script   361 non-null    object \n",
            " 5   Other Name(s)                             333 non-null    object \n",
            " 6   Capacity (MW)                             1541 non-null   object \n",
            " 7   Status                                    1541 non-null   object \n",
            " 8   Reactor Type                              1541 non-null   object \n",
            " 9   Model                                     1541 non-null   object \n",
            " 10  Start Year                                809 non-null    float64\n",
            " 11  Retirement Year                           253 non-null    float64\n",
            " 12  Planned Retirement                        253 non-null    object \n",
            " 13  Cancellation Year                         437 non-null    float64\n",
            " 14  Construction Start Date                   783 non-null    object \n",
            " 15  First Criticality Date                    662 non-null    object \n",
            " 16  First Grid Connection                     655 non-null    object \n",
            " 17  Commercial Operation Date                 809 non-null    object \n",
            " 18  Retirement Date                           253 non-null    object \n",
            " 19  Owner                                     1372 non-null   object \n",
            " 20  Owner Name in Local Language / Script     457 non-null    object \n",
            " 21  Operator                                  1065 non-null   object \n",
            " 22  Operator Name in Local Language / Script  372 non-null    object \n",
            " 23  Reference Net Capacity (MW)               709 non-null    float64\n",
            " 24  Design Net Capacity (MW)                  723 non-null    float64\n",
            " 25  Thermal Capacity (MWt)                    741 non-null    float64\n",
            " 26  Latitude                                  1541 non-null   float64\n",
            " 27  Longitude                                 1541 non-null   float64\n",
            " 28  Location Accuracy                         1541 non-null   object \n",
            " 29  City                                      500 non-null    object \n",
            " 30  Local Area (taluk, county)                1262 non-null   object \n",
            " 31  Major Area (prefecture, district)         519 non-null    object \n",
            " 32  State/Province                            1378 non-null   object \n",
            " 33  Subregion                                 1541 non-null   object \n",
            " 34  Region                                    1541 non-null   object \n",
            " 35  GEM location ID                           1541 non-null   object \n",
            " 36  GEM unit ID                               1541 non-null   object \n",
            " 37  Wiki URL                                  1541 non-null   object \n",
            "dtypes: float64(8), object(30)\n",
            "memory usage: 457.6+ KB\n"
          ]
        }
      ],
      "source": [
        "# Read data\n",
        "nuclear_df = pd.read_csv(r\"D:\\NDIS_Database\\15_NuclearPower\\nuclearpp.csv\")\n",
        "nuclear_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BdmlE0UWg4B",
        "outputId": "2cd884ef-5b34-4e74-f739-49972a4cf398"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       G100000500502\n",
              "1       G100000500382\n",
              "2       G100000500646\n",
              "3       G100000500600\n",
              "4       G100000500385\n",
              "            ...      \n",
              "1536    G100000501492\n",
              "1537    G100000501493\n",
              "1538    G100000501494\n",
              "1539    G100000501495\n",
              "1540    G100000501496\n",
              "Name: GEM unit ID, Length: 1541, dtype: object"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nuclear_df['GEM unit ID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QSdG43eWg4B"
      },
      "outputs": [],
      "source": [
        "# Assemble the cleaned nuclear hazard dataframe\n",
        "cleaned_nuclear_df = pd.DataFrame({\n",
        "    \"HazardID\": nuclear_df['GEM unit ID'],\n",
        "    \"latitude\": pd.to_numeric(nuclear_df[\"Latitude\"], errors=\"coerce\"),\n",
        "    \"longitude\": pd.to_numeric(nuclear_df[\"Longitude\"], errors=\"coerce\"),\n",
        "    \"HazardType\": \"Nuclear\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w4QxfFBWg4B",
        "outputId": "4c9cdeec-2a1a-4f4c-801c-48b53b820eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1541 entries, 0 to 1540\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   HazardID    1541 non-null   object \n",
            " 1   latitude    1541 non-null   float64\n",
            " 2   longitude   1541 non-null   float64\n",
            " 3   HazardType  1541 non-null   object \n",
            "dtypes: float64(2), object(2)\n",
            "memory usage: 48.3+ KB\n"
          ]
        }
      ],
      "source": [
        "cleaned_nuclear_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dInMnxDkWg4C",
        "outputId": "2be8d050-664e-4055-b80c-9e050b1802cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1541"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cleaned_nuclear_df.HazardID.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rah3ARHoWg4D",
        "outputId": "f9b432eb-636c-49f6-cce6-0341af35e89c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1541 entries, 0 to 1540\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   HazardID    1541 non-null   int64  \n",
            " 1   latitude    1541 non-null   float64\n",
            " 2   longitude   1541 non-null   float64\n",
            " 3   HazardType  1541 non-null   object \n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 48.3+ KB\n"
          ]
        }
      ],
      "source": [
        "cleaned_nuclear_df = cleaned_nuclear_df.copy()\n",
        "\n",
        "# Extract last 6 digits of original G-code\n",
        "cleaned_nuclear_df[\"unit_id_digits\"] = cleaned_nuclear_df[\"HazardID\"].str[-6:]\n",
        "\n",
        "# Add prefix '1110' to make a uniform 10-digit numeric HazardID\n",
        "cleaned_nuclear_df[\"HazardID\"] = (\"1110\" + cleaned_nuclear_df[\"unit_id_digits\"]).astype(\"int64\")\n",
        "\n",
        "# Optional: drop helper column\n",
        "cleaned_nuclear_df.drop(columns=[\"unit_id_digits\"], inplace=True)\n",
        "cleaned_nuclear_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iadYpitOWg4D",
        "outputId": "171d4758-0abc-4473-f487-9c9b5beb7269"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HazardID</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>HazardType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1110500502</td>\n",
              "      <td>-33.96701</td>\n",
              "      <td>-59.20950</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1110500382</td>\n",
              "      <td>-33.96720</td>\n",
              "      <td>-59.20730</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1110500646</td>\n",
              "      <td>-33.96720</td>\n",
              "      <td>-59.20750</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1110500600</td>\n",
              "      <td>-33.96780</td>\n",
              "      <td>-59.21301</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1110500385</td>\n",
              "      <td>-32.23160</td>\n",
              "      <td>-64.44220</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>1110501492</td>\n",
              "      <td>11.41090</td>\n",
              "      <td>108.97430</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1537</th>\n",
              "      <td>1110501493</td>\n",
              "      <td>11.69030</td>\n",
              "      <td>109.17510</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1538</th>\n",
              "      <td>1110501494</td>\n",
              "      <td>11.69030</td>\n",
              "      <td>109.17510</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1539</th>\n",
              "      <td>1110501495</td>\n",
              "      <td>11.69030</td>\n",
              "      <td>109.17510</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1540</th>\n",
              "      <td>1110501496</td>\n",
              "      <td>11.69030</td>\n",
              "      <td>109.17510</td>\n",
              "      <td>Nuclear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1541 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        HazardID  latitude  longitude HazardType\n",
              "0     1110500502 -33.96701  -59.20950    Nuclear\n",
              "1     1110500382 -33.96720  -59.20730    Nuclear\n",
              "2     1110500646 -33.96720  -59.20750    Nuclear\n",
              "3     1110500600 -33.96780  -59.21301    Nuclear\n",
              "4     1110500385 -32.23160  -64.44220    Nuclear\n",
              "...          ...       ...        ...        ...\n",
              "1536  1110501492  11.41090  108.97430    Nuclear\n",
              "1537  1110501493  11.69030  109.17510    Nuclear\n",
              "1538  1110501494  11.69030  109.17510    Nuclear\n",
              "1539  1110501495  11.69030  109.17510    Nuclear\n",
              "1540  1110501496  11.69030  109.17510    Nuclear\n",
              "\n",
              "[1541 rows x 4 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_nuclear_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V7ZkCsHWg4E",
        "outputId": "fd1755db-4cc2-444e-ddae-7add273eb216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1541 entries, 0 to 1540\n",
            "Data columns (total 13 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   HazardID               1541 non-null   int64  \n",
            " 1   latitude               1541 non-null   float64\n",
            " 2   longitude              1541 non-null   float64\n",
            " 3   HazardType             1541 non-null   object \n",
            " 4   intensity              1541 non-null   float64\n",
            " 5   duration_minutes       1541 non-null   float64\n",
            " 6   economic_loss_million  1541 non-null   float64\n",
            " 7   travel_time            0 non-null      float64\n",
            " 8   monitor_time           1541 non-null   float64\n",
            " 9   cpm_total_time         0 non-null      float64\n",
            " 10  HazardStage            1541 non-null   object \n",
            " 11  pop                    1541 non-null   float64\n",
            " 12  distance               1541 non-null   float64\n",
            "dtypes: float64(10), int64(1), object(2)\n",
            "memory usage: 156.6+ KB\n"
          ]
        }
      ],
      "source": [
        "# Read data\n",
        "cleaned_nuclear_df = pd.read_csv(r\"D:\\NDIS_Database\\cleaned_nuclear_df.csv\")\n",
        "cleaned_nuclear_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgEzYtjtWg4E"
      },
      "source": [
        "# Concatenate all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pEu9isDWg4F",
        "outputId": "b94e98c3-b5aa-46fb-dee7-4579e8112355"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgisclone\\Lib\\site-packages\\geopandas\\array.py:1470: UserWarning: CRS not set for some of the concatenation inputs. Setting output's CRS as WGS 84 (the single non-null crs provided).\n",
            "  return GeometryArray(data, crs=_get_common_crs(to_concat))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HazardID</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>geometry</th>\n",
              "      <th>HazardType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>210010</td>\n",
              "      <td>50.170000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>POINT (6.85000 50.17000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>210020</td>\n",
              "      <td>45.775000</td>\n",
              "      <td>2.970000</td>\n",
              "      <td>POINT (2.97000 45.77500)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>210030</td>\n",
              "      <td>42.170000</td>\n",
              "      <td>2.530000</td>\n",
              "      <td>POINT (2.53000 42.17000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>210040</td>\n",
              "      <td>38.870000</td>\n",
              "      <td>-4.020000</td>\n",
              "      <td>POINT (-4.02000 38.87000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>211004</td>\n",
              "      <td>41.730000</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>POINT (12.70000 41.73000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172818</th>\n",
              "      <td>1770172818</td>\n",
              "      <td>-14.438700</td>\n",
              "      <td>34.575740</td>\n",
              "      <td>POINT (34.57574 -14.43870)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172819</th>\n",
              "      <td>1770172819</td>\n",
              "      <td>-14.477742</td>\n",
              "      <td>34.599504</td>\n",
              "      <td>POINT (34.59950 -14.47774)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172820</th>\n",
              "      <td>1770172820</td>\n",
              "      <td>-14.516784</td>\n",
              "      <td>34.623267</td>\n",
              "      <td>POINT (34.62327 -14.51678)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172821</th>\n",
              "      <td>1770172821</td>\n",
              "      <td>-14.555826</td>\n",
              "      <td>34.647031</td>\n",
              "      <td>POINT (34.64703 -14.55583)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172822</th>\n",
              "      <td>1770172822</td>\n",
              "      <td>-14.581980</td>\n",
              "      <td>34.662950</td>\n",
              "      <td>POINT (34.66295 -14.58198)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1933648 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          HazardID   latitude  longitude                    geometry  \\\n",
              "0           210010  50.170000   6.850000    POINT (6.85000 50.17000)   \n",
              "1           210020  45.775000   2.970000    POINT (2.97000 45.77500)   \n",
              "2           210030  42.170000   2.530000    POINT (2.53000 42.17000)   \n",
              "3           210040  38.870000  -4.020000   POINT (-4.02000 38.87000)   \n",
              "4           211004  41.730000  12.700000   POINT (12.70000 41.73000)   \n",
              "...            ...        ...        ...                         ...   \n",
              "172818  1770172818 -14.438700  34.575740  POINT (34.57574 -14.43870)   \n",
              "172819  1770172819 -14.477742  34.599504  POINT (34.59950 -14.47774)   \n",
              "172820  1770172820 -14.516784  34.623267  POINT (34.62327 -14.51678)   \n",
              "172821  1770172821 -14.555826  34.647031  POINT (34.64703 -14.55583)   \n",
              "172822  1770172822 -14.581980  34.662950  POINT (34.66295 -14.58198)   \n",
              "\n",
              "        HazardType  \n",
              "0                1  \n",
              "1                1  \n",
              "2                1  \n",
              "3                1  \n",
              "4                1  \n",
              "...            ...  \n",
              "172818           4  \n",
              "172819           4  \n",
              "172820           4  \n",
              "172821           4  \n",
              "172822           4  \n",
              "\n",
              "[1933648 rows x 5 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Concatenate fault data to the rest of the datasets\n",
        "ghz_df = pd.concat([vo_df, ls_df, ts_df, eq_df, faultdb, cleaned_nuclear_df]) #All Geohazards dataframe\n",
        "ghz_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQmk93e8Wg4F",
        "outputId": "0c681d3a-e886-4bf7-80e0-319cfed02133"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HazardID</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>geometry</th>\n",
              "      <th>HazardType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>210010</td>\n",
              "      <td>50.170000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>POINT (6.85000 50.17000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>210020</td>\n",
              "      <td>45.775000</td>\n",
              "      <td>2.970000</td>\n",
              "      <td>POINT (2.97000 45.77500)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>210030</td>\n",
              "      <td>42.170000</td>\n",
              "      <td>2.530000</td>\n",
              "      <td>POINT (2.53000 42.17000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>210040</td>\n",
              "      <td>38.870000</td>\n",
              "      <td>-4.020000</td>\n",
              "      <td>POINT (-4.02000 38.87000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>211004</td>\n",
              "      <td>41.730000</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>POINT (12.70000 41.73000)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172818</th>\n",
              "      <td>1770172818</td>\n",
              "      <td>-14.438700</td>\n",
              "      <td>34.575740</td>\n",
              "      <td>POINT (34.57574 -14.43870)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172819</th>\n",
              "      <td>1770172819</td>\n",
              "      <td>-14.477742</td>\n",
              "      <td>34.599504</td>\n",
              "      <td>POINT (34.59950 -14.47774)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172820</th>\n",
              "      <td>1770172820</td>\n",
              "      <td>-14.516784</td>\n",
              "      <td>34.623267</td>\n",
              "      <td>POINT (34.62327 -14.51678)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172821</th>\n",
              "      <td>1770172821</td>\n",
              "      <td>-14.555826</td>\n",
              "      <td>34.647031</td>\n",
              "      <td>POINT (34.64703 -14.55583)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172822</th>\n",
              "      <td>1770172822</td>\n",
              "      <td>-14.581980</td>\n",
              "      <td>34.662950</td>\n",
              "      <td>POINT (34.66295 -14.58198)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1933648 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          HazardID   latitude  longitude                    geometry  \\\n",
              "0           210010  50.170000   6.850000    POINT (6.85000 50.17000)   \n",
              "1           210020  45.775000   2.970000    POINT (2.97000 45.77500)   \n",
              "2           210030  42.170000   2.530000    POINT (2.53000 42.17000)   \n",
              "3           210040  38.870000  -4.020000   POINT (-4.02000 38.87000)   \n",
              "4           211004  41.730000  12.700000   POINT (12.70000 41.73000)   \n",
              "...            ...        ...        ...                         ...   \n",
              "172818  1770172818 -14.438700  34.575740  POINT (34.57574 -14.43870)   \n",
              "172819  1770172819 -14.477742  34.599504  POINT (34.59950 -14.47774)   \n",
              "172820  1770172820 -14.516784  34.623267  POINT (34.62327 -14.51678)   \n",
              "172821  1770172821 -14.555826  34.647031  POINT (34.64703 -14.55583)   \n",
              "172822  1770172822 -14.581980  34.662950  POINT (34.66295 -14.58198)   \n",
              "\n",
              "        HazardType  \n",
              "0                1  \n",
              "1                1  \n",
              "2                1  \n",
              "3                1  \n",
              "4                1  \n",
              "...            ...  \n",
              "172818           4  \n",
              "172819           4  \n",
              "172820           4  \n",
              "172821           4  \n",
              "172822           4  \n",
              "\n",
              "[1933648 rows x 5 columns]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ghz_df.set_crs(epsg=4326, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNL-ztfhWg4G"
      },
      "outputs": [],
      "source": [
        "# Save locally in a supported format\n",
        "output_path = \"D:/NDIS_Database/ghz.gpkg\"  # Adjust as needed\n",
        "ghz_df.to_file(output_path, driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4hxKhRTWg4G"
      },
      "outputs": [],
      "source": [
        "ghz_df.drop('geometry',axis=1).to_csv(\"D:/NDIS_Database/ghz84.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnUPapk3Wg4G"
      },
      "outputs": [],
      "source": [
        "# For query purpose save it into sql\n",
        "# Step 1: Create or open the SQLite database\n",
        "conn = sqlite3.connect(\"ghz_data.sqlite\")\n",
        "\n",
        "# Step 2: Save the full multi-hazard DataFrame\n",
        "ghz_df.to_sql(\"hazards\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# Step 3: Close the connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehxjnwxrWg4H"
      },
      "source": [
        "## <font color='red'> Countries EEZ Data </font>\n",
        "Retrieved from Maritime Boundaries and Exclusive Economic Zones (200NM), version 12\n",
        "\n",
        "https://www.marineregions.org/. https://doi.org/10.14284/632\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Citation:</b>\n",
        "    Flanders Marine Institute (2024). Union of the ESRI Country shapefile and the Exclusive Economic Zones (version 4). Available online at https://www.marineregions.org/. https://doi.org/10.14284/698. Consulted on 2025-02-20\n",
        "Further info:\n",
        "https://www.marineregions.org/downloads.php#unioneezcountry\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjCXr__PWg4H"
      },
      "source": [
        "## Test Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCWGNGm8Wg4H",
        "outputId": "58dd4494-ecd4-4fd8-ac8b-878f1ccb73e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HazardID</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>HazardType</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.100100e+05</td>\n",
              "      <td>50.170000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT (6.85000 50.17000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.100200e+05</td>\n",
              "      <td>45.775000</td>\n",
              "      <td>2.970000</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT (2.97000 45.77500)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.100300e+05</td>\n",
              "      <td>42.170000</td>\n",
              "      <td>2.530000</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT (2.53000 42.17000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.100400e+05</td>\n",
              "      <td>38.870000</td>\n",
              "      <td>-4.020000</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT (-4.02000 38.87000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.110040e+05</td>\n",
              "      <td>41.730000</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT (12.70000 41.73000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933494</th>\n",
              "      <td>1.776288e+09</td>\n",
              "      <td>-14.438700</td>\n",
              "      <td>34.575740</td>\n",
              "      <td>4</td>\n",
              "      <td>POINT (34.57574 -14.43870)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933495</th>\n",
              "      <td>1.771045e+09</td>\n",
              "      <td>-14.477742</td>\n",
              "      <td>34.599504</td>\n",
              "      <td>4</td>\n",
              "      <td>POINT (34.59950 -14.47774)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933496</th>\n",
              "      <td>1.779958e+09</td>\n",
              "      <td>-14.516784</td>\n",
              "      <td>34.623267</td>\n",
              "      <td>4</td>\n",
              "      <td>POINT (34.62327 -14.51678)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933497</th>\n",
              "      <td>1.778385e+09</td>\n",
              "      <td>-14.555826</td>\n",
              "      <td>34.647031</td>\n",
              "      <td>4</td>\n",
              "      <td>POINT (34.64703 -14.55583)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933498</th>\n",
              "      <td>1.774715e+09</td>\n",
              "      <td>-14.581980</td>\n",
              "      <td>34.662950</td>\n",
              "      <td>4</td>\n",
              "      <td>POINT (34.66295 -14.58198)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1933499 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             HazardID   latitude  longitude  HazardType  \\\n",
              "0        2.100100e+05  50.170000   6.850000           1   \n",
              "1        2.100200e+05  45.775000   2.970000           1   \n",
              "2        2.100300e+05  42.170000   2.530000           1   \n",
              "3        2.100400e+05  38.870000  -4.020000           1   \n",
              "4        2.110040e+05  41.730000  12.700000           1   \n",
              "...               ...        ...        ...         ...   \n",
              "1933494  1.776288e+09 -14.438700  34.575740           4   \n",
              "1933495  1.771045e+09 -14.477742  34.599504           4   \n",
              "1933496  1.779958e+09 -14.516784  34.623267           4   \n",
              "1933497  1.778385e+09 -14.555826  34.647031           4   \n",
              "1933498  1.774715e+09 -14.581980  34.662950           4   \n",
              "\n",
              "                           geometry  \n",
              "0          POINT (6.85000 50.17000)  \n",
              "1          POINT (2.97000 45.77500)  \n",
              "2          POINT (2.53000 42.17000)  \n",
              "3         POINT (-4.02000 38.87000)  \n",
              "4         POINT (12.70000 41.73000)  \n",
              "...                             ...  \n",
              "1933494  POINT (34.57574 -14.43870)  \n",
              "1933495  POINT (34.59950 -14.47774)  \n",
              "1933496  POINT (34.62327 -14.51678)  \n",
              "1933497  POINT (34.64703 -14.55583)  \n",
              "1933498  POINT (34.66295 -14.58198)  \n",
              "\n",
              "[1933499 rows x 5 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ghz_gpkg = r\"D:\\NDIS_Database\\ghz84.gpkg\"\n",
        "# Load the GeoPackage\n",
        "ghz = gpd.read_file(ghz_gpkg, layer=\"ghz84\")\n",
        "ghz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WyqraipWg4H",
        "outputId": "c6df2324-d635-4898-91ca-e07d555c44e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Geographic 2D CRS: EPSG:4326>\n",
              "Name: WGS 84\n",
              "Axis Info [ellipsoidal]:\n",
              "- Lat[north]: Geodetic latitude (degree)\n",
              "- Lon[east]: Geodetic longitude (degree)\n",
              "Area of Use:\n",
              "- name: World.\n",
              "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
              "Datum: World Geodetic System 1984 ensemble\n",
              "- Ellipsoid: WGS 84\n",
              "- Prime Meridian: Greenwich"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ghz.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajPgPvhoWg4I"
      },
      "source": [
        "----------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1QrS_cWg4I"
      },
      "source": [
        "# <font color='red'> Clip and Near Analysis </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCn3ELgBWg4I"
      },
      "source": [
        "### CLIP and NEAR Analysis for the entire region"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoNWpjqhWg4J"
      },
      "source": [
        "Divide the dataset into regions EEZ (country+ocean territory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo5SAv9sWg4J",
        "outputId": "93671e0e-86a5-46d4-cce3-f4172aa7623e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 328 entries, 0 to 327\n",
            "Data columns (total 13 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   MRGID_EEZ   286 non-null    float64 \n",
            " 1   TERRITORY1  327 non-null    object  \n",
            " 2   MRGID_TER1  326 non-null    float64 \n",
            " 3   ISO_TER1    293 non-null    object  \n",
            " 4   UN_TER1     289 non-null    float64 \n",
            " 5   SOVEREIGN1  327 non-null    object  \n",
            " 6   MRGID_SOV1  327 non-null    float64 \n",
            " 7   ISO_SOV1    327 non-null    object  \n",
            " 8   POL_TYPE    328 non-null    object  \n",
            " 9   Y_1         328 non-null    float64 \n",
            " 10  x_1         328 non-null    float64 \n",
            " 11  AREA_KM2    328 non-null    int64   \n",
            " 12  geometry    328 non-null    geometry\n",
            "dtypes: float64(6), geometry(1), int64(1), object(5)\n",
            "memory usage: 33.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Read the shapefile from local disk\n",
        "eez = gpd.read_file(r\"D:\\NDIS_Database\\00_ClippingRegion\\EEZ_land_union_v4_202410\\EEZ_land_union_v4_202410.shp\")\n",
        "eez.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tajb0TDWg4J"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGYNr_bDWg4J"
      },
      "source": [
        "### EEZ Data Treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSfzdzXrWg4K",
        "outputId": "34551aa8-b2b3-4dd8-c862-2b346282476b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'D:\\\\ArcGISProjects\\\\GeohazardDB\\\\GeohazardDB.gdb'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the path to this geodatabase\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"  # Update the path accordingly\n",
        "gdb_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25O1PodSWg4K"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNDio-kSWg4L",
        "outputId": "143b3599-485c-4643-b101-ea6a16b7b147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Finished merging polygons. EEZ_country now contains 275 polygons.\n"
          ]
        }
      ],
      "source": [
        "# Define feature classes\n",
        "eez_country = \"EEZ_country\"\n",
        "eez_union = \"EEZ_union\"\n",
        "\n",
        "# Step 1: Generate Near Table\n",
        "near_table = \"EEZ_near_table\"\n",
        "if not arcpy.Exists(near_table):\n",
        "    print(\"⚠️ Generating Near Table...\")\n",
        "    arcpy.GenerateNearTable_analysis(eez_union, eez_country, near_table, closest=\"CLOSEST\", method=\"PLANAR\")\n",
        "\n",
        "# Step 2: Add NEAR_FID to EEZ_union\n",
        "arcpy.JoinField_management(eez_union, \"OBJECTID\", near_table, \"IN_FID\", [\"NEAR_FID\"])\n",
        "\n",
        "# Step 3: Merge EEZ_union into EEZ_country using NEAR_FID\n",
        "with arcpy.da.UpdateCursor(eez_country, [\"OBJECTID\", \"SHAPE@\"]) as country_cursor:\n",
        "    for country_row in country_cursor:\n",
        "        country_id = country_row[0]\n",
        "        country_geom = country_row[1]\n",
        "\n",
        "        # Collect matching EEZ_union geometries\n",
        "        union_geoms = []\n",
        "        with arcpy.da.SearchCursor(eez_union, [\"NEAR_FID\", \"SHAPE@\"]) as union_cursor:\n",
        "            for union_row in union_cursor:\n",
        "                if union_row[0] == country_id and union_row[1] is not None:\n",
        "                    union_geoms.append(union_row[1])\n",
        "\n",
        "        # Merge all geometries if matches exist\n",
        "        if union_geoms:\n",
        "            merged_geom = reduce(lambda x, y: x.union(y), [country_geom] + union_geoms)\n",
        "            country_row[1] = merged_geom\n",
        "            country_cursor.updateRow(country_row)\n",
        "\n",
        "print(\"✅ Finished merging polygons. EEZ_country now contains 275 polygons.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPDhBto3Wg4L",
        "outputId": "4d997a73-7cdd-4506-aef5-53f4364d50ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Unique FID count: 327\n",
            "🎉 The field has exactly 327 unique values, matching the number of polygons!\n"
          ]
        }
      ],
      "source": [
        "# Define feature classes\n",
        "eez = \"EEZ24\"\n",
        "# Field to check (change if needed)\n",
        "unique_field = \"FID\"\n",
        "\n",
        "# Get unique values\n",
        "unique_values = set()\n",
        "with arcpy.da.SearchCursor(eez, [unique_field]) as cursor:\n",
        "    for row in cursor:\n",
        "        if row[0]:  # Ignore Null values\n",
        "            unique_values.add(row[0])\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Unique {unique_field} count: {len(unique_values)}\")\n",
        "if len(unique_values) == 327:\n",
        "    print(\"🎉 The field has exactly 327 unique values, matching the number of polygons!\")\n",
        "else:\n",
        "    print(f\"⚠️ Mismatch! Expected 327 but found {len(unique_values)}. Check for duplicates or missing values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iL8LCo6Wg4M",
        "outputId": "16463645-f0dc-4a50-ce33-190db4103637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ 'AAT' was NOT found in 'ISO_SOV1'.\n"
          ]
        }
      ],
      "source": [
        "# Field to check\n",
        "field_name = \"ISO_SOV1\"\n",
        "search_value = \"AAT\"\n",
        "\n",
        "# Check if \"ANT\" exists\n",
        "exists = False\n",
        "with arcpy.da.SearchCursor(eez, [field_name]) as cursor:\n",
        "    for row in cursor:\n",
        "        if row[0] == search_value:\n",
        "            exists = True\n",
        "            break  # No need to continue once found\n",
        "\n",
        "# Print result\n",
        "if exists:\n",
        "    print(f\"✅ '{search_value}' exists in the field '{field_name}'.\")\n",
        "else:\n",
        "    print(f\"❌ '{search_value}' was NOT found in '{field_name}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdHt8AE2Wg4M"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D34bU8gEWg4N",
        "outputId": "a55e20ac-dbf4-43fc-d010-4f4fb16e666b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ISO_TER1 values have been updated to unique 3-letter names.\n"
          ]
        }
      ],
      "source": [
        "input_eez = \"EEZ24\"\n",
        "\n",
        "# Create a set to track used ISO_TER1 values and if NaN or duplicates, rename it from TERRITORY1 abbreviation\n",
        "used_names = set()\n",
        "\n",
        "# Function to generate a unique 3-letter code\n",
        "def generate_unique_code(existing_names):\n",
        "    while True:\n",
        "        # Generate a random 3-letter combination\n",
        "        code = ''.join(random.choices(string.ascii_uppercase, k=3))\n",
        "        if code not in existing_names:  # Ensure it's unique\n",
        "            return code\n",
        "\n",
        "# Step 1: Update the ISO_TER1 values\n",
        "with arcpy.da.UpdateCursor(input_eez, ['ISO_TER1', 'TERRITORY1']) as cursor:\n",
        "    for row in cursor:\n",
        "        iso_name = row[0]\n",
        "        territory_name = row[1]\n",
        "\n",
        "        # Check if this ISO_TER1 value is empty or not valid\n",
        "        if not iso_name or len(iso_name) != 3 or not iso_name.isalpha():\n",
        "            # Generate a unique 3-letter code\n",
        "            unique_code = generate_unique_code(used_names)\n",
        "            row[0] = unique_code  # Update ISO_TER1 value\n",
        "            used_names.add(unique_code)  # Add to the set of used names\n",
        "\n",
        "        # If it is valid and unique, keep the original value\n",
        "        cursor.updateRow(row)\n",
        "\n",
        "print(\"✅ ISO_TER1 values have been updated to unique 3-letter names.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvvuTpYGWg4N",
        "outputId": "bc1b99df-77a0-424a-ff8c-7044e3fe01a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ISO_TER1 values updated: duplicates fixed, invalid values replaced.\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Set input dataset\n",
        "input_eez = \"EEZ\"\n",
        "\n",
        "# Track used ISO_TER1 values\n",
        "used_names = set()\n",
        "\n",
        "# Track duplicates: {ISO_TER1: [rows]}\n",
        "iso_to_rows = defaultdict(list)\n",
        "\n",
        "# Step 1: First Pass - Identify duplicates and invalid values\n",
        "with arcpy.da.UpdateCursor(input_eez, ['ISO_TER1', 'UNION']) as cursor:\n",
        "    for row in cursor:\n",
        "        iso_name = row[0]\n",
        "        territory_name = row[1]\n",
        "\n",
        "        # Store existing values for duplication checks\n",
        "        if iso_name and len(iso_name) == 3 and iso_name.isalpha():\n",
        "            if iso_name in used_names:\n",
        "                iso_to_rows[iso_name].append(row)  # Mark as duplicate\n",
        "            else:\n",
        "                used_names.add(iso_name)  # Add valid unique code\n",
        "        else:\n",
        "            iso_to_rows[\"INVALID\"].append(row)  # Mark invalid values\n",
        "\n",
        "# Function to generate a unique 3-letter code\n",
        "def generate_unique_code(prefix, existing_names):\n",
        "    while True:\n",
        "        # Generate a code using the first 2 letters of UNION + 1 random letter\n",
        "        if prefix and len(prefix) >= 2:\n",
        "            code = prefix[:2].upper() + random.choice(string.ascii_uppercase)\n",
        "        else:\n",
        "            code = ''.join(random.choices(string.ascii_uppercase, k=3))\n",
        "\n",
        "        if code not in existing_names:  # Ensure uniqueness\n",
        "            return code\n",
        "\n",
        "# Step 2: Second Pass - Fix duplicates and invalid values\n",
        "with arcpy.da.UpdateCursor(input_eez, ['ISO_TER1', 'UNION']) as cursor:\n",
        "    for row in cursor:\n",
        "        iso_name = row[0]\n",
        "        territory_name = row[1]\n",
        "\n",
        "        # If this row was marked as a duplicate or invalid, update it\n",
        "        if iso_name in iso_to_rows or iso_name == \"INVALID\":\n",
        "            prefix = territory_name[:2] if territory_name else \"\"\n",
        "            unique_code = generate_unique_code(prefix, used_names)\n",
        "            row[0] = unique_code\n",
        "            used_names.add(unique_code)\n",
        "\n",
        "        cursor.updateRow(row)\n",
        "\n",
        "print(\"✅ ISO_TER1 values updated: duplicates fixed, invalid values replaced.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiJCJsfnWg4O"
      },
      "source": [
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIurtSTgWg4O"
      },
      "source": [
        "### Test Using Smaller area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk3rqtX8Wg4P"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkKh0ixEWg4P",
        "outputId": "c17077a1-4d6c-4975-d83f-715b03a8ff83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Processing country: GRD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GRD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRD, replacing NEAR_FID reference.\n",
            "⏳ Processing country: MAF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MAF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAF, replacing NEAR_FID reference.\n",
            "⏳ Processing country: MTQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MTQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MTQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MTQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MTQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MTQ, replacing NEAR_FID reference.\n",
            " All geohazard data merged into D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_dist successfully!\n",
            "✅ All processing completed! Elapsed time: 1.3288746066667954 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "# Define paths\n",
        "project_folder = r\"D:\\ArcGISProjects\\GeohazardDB\"\n",
        "gdb_path = os.path.join(project_folder, \"GeohazardDB.gdb\")  # File Geodatabase\n",
        "\n",
        "# Initialize a list to store processed geohazard datasets\n",
        "ghz_list = []\n",
        "\n",
        "# Input datasets\n",
        "geohazard_layer = os.path.join(gdb_path, \"g84_Clip\")  # Geohazard dataset\n",
        "road_layer = os.path.join(gdb_path, \"grip_Clip\")  # Global road dataset\n",
        "country_layer = os.path.join(gdb_path, \"eez3\")  # Country boundaries\n",
        "\n",
        "# Check if GDB exists, otherwise create it\n",
        "if not arcpy.Exists(gdb_path):\n",
        "    arcpy.CreateFileGDB_management(project_folder, \"GeohazardDB.gdb\")\n",
        "\n",
        "# Iterate through each country\n",
        "with arcpy.da.SearchCursor(country_layer, [\"ISO_TER1\", \"SHAPE@\"]) as country_cursor:\n",
        "    for row in country_cursor:\n",
        "        country_code = row[0]  # Country code (e.g., THA, USA)\n",
        "        country_geometry = row[1]  # Country boundary geometry\n",
        "\n",
        "        print(f\"\\u23F3 Processing country: {country_code}...\")\n",
        "\n",
        "        # Define output names inside the GDB\n",
        "        ghz_clip = os.path.join(gdb_path, f\"ghz_{country_code}\")\n",
        "        road_clip = os.path.join(gdb_path, f\"road_{country_code}\")\n",
        "        near_output = os.path.join(gdb_path, f\"near_{country_code}\")\n",
        "\n",
        "        # ---- Step 1: Clip Geohazard Data ----\n",
        "        if arcpy.Exists(ghz_clip):\n",
        "            arcpy.Delete_management(ghz_clip)\n",
        "        try:\n",
        "            arcpy.Clip_analysis(geohazard_layer, country_geometry, ghz_clip)\n",
        "            print(f\"  \\u2705 Clipped geohazard layer: {ghz_clip}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  \\u274C Error clipping geohazard: {e}\")\n",
        "            continue  # Skip to next country if error occurs\n",
        "\n",
        "        # ---- Step 2: Clip Road Data ----\n",
        "        if arcpy.Exists(road_clip):\n",
        "            arcpy.Delete_management(road_clip)\n",
        "        try:\n",
        "            arcpy.Clip_analysis(road_layer, country_geometry, road_clip)\n",
        "            print(f\"  \\u2705 Clipped road layer: {road_clip}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  {chr(0x274C)} Error clipping roads: {e}\")\n",
        "            continue  # Skip to next country if error occurs\n",
        "\n",
        "        # ---- Step 3: Perform Near Analysis ----\n",
        "        if arcpy.Exists(near_output):\n",
        "            arcpy.Delete_management(near_output)\n",
        "        try:\n",
        "            arcpy.GenerateNearTable_analysis(\n",
        "                in_features=ghz_clip,\n",
        "                near_features=road_clip,\n",
        "                out_table=near_output,\n",
        "                search_radius=\"100000 Meters\",  # Keep it in 100 Km\n",
        "                location=\"LOCATION\",  # Include X, Y coordinates\n",
        "                angle=\"ANGLE\",\n",
        "                closest=\"CLOSEST\",\n",
        "                method=\"GEODESIC\"\n",
        "            )\n",
        "            print(f\"  \\u2705 Near analysis completed: {near_output}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  \\u274C Error in Near Analysis: {e}\")\n",
        "\n",
        "\n",
        "        # ---- Step 4: Add distance to geohazard ----\n",
        "        # Add \"distance\" field if it doesn't exist\n",
        "        if \"distance\" not in [f.name for f in arcpy.ListFields(ghz_clip)]:\n",
        "            arcpy.AddField_management(ghz_clip, \"distance\", \"DOUBLE\")\n",
        "\n",
        "        # Update \"distance\" field with NEAR_DIST from the near table\n",
        "        with arcpy.da.UpdateCursor(ghz_clip, [\"OBJECTID\", \"distance\"]) as ghz_cursor:\n",
        "            for ghz_row in ghz_cursor:\n",
        "                ghz_id = ghz_row[0]  # OBJECTID of ghz_XXX\n",
        "\n",
        "                # Find matching NEAR_DIST from the near table\n",
        "                with arcpy.da.SearchCursor(near_output, [\"IN_FID\", \"NEAR_DIST\"]) as near_cursor:\n",
        "                    for near_row in near_cursor:\n",
        "                        if near_row[0] == ghz_id:  # Match OBJECTID\n",
        "                            ghz_row[1] = near_row[1]  # Assign NEAR_DIST\n",
        "                            ghz_cursor.updateRow(ghz_row)\n",
        "                            break  # Stop once found\n",
        "\n",
        "        print(f\"\\u2705 NEAR_DIST added to {ghz_clip} as 'distance' field.\")\n",
        "\n",
        "        # Add \"HazardID\" field to near table if it doesn't exist\n",
        "        if \"HazardID\" not in [f.name for f in arcpy.ListFields(near_output)]:\n",
        "            arcpy.AddField_management(near_output, \"HazardID\", \"TEXT\")\n",
        "\n",
        "        # Since this uses \"CLOSEST\" method, so it will only take 1 closest disance,\n",
        "        # and discard the NEAR_FID as the 1:N will no longer needed. Instead it can be replaced with HazardID\n",
        "        # to obtain the relationship with the ghz dataset\n",
        "        # Use UpdateCursor to populate HazardID from ghz_XXX\n",
        "        with arcpy.da.UpdateCursor(near_output, [\"IN_FID\", \"HazardID\"]) as cursor:\n",
        "            for row in cursor:\n",
        "                # Fetch the corresponding HazardID from ghz_XXX\n",
        "                with arcpy.da.SearchCursor(ghz_clip, [\"OBJECTID\", \"HazardID\"]) as ghz_cursor:\n",
        "                    for ghz_row in ghz_cursor:\n",
        "                        if row[0] == ghz_row[0]:  # Match OBJECTID\n",
        "                            row[1] = ghz_row[1]  # Assign HazardID\n",
        "                            cursor.updateRow(row)\n",
        "                            break  # Exit loop once matched\n",
        "\n",
        "        print(f\"\\u2705 HazardID added to {near_output}, replacing NEAR_FID reference.\")\n",
        "\n",
        "        # Add processed dataset to list for final merge\n",
        "        ghz_list.append(ghz_clip)\n",
        "\n",
        "# Merge all processed ghz_XXX datasets into one: \"ghz_dist\"\n",
        "ghz_dist = os.path.join(gdb_path, \"ghz_dist\")\n",
        "\n",
        "if arcpy.Exists(ghz_dist):\n",
        "    arcpy.Delete_management(ghz_dist)  # Ensure a fresh start\n",
        "\n",
        "arcpy.Merge_management(ghz_list, ghz_dist)\n",
        "\n",
        "print(f\" All geohazard data merged into {ghz_dist} successfully!\")\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"\\u2705 All processing completed! Elapsed time: %s minutes\"%str(elapsed/60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efA7XdPyWg4P"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy0znauTWg4Q"
      },
      "source": [
        "# <h1 style=\"background-color:#d5f2e1; color: #bc6ee0;\">Clip and Near Analysis Including Outside EEZ</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgfZQ3e3Wg4Q"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "HYfvixqhWg4Q",
        "outputId": "fcdc1558-6fbe-425d-fff7-b8d95b631778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Processing country 1/328: JOR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 2/328: BDI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BDI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BDI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BDI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BDI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BDI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 3/328: URJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_URJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_URJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_URJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_URJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_URJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 4/328: LVA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LVA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LVA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LVA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LVA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LVA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 5/328: BDZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BDZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BDZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BDZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BDZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BDZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 6/328: BLR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BLR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BLR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BLR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BLR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BLR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 7/328: HUN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HUN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_HUN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HUN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HUN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HUN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 8/328: TJK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TJK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TJK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TJK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TJK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TJK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 9/328: SOD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SOD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SOD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SOD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SOD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SOD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 10/328: BHS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BHS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BHS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BHS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BHS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BHS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 11/328: COK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_COK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 12/328: ICH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ICH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ICH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ICH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ICH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ICH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 13/328: RUS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RUS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_RUS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RUS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RUS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RUS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 14/328: LTU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LTU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LTU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LTU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LTU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LTU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 15/328: ISR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ISR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ISR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ISR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ISR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ISR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 16/328: WLF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WLF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_WLF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WLF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WLF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WLF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 17/328: BRA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BRA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BRA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BRA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BRA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BRA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 18/328: KEN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KEN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KEN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KEN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KEN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KEN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 19/328: SOM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SOM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SOM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SOM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SOM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SOM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 20/328: COM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_COM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 21/328: BGD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BGD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BGD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BGD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BGD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BGD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 22/328: IRL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IRL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_IRL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IRL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IRL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IRL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 23/328: MHL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MHL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MHL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MHL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MHL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MHL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 24/328: MNE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MNE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MNE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MNE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MNE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MNE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 25/328: NZL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NZL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NZL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NZL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NZL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NZL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 26/328: SPM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SPM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SPM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SPM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SPM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SPM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 27/328: PRY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PRY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PRY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PRY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PRY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PRY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 28/328: SVK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SVK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SVK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SVK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SVK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SVK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 29/328: MKD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MKD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MKD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MKD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MKD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MKD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 30/328: PSE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PSE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PSE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PSE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PSE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PSE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 31/328: CMR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CMR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CMR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CMR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CMR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CMR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 32/328: ASK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ASK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ASK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ASK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ASK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ASK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 33/328: BIH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BIH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BIH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BIH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BIH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BIH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 34/328: ARG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ARG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ARG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ARG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ARG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ARG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 35/328: BEL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BEL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BEL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BEL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BEL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BEL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 36/328: RDA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RDA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_RDA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RDA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RDA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RDA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 37/328: OVN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 38/328: TKM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TKM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TKM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TKM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TKM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TKM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 39/328: KEK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KEK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KEK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KEK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KEK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KEK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 40/328: BGR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BGR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BGR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BGR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BGR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BGR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 41/328: CUW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CUW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CUW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CUW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CUW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CUW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 42/328: POL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_POL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_POL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_POL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_POL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_POL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 43/328: MEX...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MEX\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MEX\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MEX\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MEX as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MEX, replacing NEAR_FID reference.\n",
            "⏳ Processing country 44/328: JEY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JEY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JEY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JEY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JEY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JEY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 45/328: NIU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NIU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NIU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NIU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NIU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NIU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 46/328: VGB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VGB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VGB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VGB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VGB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VGB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 47/328: MLI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MLI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MLI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MLI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MLI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MLI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 48/328: LBY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LBY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LBY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LBY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LBY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LBY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 49/328: THA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_THA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_THA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_THA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_THA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_THA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 50/328: FJI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FJI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FJI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FJI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FJI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FJI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 51/328: NER...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NER\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NER\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NER\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NER as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NER, replacing NEAR_FID reference.\n",
            "⏳ Processing country 52/328: JOE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 53/328: LSO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LSO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LSO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LSO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LSO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LSO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 54/328: PYF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PYF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PYF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PYF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PYF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PYF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 55/328: LBR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LBR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LBR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LBR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LBR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LBR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 56/328: DMA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DMA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DMA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DMA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DMA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DMA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 57/328: MOZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MOZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MOZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MOZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MOZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MOZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 58/328: ETH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ETH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ETH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ETH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ETH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ETH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 59/328: UGA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UGA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UGA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UGA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UGA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UGA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 60/328: BVT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BVT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BVT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BVT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BVT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BVT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 61/328: JOF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 62/328: UBM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UBM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UBM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UBM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UBM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UBM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 63/328: PAJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PAJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 64/328: DNK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DNK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DNK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DNK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DNK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DNK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 65/328: RÉQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RÉQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_RÉQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RÉQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RÉQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RÉQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 66/328: CRI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CRI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CRI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CRI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CRI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CRI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 67/328: OMN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OMN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OMN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OMN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OMN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OMN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 68/328: CAW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CAW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CAW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CAW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CAW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CAW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 69/328: SAB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SAB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 70/328: SUR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SUR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SUR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SUR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SUR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SUR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 71/328: JAN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JAN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JAN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JAN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JAN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JAN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 72/328: PAK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PAK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 73/328: GIN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GIN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GIN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GIN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GIN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GIN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 74/328: SAU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SAU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 75/328: VEZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VEZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VEZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VEZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VEZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VEZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 76/328: GEO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GEO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GEO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GEO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GEO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GEO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 77/328: JAC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JAC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JAC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JAC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JAC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JAC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 78/328: SXM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SXM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SXM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SXM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SXM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SXM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 79/328: CUB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CUB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CUB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CUB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CUB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CUB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 80/328: VUT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VUT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VUT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VUT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VUT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VUT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 81/328: CHE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CHE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CHE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CHE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CHE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CHE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 82/328: QAE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QAE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_QAE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QAE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QAE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QAE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 83/328: ERI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ERI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ERI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ERI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ERI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ERI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 84/328: AMO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AMO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AMO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AMO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AMO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AMO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 85/328: SWE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SWE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SWE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SWE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SWE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SWE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 86/328: CHP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CHP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CHP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CHP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CHP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CHP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 87/328: SRZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SRZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SRZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SRZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SRZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SRZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 88/328: CHB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CHB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CHB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CHB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CHB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CHB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 89/328: GNQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GNQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GNQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GNQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GNQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GNQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 90/328: GRC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GRC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 91/328: ZMB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZMB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ZMB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZMB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZMB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZMB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 92/328: QAJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QAJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_QAJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QAJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QAJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QAJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 93/328: MDG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MDG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MDG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MDG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MDG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MDG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 94/328: SYC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SYC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SYC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SYC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SYC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SYC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 95/328: AUS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AUS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AUS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AUS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AUS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AUS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 96/328: ABW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ABW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ABW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ABW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ABW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ABW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 97/328: TON...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TON\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TON\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TON\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TON as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TON, replacing NEAR_FID reference.\n",
            "⏳ Processing country 98/328: SAH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SAH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 99/328: KHM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KHM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KHM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KHM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KHM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KHM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 100/328: NLD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NLD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NLD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NLD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NLD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NLD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 101/328: BAV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BAV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BAV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BAV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BAV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BAV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 102/328: FSM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FSM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FSM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FSM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FSM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FSM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 103/328: SMR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SMR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SMR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SMR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SMR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SMR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 104/328: SJK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SJK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SJK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SJK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SJK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SJK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 105/328: ZGK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZGK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ZGK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZGK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZGK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZGK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 106/328: MRT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MRT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MRT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MRT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MRT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MRT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 107/328: BEN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BEN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BEN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BEN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BEN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BEN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 108/328: BMU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BMU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BMU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BMU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BMU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BMU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 109/328: MVF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MVF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MVF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MVF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MVF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MVF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 110/328: LCA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LCA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LCA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LCA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LCA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LCA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 111/328: PHL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PHL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PHL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PHL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PHL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PHL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 112/328: PAR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PAR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 113/328: OVB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 114/328: NFK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NFK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NFK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NFK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NFK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NFK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 115/328: IND...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IND\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_IND\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IND\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IND as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IND, replacing NEAR_FID reference.\n",
            "⏳ Processing country 116/328: COD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_COD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 117/328: ZWE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZWE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ZWE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZWE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZWE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZWE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 118/328: SRB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SRB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SRB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SRB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SRB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SRB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 119/328: ASM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ASM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ASM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ASM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ASM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ASM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 120/328: UKR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UKR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UKR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UKR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UKR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UKR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 121/328: NCL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NCL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NCL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NCL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NCL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NCL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 122/328: GLP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GLP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GLP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GLP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GLP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GLP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 123/328: SLB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SLB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SLB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SLB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SLB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SLB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 124/328: NRU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NRU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NRU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NRU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NRU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NRU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 125/328: BOL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BOL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BOL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BOL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BOL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BOL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 126/328: AUT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AUT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AUT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AUT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AUT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AUT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 127/328: KGZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KGZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KGZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KGZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KGZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KGZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 128/328: ESP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ESP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ESP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ESP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ESP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ESP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 129/328: SYR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SYR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SYR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SYR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SYR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SYR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 130/328: JOK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 131/328: UAS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UAS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UAS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UAS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UAS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UAS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 132/328: TUV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TUV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TUV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TUV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TUV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TUV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 133/328: RJT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RJT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_RJT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RJT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RJT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RJT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 134/328: JOT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 135/328: SVU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SVU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SVU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SVU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SVU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SVU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 136/328: GIC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GIC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GIC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GIC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GIC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GIC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 137/328: SAZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SAZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 138/328: NPL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NPL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NPL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NPL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NPL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NPL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 139/328: TCD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TCD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TCD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TCD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TCD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TCD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 140/328: GUE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GUE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GUE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GUE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GUE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GUE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 141/328: EGD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EGD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_EGD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EGD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EGD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EGD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 142/328: SLE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SLE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SLE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SLE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SLE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SLE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 143/328: GRD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GRD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 144/328: STG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_STG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_STG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_STG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_STG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_STG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 145/328: FIN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FIN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FIN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FIN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FIN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FIN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 146/328: BFA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BFA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BFA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BFA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BFA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BFA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 147/328: MNG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MNG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MNG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MNG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MNG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MNG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 148/328: HTI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HTI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_HTI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HTI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HTI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HTI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 149/328: MUS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MUS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MUS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MUS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MUS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MUS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 150/328: ALB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ALB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ALB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ALB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ALB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ALB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 151/328: NOF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NOF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NOF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NOF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NOF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NOF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 152/328: TUR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TUR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TUR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TUR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TUR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TUR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 153/328: GGY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GGY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GGY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GGY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GGY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GGY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 154/328: LII...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LII\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LII\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LII\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LII as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LII, replacing NEAR_FID reference.\n",
            "⏳ Processing country 155/328: PRT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PRT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PRT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PRT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PRT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PRT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 156/328: CXR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CXR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CXR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CXR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CXR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CXR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 157/328: WSM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WSM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_WSM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WSM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WSM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WSM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 158/328: TTO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TTO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TTO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TTO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TTO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TTO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 159/328: CYM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CYM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CYM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CYM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CYM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CYM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 160/328: VAT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VAT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VAT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VAT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VAT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VAT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 161/328: UNW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UNW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UNW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UNW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UNW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UNW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 162/328: LAO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LAO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LAO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LAO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LAO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LAO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 163/328: MDA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MDA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MDA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MDA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MDA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MDA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 164/328: BTN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BTN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BTN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BTN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BTN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BTN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 165/328: SSD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SSD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SSD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SSD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SSD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SSD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 166/328: JOH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 167/328: JOD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 168/328: TLS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TLS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TLS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TLS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TLS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TLS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 169/328: JOG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 170/328: NGA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NGA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NGA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NGA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NGA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NGA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 171/328: WAW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WAW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_WAW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WAW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WAW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WAW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 172/328: OVX...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVX\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVX\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVX\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVX as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVX, replacing NEAR_FID reference.\n",
            "⏳ Processing country 173/328: VNM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VNM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VNM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VNM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VNM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VNM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 174/328: SIN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SIN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SIN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SIN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SIN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SIN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 175/328: ESH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ESH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ESH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ESH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ESH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ESH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 176/328: DLL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DLL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DLL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DLL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DLL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DLL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 177/328: TWN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TWN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TWN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TWN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TWN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TWN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 178/328: ITA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ITA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ITA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ITA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ITA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ITA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 179/328: PEG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PEG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PEG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PEG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PEG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PEG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 180/328: JOO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 181/328: GHA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GHA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GHA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GHA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GHA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GHA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 182/328: ARE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ARE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ARE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ARE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ARE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ARE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 183/328: MSR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MSR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MSR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MSR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MSR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MSR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 184/328: FLK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FLK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FLK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FLK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FLK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FLK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 185/328: IDN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IDN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_IDN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IDN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IDN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IDN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 186/328: PRK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PRK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PRK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PRK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PRK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PRK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 187/328: FRD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FRD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FRD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FRD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FRD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FRD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 188/328: MAY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MAY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 189/328: MAR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MAR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 190/328: SDN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SDN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SDN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SDN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SDN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SDN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 191/328: BAS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BAS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BAS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BAS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BAS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BAS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 192/328: RWN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RWN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_RWN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RWN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_RWN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_RWN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 193/328: MCO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MCO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MCO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MCO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MCO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MCO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 194/328: OVV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 195/328: LUX...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LUX\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LUX\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LUX\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LUX as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LUX, replacing NEAR_FID reference.\n",
            "⏳ Processing country 196/328: TUN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TUN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TUN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TUN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TUN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TUN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 197/328: BRN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BRN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BRN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BRN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BRN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BRN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 198/328: MNP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MNP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MNP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MNP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MNP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MNP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 199/328: DHK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DHK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DHK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DHK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DHK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DHK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 200/328: GDY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GDY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GDY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GDY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GDY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GDY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 201/328: TKL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TKL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TKL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TKL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TKL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TKL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 202/328: ARM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ARM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ARM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ARM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ARM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ARM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 203/328: EVZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EVZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_EVZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EVZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EVZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EVZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 204/328: BWA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BWA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BWA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BWA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BWA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BWA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 205/328: SLV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SLV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SLV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SLV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SLV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SLV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 206/328: QHB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QHB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_QHB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QHB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QHB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QHB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 207/328: ROU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ROU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ROU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ROU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ROU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ROU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 208/328: KWT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KWT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KWT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KWT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KWT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KWT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 209/328: GAB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GAB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GAB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GAB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GAB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GAB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 210/328: WLM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WLM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_WLM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WLM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_WLM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_WLM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 211/328: JOW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 212/328: AIA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AIA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AIA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AIA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AIA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AIA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 213/328: HMD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HMD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_HMD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HMD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HMD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HMD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 214/328: MAF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MAF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MAF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MAF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 215/328: COJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_COJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 216/328: CYP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CYP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CYP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CYP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CYP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CYP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 217/328: GUM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GUM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GUM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GUM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GUM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GUM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 218/328: GRL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GRL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GRL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GRL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 219/328: IMN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IMN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_IMN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IMN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IMN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IMN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 220/328: JOP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 221/328: UNM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UNM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UNM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UNM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UNM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UNM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 222/328: CCK...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CCK\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CCK\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CCK\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CCK as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CCK, replacing NEAR_FID reference.\n",
            "⏳ Processing country 223/328: ECR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ECR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ECR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ECR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ECR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ECR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 224/328: CIV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CIV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CIV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CIV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CIV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CIV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 225/328: NGL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NGL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NGL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NGL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NGL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NGL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 226/328: COG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_COG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 227/328: JAQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JAQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JAQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JAQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JAQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JAQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 228/328: AGO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AGO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AGO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AGO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AGO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AGO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 229/328: GTM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GTM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GTM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GTM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GTM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GTM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 230/328: CAF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CAF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CAF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CAF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CAF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CAF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 231/328: OKD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OKD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OKD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OKD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OKD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OKD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 232/328: YYJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_YYJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_YYJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_YYJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_YYJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_YYJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 233/328: BOF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BOF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BOF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BOF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BOF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BOF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 234/328: AZE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AZE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AZE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AZE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AZE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AZE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 235/328: COQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_COQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_COQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_COQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 236/328: BDY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BDY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BDY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BDY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BDY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BDY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 237/328: HOD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HOD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_HOD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HOD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HOD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HOD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 238/328: TRM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TRM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TRM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TRM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TRM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TRM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 239/328: CRC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CRC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CRC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CRC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CRC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CRC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 240/328: MWI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MWI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MWI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MWI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MWI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MWI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 241/328: TCA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TCA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TCA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TCA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TCA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TCA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 242/328: LKA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LKA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LKA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LKA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LKA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LKA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 243/328: SEF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SEF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SEF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SEF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SEF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SEF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 244/328: MTQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MTQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MTQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MTQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MTQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MTQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 245/328: QGI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QGI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_QGI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QGI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QGI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QGI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 246/328: MMR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MMR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MMR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MMR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MMR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MMR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 247/328: MDV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MDV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MDV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MDV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MDV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MDV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 248/328: UZB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UZB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_UZB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UZB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_UZB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_UZB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 249/328: JOU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 250/328: SWZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SWZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SWZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SWZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SWZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SWZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 251/328: DOJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DOJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DOJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DOJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DOJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DOJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 252/328: HOJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HOJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_HOJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HOJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HOJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HOJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 253/328: EMQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EMQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_EMQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EMQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EMQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EMQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 254/328: LBN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LBN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LBN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LBN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LBN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LBN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 255/328: BLM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BLM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BLM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BLM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BLM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BLM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 256/328: PUR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PUR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PUR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PUR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PUR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PUR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 257/328: QIB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QIB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_QIB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QIB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_QIB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_QIB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 258/328: MUJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MUJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MUJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MUJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MUJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MUJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 259/328: GIB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GIB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GIB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GIB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GIB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GIB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 260/328: JOL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 261/328: KNA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KNA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KNA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KNA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KNA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KNA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 262/328: JUW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JUW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JUW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JUW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JUW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JUW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 263/328: BHR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BHR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BHR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BHR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BHR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BHR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 264/328: PME...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PME\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PME\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PME\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PME as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PME, replacing NEAR_FID reference.\n",
            "⏳ Processing country 265/328: AND...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AND\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AND\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AND\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AND as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AND, replacing NEAR_FID reference.\n",
            "⏳ Processing country 266/328: CZE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CZE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CZE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CZE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CZE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CZE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 267/328: PHV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PHV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PHV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PHV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PHV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PHV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 268/328: NIC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NIC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NIC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NIC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NIC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NIC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 269/328: KAZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KAZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_KAZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KAZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_KAZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_KAZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 270/328: GNB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GNB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GNB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GNB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GNB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GNB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 271/328: OVZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 272/328: IRN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IRN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_IRN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IRN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IRN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IRN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 273/328: JPN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JPN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JPN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JPN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JPN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JPN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 274/328: YEM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_YEM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_YEM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_YEM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_YEM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_YEM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 275/328: SVN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SVN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SVN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SVN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SVN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SVN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 276/328: AFG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AFG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_AFG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AFG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_AFG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_AFG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 277/328: JUD...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JUD\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JUD\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JUD\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JUD as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JUD, replacing NEAR_FID reference.\n",
            "⏳ Processing country 278/328: TZA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TZA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TZA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TZA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TZA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TZA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 279/328: JOM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 280/328: PCN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PCN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PCN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PCN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PCN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PCN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 281/328: DEU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DEU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DEU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DEU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DEU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DEU, replacing NEAR_FID reference.\n",
            "⏳ Processing country 282/328: ISP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ISP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ISP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ISP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ISP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ISP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 283/328: JON...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JON\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JON\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JON\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JON as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JON, replacing NEAR_FID reference.\n",
            "⏳ Processing country 284/328: OVE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 285/328: GUF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GUF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GUF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GUF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GUF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GUF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 286/328: IRZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IRZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_IRZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IRZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_IRZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_IRZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 287/328: NAM...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NAM\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_NAM\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NAM\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_NAM as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_NAM, replacing NEAR_FID reference.\n",
            "⏳ Processing country 288/328: BEC...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BEC\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BEC\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BEC\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BEC as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BEC, replacing NEAR_FID reference.\n",
            "⏳ Processing country 289/328: ZAF...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZAF\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ZAF\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZAF\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ZAF as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ZAF, replacing NEAR_FID reference.\n",
            "⏳ Processing country 290/328: OGL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OGL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OGL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OGL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OGL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OGL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 291/328: EUO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EUO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_EUO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EUO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EUO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EUO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 292/328: JOV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 293/328: MLT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MLT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MLT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MLT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MLT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MLT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 294/328: SGS...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SGS\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SGS\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SGS\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SGS as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SGS, replacing NEAR_FID reference.\n",
            "⏳ Processing country 295/328: VCT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VCT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VCT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VCT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VCT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VCT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 296/328: OVA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 297/328: OVQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 298/328: PLW...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PLW\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PLW\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PLW\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PLW as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PLW, replacing NEAR_FID reference.\n",
            "⏳ Processing country 299/328: ATG...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ATG\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_ATG\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ATG\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_ATG as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_ATG, replacing NEAR_FID reference.\n",
            "⏳ Processing country 300/328: DJI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DJI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DJI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DJI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DJI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DJI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 301/328: SAN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SAN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SAN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SAN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 302/328: VIR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VIR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_VIR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VIR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_VIR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_VIR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 303/328: SGP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SGP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SGP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SGP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SGP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SGP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 304/328: JOI...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOI\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOI\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOI\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOI as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOI, replacing NEAR_FID reference.\n",
            "⏳ Processing country 305/328: CPV...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CPV\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CPV\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CPV\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CPV as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CPV, replacing NEAR_FID reference.\n",
            "⏳ Processing country 306/328: CSH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CSH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_CSH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CSH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_CSH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_CSH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 307/328: DZA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DZA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_DZA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DZA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_DZA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_DZA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 308/328: JOB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 309/328: JOZ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOZ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOZ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOZ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOZ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOZ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 310/328: EST...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EST\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_EST\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EST\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_EST as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_EST, replacing NEAR_FID reference.\n",
            "⏳ Processing country 311/328: TGO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TGO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_TGO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TGO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_TGO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_TGO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 312/328: MYT...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MYT\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MYT\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MYT\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_MYT as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_MYT, replacing NEAR_FID reference.\n",
            "⏳ Processing country 313/328: JOA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 314/328: GMB...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GMB\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_GMB\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GMB\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_GMB as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_GMB, replacing NEAR_FID reference.\n",
            "⏳ Processing country 315/328: PAN...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAN\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_PAN\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAN\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_PAN as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_PAN, replacing NEAR_FID reference.\n",
            "⏳ Processing country 316/328: OVH...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVH\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVH\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVH\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVH as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVH, replacing NEAR_FID reference.\n",
            "⏳ Processing country 317/328: JOY...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOY\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOY\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOY\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOY as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOY, replacing NEAR_FID reference.\n",
            "⏳ Processing country 318/328: JOX...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOX\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOX\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOX\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOX as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOX, replacing NEAR_FID reference.\n",
            "⏳ Processing country 319/328: HEJ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HEJ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_HEJ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HEJ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_HEJ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_HEJ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 320/328: BRR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BRR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_BRR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BRR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_BRR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_BRR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 321/328: FTR...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FTR\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FTR\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FTR\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FTR as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FTR, replacing NEAR_FID reference.\n",
            "⏳ Processing country 322/328: SNA...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SNA\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_SNA\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SNA\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_SNA as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_SNA, replacing NEAR_FID reference.\n",
            "⏳ Processing country 323/328: LIE...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LIE\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LIE\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LIE\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LIE as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LIE, replacing NEAR_FID reference.\n",
            "⏳ Processing country 324/328: OVP...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVP\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OVP\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVP\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OVP as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OVP, replacing NEAR_FID reference.\n",
            "⏳ Processing country 325/328: LPL...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LPL\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_LPL\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LPL\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_LPL as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_LPL, replacing NEAR_FID reference.\n",
            "⏳ Processing country 326/328: JOQ...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOQ\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_JOQ\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOQ\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_JOQ as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_JOQ, replacing NEAR_FID reference.\n",
            "⏳ Processing country 327/328: FAO...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FAO\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_FAO\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FAO\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_FAO as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_FAO, replacing NEAR_FID reference.\n",
            "⏳ Processing country 328/328: OQU...\n",
            "  ✅ Clipped geohazard layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OQU\n",
            "  ✅ Clipped road layer: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_OQU\n",
            "  ✅ Near analysis completed: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OQU\n",
            "✅ NEAR_DIST added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_OQU as 'distance' field.\n",
            "✅ HazardID added to D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\near_OQU, replacing NEAR_FID reference.\n",
            " All geohazard data merged into D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\ghz_dist successfully!\n",
            "✅ All near tables compiled into D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\compiled_near_table successfully!\n",
            "✅ Successfully created outside_eez feature class\n",
            "✅ Polylines created from compiled near table at D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\compiled_near_lines!\n",
            "✅ All processing completed! Elapsed time: 4628.1864107050005 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "# Define paths\n",
        "project_folder = r\"D:\\ArcGISProjects\\GeohazardDB\"\n",
        "gdb_path = os.path.join(project_folder, \"GeohazardDB.gdb\")  # File Geodatabase\n",
        "\n",
        "# Initialize lists to store processed geohazard datasets and near tables\n",
        "ghz_list = []\n",
        "near_tables = []\n",
        "outside_eez_list = []  # List to store datasets with points outside EEZ\n",
        "\n",
        "# Input datasets\n",
        "geohazard_layer = os.path.join(gdb_path, \"ghz84\")  # Geohazard dataset\n",
        "road_layer = os.path.join(gdb_path, \"roads\")  # Global road dataset\n",
        "country_layer = os.path.join(gdb_path, \"eez_country\")  # Country boundaries\n",
        "\n",
        "# Check if GDB exists, otherwise create it\n",
        "if not arcpy.Exists(gdb_path):\n",
        "    arcpy.CreateFileGDB_management(project_folder, \"GeohazardDB.gdb\")\n",
        "\n",
        "# Get total number of countries to process\n",
        "total_countries = int(arcpy.GetCount_management(country_layer)[0])\n",
        "\n",
        "# Iterate through each country\n",
        "with arcpy.da.SearchCursor(country_layer, [\"ISO_TER1\", \"SHAPE@\"]) as country_cursor:\n",
        "    for index, row in enumerate(country_cursor, start=1):\n",
        "        country_code = row[0]  # Country code (e.g., THA, USA)\n",
        "        country_geometry = row[1]  # Country boundary geometry\n",
        "\n",
        "        print(f\"\\u23F3 Processing country {index}/{total_countries}: {country_code}...\")\n",
        "\n",
        "        # Define output names inside the GDB\n",
        "        ghz_clip = os.path.join(gdb_path, f\"ghz_{country_code}\")\n",
        "        road_clip = os.path.join(gdb_path, f\"road_{country_code}\")\n",
        "        near_output = os.path.join(gdb_path, f\"near_{country_code}\")\n",
        "\n",
        "        # ---- Step 1: Clip Geohazard Data ----\n",
        "        if arcpy.Exists(ghz_clip):\n",
        "            arcpy.Delete_management(ghz_clip)\n",
        "        try:\n",
        "            arcpy.Clip_analysis(geohazard_layer, country_geometry, ghz_clip)\n",
        "            print(f\"  \\u2705 Clipped geohazard layer: {ghz_clip}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  \\u274C Error clipping geohazard: {e}\")\n",
        "            continue  # Skip to next country if error occurs\n",
        "\n",
        "        # ---- Step 2: Clip Road Data ----\n",
        "        if arcpy.Exists(road_clip):\n",
        "            arcpy.Delete_management(road_clip)\n",
        "        try:\n",
        "            arcpy.Clip_analysis(road_layer, country_geometry, road_clip)\n",
        "            print(f\"  \\u2705 Clipped road layer: {road_clip}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  {chr(0x274C)} Error clipping roads: {e}\")\n",
        "            continue  # Skip to next country if error occurs\n",
        "\n",
        "        # ---- Step 3: Perform Near Analysis ----\n",
        "        if arcpy.Exists(near_output):\n",
        "            arcpy.Delete_management(near_output)\n",
        "        try:\n",
        "            arcpy.GenerateNearTable_analysis(\n",
        "                in_features=ghz_clip,\n",
        "                near_features=road_clip,\n",
        "                out_table=near_output,\n",
        "                search_radius=\"\",  # No search radius\n",
        "                location=\"LOCATION\",  # Include X, Y coordinates\n",
        "                angle=\"ANGLE\",\n",
        "                closest=\"CLOSEST\",\n",
        "                method=\"GEODESIC\"\n",
        "            )\n",
        "            print(f\"  \\u2705 Near analysis completed: {near_output}\")\n",
        "            near_tables.append(near_output)  # Store near table\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  \\u274C Error in Near Analysis: {e}\")\n",
        "\n",
        "        # ---- Step 4: Add distance to geohazard ----\n",
        "        # Add \"distance\" field if it doesn't exist\n",
        "        if \"distance\" not in [f.name for f in arcpy.ListFields(ghz_clip)]:\n",
        "            arcpy.AddField_management(ghz_clip, \"distance\", \"DOUBLE\")\n",
        "\n",
        "        # Update \"distance\" field with NEAR_DIST from the near table\n",
        "        with arcpy.da.UpdateCursor(ghz_clip, [\"OBJECTID\", \"distance\"]) as ghz_cursor:\n",
        "            for ghz_row in ghz_cursor:\n",
        "                ghz_id = ghz_row[0]  # OBJECTID of ghz_XXX\n",
        "\n",
        "                # Find matching NEAR_DIST from the near table\n",
        "                found_match = False\n",
        "                with arcpy.da.SearchCursor(near_output, [\"IN_FID\", \"NEAR_DIST\"]) as near_cursor:\n",
        "                    for near_row in near_cursor:\n",
        "                        if near_row[0] == ghz_id:  # Match OBJECTID\n",
        "                            ghz_row[1] = near_row[1]  # Assign NEAR_DIST\n",
        "                            ghz_cursor.updateRow(ghz_row)\n",
        "                            found_match = True\n",
        "                            break  # Stop once found\n",
        "\n",
        "                if not found_match:  # If no match found, add to outside_eez list\n",
        "                    outside_eez_list.append(ghz_clip)\n",
        "\n",
        "        print(f\"\\u2705 NEAR_DIST added to {ghz_clip} as 'distance' field.\")\n",
        "\n",
        "        # Add \"HazardID\" field to near table if it doesn't exist\n",
        "        if \"HazardID\" not in [f.name for f in arcpy.ListFields(near_output)]:\n",
        "            arcpy.AddField_management(near_output, \"HazardID\", \"TEXT\")\n",
        "\n",
        "        # Use UpdateCursor to populate HazardID from ghz_XXX\n",
        "        with arcpy.da.UpdateCursor(near_output, [\"IN_FID\", \"HazardID\"]) as cursor:\n",
        "            for row in cursor:\n",
        "                # Fetch the corresponding HazardID from ghz_XXX\n",
        "                with arcpy.da.SearchCursor(ghz_clip, [\"OBJECTID\", \"HazardID\"]) as ghz_cursor:\n",
        "                    for ghz_row in ghz_cursor:\n",
        "                        if row[0] == ghz_row[0]:  # Match OBJECTID\n",
        "                            row[1] = ghz_row[1]  # Assign HazardID\n",
        "                            cursor.updateRow(row)\n",
        "                            break  # Exit loop once matched\n",
        "\n",
        "        print(f\"\\u2705 HazardID added to {near_output}, replacing NEAR_FID reference.\")\n",
        "\n",
        "        # Add processed dataset to list for final merge\n",
        "        ghz_list.append(ghz_clip)\n",
        "\n",
        "# Merge all processed ghz_XXX datasets into one: \"ghz_dist\"\n",
        "ghz_dist = os.path.join(gdb_path, \"ghz_dist\")\n",
        "\n",
        "if arcpy.Exists(ghz_dist):\n",
        "    arcpy.Delete_management(ghz_dist)  # Ensure a fresh start\n",
        "\n",
        "arcpy.Merge_management(ghz_list, ghz_dist)\n",
        "\n",
        "print(f\" All geohazard data merged into {ghz_dist} successfully!\")\n",
        "\n",
        "# ---- Step 5: Compile all near tables into one ----\n",
        "compiled_near_table = os.path.join(gdb_path, \"compiled_near_table\")\n",
        "if arcpy.Exists(compiled_near_table):\n",
        "    arcpy.Delete_management(compiled_near_table)\n",
        "\n",
        "# Create empty table to store results\n",
        "arcpy.CreateTable_management(gdb_path, \"compiled_near_table\")\n",
        "arcpy.AddField_management(compiled_near_table, \"FROM_X\", \"DOUBLE\")\n",
        "arcpy.AddField_management(compiled_near_table, \"FROM_Y\", \"DOUBLE\")\n",
        "arcpy.AddField_management(compiled_near_table, \"NEAR_X\", \"DOUBLE\")\n",
        "arcpy.AddField_management(compiled_near_table, \"NEAR_Y\", \"DOUBLE\")\n",
        "arcpy.AddField_management(compiled_near_table, \"NEAR_FID\", \"LONG\")\n",
        "arcpy.AddField_management(compiled_near_table, \"HazardID\", \"TEXT\")\n",
        "\n",
        "# Insert cursor for compiled near table\n",
        "with arcpy.da.InsertCursor(compiled_near_table, [\"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\", \"NEAR_FID\", \"HazardID\"]) as insert_cursor:\n",
        "    for near_table in near_tables:\n",
        "        with arcpy.da.SearchCursor(near_table, [\"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\", \"NEAR_FID\", \"HazardID\"]) as cursor:\n",
        "            for row in cursor:\n",
        "                insert_cursor.insertRow(row)\n",
        "\n",
        "print(f\"\\u270 All near tables compiled into {compiled_near_table} successfully!\")\n",
        "\n",
        "# ---- Step 6: Handle points outside EEZ ----\n",
        "outside_eez_output = os.path.join(gdb_path, \"outside_eez\")\n",
        "\n",
        "# Try deleting the feature class if it exists (avoid locking issues)\n",
        "if arcpy.Exists(outside_eez_output):\n",
        "    try:\n",
        "        arcpy.Delete_management(outside_eez_output)\n",
        "        print(f\"\\u270 Deleted existing {outside_eez_output}\")\n",
        "    except Exception as e:\n",
        "        print(f\"&#9888 Error deleting {outside_eez_output}: {e}\")\n",
        "        time.sleep(2)  # Wait a bit and retry\n",
        "        arcpy.Delete_management(outside_eez_output)\n",
        "\n",
        "# Get all field names from geohazard_layer (excluding OBJECTID & Shape)\n",
        "fields = [f.name for f in arcpy.ListFields(geohazard_layer) if f.type not in (\"OID\", \"Geometry\")]\n",
        "fields.insert(0, \"SHAPE@\")  # Ensure geometry is included\n",
        "\n",
        "# Create a new feature class with the same schema\n",
        "try:\n",
        "    arcpy.CreateFeatureclass_management(\n",
        "        gdb_path, \"outside_eez\", \"POINT\",\n",
        "        template=geohazard_layer,  # Preserve schema\n",
        "        spatial_reference=arcpy.Describe(geohazard_layer).spatialReference\n",
        "    )\n",
        "    print(\"\\u270 Successfully created outside_eez feature class\")\n",
        "except Exception as e:\n",
        "    print(f\"\\u274C Failed to create outside_eez: {e}\")\n",
        "\n",
        "# ---- Step 7: Create Polyline Feature Class from Compiled Near Table ----\n",
        "polyline_output = os.path.join(gdb_path, \"compiled_near_lines\")\n",
        "if arcpy.Exists(polyline_output):\n",
        "    arcpy.Delete_management(polyline_output)\n",
        "\n",
        "# Use XY To Line tool to create lines from compiled near table\n",
        "arcpy.XYToLine_management(\n",
        "    compiled_near_table,\n",
        "    polyline_output,\n",
        "    \"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\",\n",
        "    \"\",  # Optional Line ID field\n",
        ")\n",
        "\n",
        "print(f\"\\u270 Polylines created from compiled near table at {polyline_output}!\")\n",
        "\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"\\u2705 All processing completed! Elapsed time: %s minutes\" % str(elapsed / 60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nTxUh7MWg4R",
        "outputId": "6b41cf64-d076-4081-ed3e-8ec747ce7ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Deleted existing D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\outside_eez\n",
            "✅ Successfully created outside_eez feature class\n"
          ]
        }
      ],
      "source": [
        "# ---- Step 6: Handle points outside EEZ ----\n",
        "outside_eez_output = os.path.join(gdb_path, \"outside_eez\")\n",
        "\n",
        "# Try deleting the feature class if it exists (avoid locking issues)\n",
        "if arcpy.Exists(outside_eez_output):\n",
        "    try:\n",
        "        arcpy.Delete_management(outside_eez_output)\n",
        "        print(f\"✅ Deleted existing {outside_eez_output}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error deleting {outside_eez_output}: {e}\")\n",
        "        time.sleep(2)  # Wait a bit and retry\n",
        "        arcpy.Delete_management(outside_eez_output)\n",
        "\n",
        "# Get all field names from geohazard_layer (excluding OBJECTID & Shape)\n",
        "fields = [f.name for f in arcpy.ListFields(geohazard_layer) if f.type not in (\"OID\", \"Geometry\")]\n",
        "fields.insert(0, \"SHAPE@\")  # Ensure geometry is included\n",
        "\n",
        "# Create a new feature class with the same schema\n",
        "try:\n",
        "    arcpy.CreateFeatureclass_management(\n",
        "        gdb_path, \"outside_eez\", \"POINT\",\n",
        "        template=geohazard_layer,  # Preserve schema\n",
        "        spatial_reference=arcpy.Describe(geohazard_layer).spatialReference\n",
        "    )\n",
        "    print(\"✅ Successfully created outside_eez feature class\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to create outside_eez: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbzqRsCUWg4S",
        "outputId": "fbcffbc9-c863-49af-f303-d586dc4c0955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Polylines created from compiled near table at D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\compiled_near_lines!\n"
          ]
        }
      ],
      "source": [
        "# ---- Step 7: Create Polyline Feature Class from Compiled Near Table ----\n",
        "polyline_output = os.path.join(gdb_path, \"compiled_near_lines\")\n",
        "if arcpy.Exists(polyline_output):\n",
        "    arcpy.Delete_management(polyline_output)\n",
        "\n",
        "# Use XY To Line tool to create lines from compiled near table\n",
        "arcpy.XYToLine_management(\n",
        "    compiled_near_table,\n",
        "    polyline_output,\n",
        "    \"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\",\n",
        "    \"\",  # Optional Line ID field\n",
        ")\n",
        "\n",
        "print(f\"✅ Polylines created from compiled near table at {polyline_output}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJi_b929Wg4S",
        "outputId": "698058cb-6b60-48f2-8e16-82c30f19d4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processing THA ---\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_THA\n",
            "  ✅ XY to Point completed: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_points_THA\n",
            "\n",
            "--- Processing IDN ---\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IDN\n",
            "  ✅ XY to Point completed: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_points_IDN\n",
            "\n",
            "--- Processing JPN ---\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JPN\n",
            "  ✅ XY to Point completed: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_points_JPN\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Paths\n",
        "source_gdb = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"\n",
        "output_gdb = r\"D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\"\n",
        "\n",
        "# Make sure output GDB exists\n",
        "if not arcpy.Exists(output_gdb):\n",
        "    arcpy.CreateFileGDB_management(os.path.dirname(output_gdb), os.path.basename(output_gdb))\n",
        "\n",
        "# Example test country codes — replace or expand this list as needed\n",
        "test_country_codes = [\"THA\", \"IDN\", \"JPN\"]\n",
        "\n",
        "for country_code in test_country_codes:\n",
        "    ghz_fc = os.path.join(source_gdb, f\"ghz_{country_code}\")\n",
        "    road_fc = os.path.join(source_gdb, f\"road_{country_code}\")\n",
        "    near_table = os.path.join(output_gdb, f\"near_{country_code}\")\n",
        "    point_output = os.path.join(output_gdb, f\"near_points_{country_code}\")\n",
        "\n",
        "    print(f\"\\n--- Processing {country_code} ---\")\n",
        "\n",
        "    # Check if input features exist\n",
        "    if not arcpy.Exists(ghz_fc) or not arcpy.Exists(road_fc):\n",
        "        print(f\"  ⛔ Skipped: Missing clipped layers for {country_code}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Step 1: Generate Near Table\n",
        "        if arcpy.Exists(near_table):\n",
        "            arcpy.Delete_management(near_table)\n",
        "        arcpy.GenerateNearTable_analysis(\n",
        "            in_features=ghz_fc,\n",
        "            near_features=road_fc,\n",
        "            out_table=near_table,\n",
        "            location=\"LOCATION\",\n",
        "            angle=\"ANGLE\",\n",
        "            closest=\"CLOSEST\",\n",
        "            method=\"GEODESIC\"\n",
        "        )\n",
        "        print(f\"  ✅ Near table created: {near_table}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error generating near table: {e}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Step 2: Convert XY to Point\n",
        "        if arcpy.Exists(point_output):\n",
        "            arcpy.Delete_management(point_output)\n",
        "        arcpy.XYTableToPoint_management(\n",
        "            in_table=near_table,\n",
        "            out_feature_class=point_output,\n",
        "            x_field=\"NEAR_X\",\n",
        "            y_field=\"NEAR_Y\",\n",
        "            coordinate_system=arcpy.Describe(ghz_fc).spatialReference\n",
        "        )\n",
        "        print(f\"  ✅ XY to Point completed: {point_output}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error converting to point: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBSUyFf6Wg4S",
        "outputId": "e2113d97-ea2e-41fa-827c-a32316c6970c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🍳 Processing JOR...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOR\n",
            "  ❌ Error appending rows for JOR: Cannot find field 'HazardID'\n",
            "🍳 Processing BDI...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BDI\n",
            "  ❌ Error appending rows for BDI: Cannot find field 'HazardID'\n",
            "🍳 Processing URJ...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_URJ\n",
            "  ❌ Error appending rows for URJ: Cannot find field 'HazardID'\n",
            "🍳 Processing LVA...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LVA\n",
            "  ❌ Error appending rows for LVA: Cannot find field 'HazardID'\n",
            "🍳 Processing BDZ...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BDZ\n",
            "  ❌ Error appending rows for BDZ: Cannot find field 'HazardID'\n",
            "🍳 Processing BLR...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BLR\n",
            "  ❌ Error appending rows for BLR: Cannot find field 'HazardID'\n",
            "🍳 Processing HUN...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HUN\n",
            "  ❌ Error appending rows for HUN: Cannot find field 'HazardID'\n",
            "🍳 Processing TJK...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TJK\n",
            "  ❌ Error appending rows for TJK: Cannot find field 'HazardID'\n",
            "🍳 Processing SOD...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SOD\n",
            "  ❌ Error appending rows for SOD: Cannot find field 'HazardID'\n",
            "🍳 Processing BHS...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BHS\n",
            "  ❌ Error appending rows for BHS: Cannot find field 'HazardID'\n",
            "🍳 Processing COK...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COK\n",
            "  ❌ Error appending rows for COK: Cannot find field 'HazardID'\n",
            "🍳 Processing ICH...\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "# Paths\n",
        "source_gdb = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"\n",
        "output_gdb = r\"D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\"\n",
        "\n",
        "# Field schema for compiled table\n",
        "fields = [\n",
        "    (\"FROM_X\", \"DOUBLE\"),\n",
        "    (\"FROM_Y\", \"DOUBLE\"),\n",
        "    (\"NEAR_X\", \"DOUBLE\"),\n",
        "    (\"NEAR_Y\", \"DOUBLE\"),\n",
        "    (\"NEAR_FID\", \"LONG\"),\n",
        "    (\"HazardID\", \"TEXT\")\n",
        "]\n",
        "\n",
        "# Create output GDB if needed\n",
        "if not arcpy.Exists(output_gdb):\n",
        "    arcpy.CreateFileGDB_management(os.path.dirname(output_gdb), os.path.basename(output_gdb))\n",
        "\n",
        "# Prepare compiled near table\n",
        "compiled_table = os.path.join(output_gdb, \"compiled_near_table\")\n",
        "if arcpy.Exists(compiled_table):\n",
        "    arcpy.Delete_management(compiled_table)\n",
        "arcpy.CreateTable_management(output_gdb, \"compiled_near_table\")\n",
        "for name, ftype in fields:\n",
        "    arcpy.AddField_management(compiled_table, name, ftype)\n",
        "\n",
        "# Load all country codes from EEZ feature class\n",
        "eez_fc = os.path.join(source_gdb, \"eez_country\")\n",
        "country_codes = [row[0] for row in arcpy.da.SearchCursor(eez_fc, [\"ISO_TER1\"])]\n",
        "\n",
        "# Loop through all countries\n",
        "for code in country_codes:\n",
        "    ghz_fc = os.path.join(source_gdb, f\"ghz_{code}\")\n",
        "    road_fc = os.path.join(source_gdb, f\"road_{code}\")\n",
        "    near_table = os.path.join(output_gdb, f\"near_{code}\")\n",
        "\n",
        "    print(f\"\\U0001f373 Processing {code}...\")\n",
        "\n",
        "    if not arcpy.Exists(ghz_fc) or not arcpy.Exists(road_fc):\n",
        "        print(f\"  ⛔ Missing input for {code}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Generate Near Table\n",
        "        if arcpy.Exists(near_table):\n",
        "            arcpy.Delete_management(near_table)\n",
        "        arcpy.GenerateNearTable_analysis(\n",
        "            in_features=ghz_fc,\n",
        "            near_features=road_fc,\n",
        "            out_table=near_table,\n",
        "            location=\"LOCATION\",\n",
        "            angle=\"ANGLE\",\n",
        "            closest=\"CLOSEST\",\n",
        "            method=\"GEODESIC\"\n",
        "        )\n",
        "        print(f\"  ✅ Near table created: {near_table}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error generating near table for {code}: {e}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Append rows to compiled table\n",
        "        with arcpy.da.InsertCursor(compiled_table, [f[0] for f in fields]) as insert_cursor:\n",
        "            with arcpy.da.SearchCursor(near_table, [f[0] for f in fields]) as read_cursor:\n",
        "                for row in read_cursor:\n",
        "                    insert_cursor.insertRow(row)\n",
        "        print(f\"  ➕ Appended {code} to compiled table.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error appending rows for {code}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Final step: XY To Line from compiled table\n",
        "polyline_output = os.path.join(output_gdb, \"compiled_near_lines\")\n",
        "if arcpy.Exists(polyline_output):\n",
        "    arcpy.Delete_management(polyline_output)\n",
        "\n",
        "try:\n",
        "    arcpy.XYToLine_management(\n",
        "        in_table=compiled_table,\n",
        "        out_feature_class=polyline_output,\n",
        "        startx_field=\"FROM_X\",\n",
        "        starty_field=\"FROM_Y\",\n",
        "        endx_field=\"NEAR_X\",\n",
        "        endy_field=\"NEAR_Y\",\n",
        "        line_type=\"GEODESIC\"\n",
        "    )\n",
        "    print(f\"\\n✅ Global polyline layer created: {polyline_output}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error creating polyline layer: {e}\")\n",
        "\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"\\u2705 All processing completed! Elapsed time: %s minutes\" % str(elapsed / 60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frdjHOm3Wg4T",
        "outputId": "da6a14a7-4d2f-4e7b-bcfe-1c4f3e1cee62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ length_m field populated with geodesic length in meters.\n"
          ]
        }
      ],
      "source": [
        "compiled_lines = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\compiled_near_lines\"\n",
        "\n",
        "# Add new field for length in meters\n",
        "if \"length_m\" not in [f.name for f in arcpy.ListFields(compiled_lines)]:\n",
        "    arcpy.AddField_management(compiled_lines, \"length_m\", \"DOUBLE\")\n",
        "\n",
        "# Calculate geodesic length in meters\n",
        "arcpy.CalculateGeometryAttributes_management(\n",
        "    in_features=compiled_lines,\n",
        "    geometry_property=[[\"distance_m\", \"LENGTH_GEODESIC\"]],\n",
        "    length_unit=\"METERS\"\n",
        ")\n",
        "print(\"✅ length_m field populated with geodesic length in meters.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpFjUnJhWg4T",
        "outputId": "df8f04a9-7fb1-4320-d7c0-90426c05d4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ HazardID injected into compiled_near_lines.\n"
          ]
        }
      ],
      "source": [
        "compiled_table = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\compiled_near_table\"\n",
        "arcpy.JoinField_management(\n",
        "    in_data=compiled_lines,\n",
        "    in_field=\"OID\",\n",
        "    join_table=compiled_table,\n",
        "    join_field=\"OBJECTID\",  # the join key\n",
        "    fields=[\"HazardID\"]\n",
        ")\n",
        "print(\"✅ HazardID injected into compiled_near_lines.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33WqQAuSWg4U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doWpWSCCWg4U"
      },
      "source": [
        "# Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJKgTK_jWg4U",
        "outputId": "2f677e0d-e4e8-4948-b46a-9a39ba733417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1938350 entries, 0 to 1938349\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   travel_time            float64\n",
            " 9   cpm_total_time         float64\n",
            "dtypes: float64(8), int64(1), object(1)\n",
            "memory usage: 147.9+ MB\n"
          ]
        }
      ],
      "source": [
        "ghz_pap = pd.read_csv(r\"D:\\NDIS_Database\\ghz_paper.csv\")\n",
        "ghz_pap.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "nNfa0I1yWg4V",
        "outputId": "27660bfe-f50c-4292-ab71-7cee006448d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Total features: 1938350\n",
            "⏳ Processing chunk 1 to 10000\n",
            "⚠️ High population in chunk 1-10000: 23,881,692\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1_10000.csv\n",
            "✅ Chunk 1 to 10000 processed.\n",
            "⏳ Processing chunk 10001 to 20000\n",
            "⚠️ High population in chunk 10001-20000: 20,724,284\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_10001_20000.csv\n",
            "✅ Chunk 10001 to 20000 processed.\n",
            "⏳ Processing chunk 20001 to 30000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_20001_30000.csv\n",
            "✅ Chunk 20001 to 30000 processed.\n",
            "⏳ Processing chunk 30001 to 40000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_30001_40000.csv\n",
            "✅ Chunk 30001 to 40000 processed.\n",
            "⏳ Processing chunk 40001 to 50000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_40001_50000.csv\n",
            "✅ Chunk 40001 to 50000 processed.\n",
            "⏳ Processing chunk 50001 to 60000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_50001_60000.csv\n",
            "✅ Chunk 50001 to 60000 processed.\n",
            "⏳ Processing chunk 60001 to 70000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_60001_70000.csv\n",
            "✅ Chunk 60001 to 70000 processed.\n",
            "⏳ Processing chunk 70001 to 80000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_70001_80000.csv\n",
            "✅ Chunk 70001 to 80000 processed.\n",
            "⏳ Processing chunk 80001 to 90000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_80001_90000.csv\n",
            "✅ Chunk 80001 to 90000 processed.\n",
            "⏳ Processing chunk 90001 to 100000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_90001_100000.csv\n",
            "✅ Chunk 90001 to 100000 processed.\n",
            "⏳ Processing chunk 100001 to 110000\n",
            "⚠️ High population in chunk 100001-110000: 20,752,668\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_100001_110000.csv\n",
            "✅ Chunk 100001 to 110000 processed.\n",
            "⏳ Processing chunk 110001 to 120000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_110001_120000.csv\n",
            "✅ Chunk 110001 to 120000 processed.\n",
            "⏳ Processing chunk 120001 to 130000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_120001_130000.csv\n",
            "✅ Chunk 120001 to 130000 processed.\n",
            "⏳ Processing chunk 130001 to 140000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_130001_140000.csv\n",
            "✅ Chunk 130001 to 140000 processed.\n",
            "⏳ Processing chunk 140001 to 150000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_140001_150000.csv\n",
            "✅ Chunk 140001 to 150000 processed.\n",
            "⏳ Processing chunk 150001 to 160000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_150001_160000.csv\n",
            "✅ Chunk 150001 to 160000 processed.\n",
            "⏳ Processing chunk 160001 to 170000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_160001_170000.csv\n",
            "✅ Chunk 160001 to 170000 processed.\n",
            "⏳ Processing chunk 170001 to 180000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_170001_180000.csv\n",
            "✅ Chunk 170001 to 180000 processed.\n",
            "⏳ Processing chunk 180001 to 190000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_180001_190000.csv\n",
            "✅ Chunk 180001 to 190000 processed.\n",
            "⏳ Processing chunk 190001 to 200000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_190001_200000.csv\n",
            "✅ Chunk 190001 to 200000 processed.\n",
            "⏳ Processing chunk 200001 to 210000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_200001_210000.csv\n",
            "✅ Chunk 200001 to 210000 processed.\n",
            "⏳ Processing chunk 210001 to 220000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_210001_220000.csv\n",
            "✅ Chunk 210001 to 220000 processed.\n",
            "⏳ Processing chunk 220001 to 230000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_220001_230000.csv\n",
            "✅ Chunk 220001 to 230000 processed.\n",
            "⏳ Processing chunk 230001 to 240000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_230001_240000.csv\n",
            "✅ Chunk 230001 to 240000 processed.\n",
            "⏳ Processing chunk 240001 to 250000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_240001_250000.csv\n",
            "✅ Chunk 240001 to 250000 processed.\n",
            "⏳ Processing chunk 250001 to 260000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_250001_260000.csv\n",
            "✅ Chunk 250001 to 260000 processed.\n",
            "⏳ Processing chunk 260001 to 270000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_260001_270000.csv\n",
            "✅ Chunk 260001 to 270000 processed.\n",
            "⏳ Processing chunk 270001 to 280000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_270001_280000.csv\n",
            "✅ Chunk 270001 to 280000 processed.\n",
            "⏳ Processing chunk 280001 to 290000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_280001_290000.csv\n",
            "✅ Chunk 280001 to 290000 processed.\n",
            "⏳ Processing chunk 290001 to 300000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_290001_300000.csv\n",
            "✅ Chunk 290001 to 300000 processed.\n",
            "⏳ Processing chunk 300001 to 310000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_300001_310000.csv\n",
            "✅ Chunk 300001 to 310000 processed.\n",
            "⏳ Processing chunk 310001 to 320000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_310001_320000.csv\n",
            "✅ Chunk 310001 to 320000 processed.\n",
            "⏳ Processing chunk 320001 to 330000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_320001_330000.csv\n",
            "✅ Chunk 320001 to 330000 processed.\n",
            "⏳ Processing chunk 330001 to 340000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_330001_340000.csv\n",
            "✅ Chunk 330001 to 340000 processed.\n",
            "⏳ Processing chunk 340001 to 350000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_340001_350000.csv\n",
            "✅ Chunk 340001 to 350000 processed.\n",
            "⏳ Processing chunk 350001 to 360000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_350001_360000.csv\n",
            "✅ Chunk 350001 to 360000 processed.\n",
            "⏳ Processing chunk 360001 to 370000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_360001_370000.csv\n",
            "✅ Chunk 360001 to 370000 processed.\n",
            "⏳ Processing chunk 370001 to 380000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_370001_380000.csv\n",
            "✅ Chunk 370001 to 380000 processed.\n",
            "⏳ Processing chunk 380001 to 390000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_380001_390000.csv\n",
            "✅ Chunk 380001 to 390000 processed.\n",
            "⏳ Processing chunk 390001 to 400000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_390001_400000.csv\n",
            "✅ Chunk 390001 to 400000 processed.\n",
            "⏳ Processing chunk 400001 to 410000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_400001_410000.csv\n",
            "✅ Chunk 400001 to 410000 processed.\n",
            "⏳ Processing chunk 410001 to 420000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_410001_420000.csv\n",
            "✅ Chunk 410001 to 420000 processed.\n",
            "⏳ Processing chunk 420001 to 430000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_420001_430000.csv\n",
            "✅ Chunk 420001 to 430000 processed.\n",
            "⏳ Processing chunk 430001 to 440000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_430001_440000.csv\n",
            "✅ Chunk 430001 to 440000 processed.\n",
            "⏳ Processing chunk 440001 to 450000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_440001_450000.csv\n",
            "✅ Chunk 440001 to 450000 processed.\n",
            "⏳ Processing chunk 450001 to 460000\n",
            "⚠️ High population in chunk 450001-460000: 20,561,176\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_450001_460000.csv\n",
            "✅ Chunk 450001 to 460000 processed.\n",
            "⏳ Processing chunk 460001 to 470000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_460001_470000.csv\n",
            "✅ Chunk 460001 to 470000 processed.\n",
            "⏳ Processing chunk 470001 to 480000\n",
            "⚠️ High population in chunk 470001-480000: 20,416,268\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_470001_480000.csv\n",
            "✅ Chunk 470001 to 480000 processed.\n",
            "⏳ Processing chunk 480001 to 490000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_480001_490000.csv\n",
            "✅ Chunk 480001 to 490000 processed.\n",
            "⏳ Processing chunk 490001 to 500000\n",
            "⚠️ High population in chunk 490001-500000: 22,027,032\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_490001_500000.csv\n",
            "✅ Chunk 490001 to 500000 processed.\n",
            "⏳ Processing chunk 500001 to 510000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_500001_510000.csv\n",
            "✅ Chunk 500001 to 510000 processed.\n",
            "⏳ Processing chunk 510001 to 520000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_510001_520000.csv\n",
            "✅ Chunk 510001 to 520000 processed.\n",
            "⏳ Processing chunk 520001 to 530000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_520001_530000.csv\n",
            "✅ Chunk 520001 to 530000 processed.\n",
            "⏳ Processing chunk 530001 to 540000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_530001_540000.csv\n",
            "✅ Chunk 530001 to 540000 processed.\n",
            "⏳ Processing chunk 540001 to 550000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_540001_550000.csv\n",
            "✅ Chunk 540001 to 550000 processed.\n",
            "⏳ Processing chunk 550001 to 560000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_550001_560000.csv\n",
            "✅ Chunk 550001 to 560000 processed.\n",
            "⏳ Processing chunk 560001 to 570000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_560001_570000.csv\n",
            "✅ Chunk 560001 to 570000 processed.\n",
            "⏳ Processing chunk 570001 to 580000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_570001_580000.csv\n",
            "✅ Chunk 570001 to 580000 processed.\n",
            "⏳ Processing chunk 580001 to 590000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_580001_590000.csv\n",
            "✅ Chunk 580001 to 590000 processed.\n",
            "⏳ Processing chunk 590001 to 600000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_590001_600000.csv\n",
            "✅ Chunk 590001 to 600000 processed.\n",
            "⏳ Processing chunk 600001 to 610000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_600001_610000.csv\n",
            "✅ Chunk 600001 to 610000 processed.\n",
            "⏳ Processing chunk 610001 to 620000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_610001_620000.csv\n",
            "✅ Chunk 610001 to 620000 processed.\n",
            "⏳ Processing chunk 620001 to 630000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_620001_630000.csv\n",
            "✅ Chunk 620001 to 630000 processed.\n",
            "⏳ Processing chunk 630001 to 640000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_630001_640000.csv\n",
            "✅ Chunk 630001 to 640000 processed.\n",
            "⏳ Processing chunk 640001 to 650000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_640001_650000.csv\n",
            "✅ Chunk 640001 to 650000 processed.\n",
            "⏳ Processing chunk 650001 to 660000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_650001_660000.csv\n",
            "✅ Chunk 650001 to 660000 processed.\n",
            "⏳ Processing chunk 660001 to 670000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_660001_670000.csv\n",
            "✅ Chunk 660001 to 670000 processed.\n",
            "⏳ Processing chunk 670001 to 680000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_670001_680000.csv\n",
            "✅ Chunk 670001 to 680000 processed.\n",
            "⏳ Processing chunk 680001 to 690000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_680001_690000.csv\n",
            "✅ Chunk 680001 to 690000 processed.\n",
            "⏳ Processing chunk 690001 to 700000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_690001_700000.csv\n",
            "✅ Chunk 690001 to 700000 processed.\n",
            "⏳ Processing chunk 700001 to 710000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_700001_710000.csv\n",
            "✅ Chunk 700001 to 710000 processed.\n",
            "⏳ Processing chunk 710001 to 720000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_710001_720000.csv\n",
            "✅ Chunk 710001 to 720000 processed.\n",
            "⏳ Processing chunk 720001 to 730000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_720001_730000.csv\n",
            "✅ Chunk 720001 to 730000 processed.\n",
            "⏳ Processing chunk 730001 to 740000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_730001_740000.csv\n",
            "✅ Chunk 730001 to 740000 processed.\n",
            "⏳ Processing chunk 740001 to 750000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_740001_750000.csv\n",
            "✅ Chunk 740001 to 750000 processed.\n",
            "⏳ Processing chunk 750001 to 760000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_750001_760000.csv\n",
            "✅ Chunk 750001 to 760000 processed.\n",
            "⏳ Processing chunk 760001 to 770000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_760001_770000.csv\n",
            "✅ Chunk 760001 to 770000 processed.\n",
            "⏳ Processing chunk 770001 to 780000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_770001_780000.csv\n",
            "✅ Chunk 770001 to 780000 processed.\n",
            "⏳ Processing chunk 780001 to 790000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_780001_790000.csv\n",
            "✅ Chunk 780001 to 790000 processed.\n",
            "⏳ Processing chunk 790001 to 800000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_790001_800000.csv\n",
            "✅ Chunk 790001 to 800000 processed.\n",
            "⏳ Processing chunk 800001 to 810000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_800001_810000.csv\n",
            "✅ Chunk 800001 to 810000 processed.\n",
            "⏳ Processing chunk 810001 to 820000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_810001_820000.csv\n",
            "✅ Chunk 810001 to 820000 processed.\n",
            "⏳ Processing chunk 820001 to 830000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_820001_830000.csv\n",
            "✅ Chunk 820001 to 830000 processed.\n",
            "⏳ Processing chunk 830001 to 840000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_830001_840000.csv\n",
            "✅ Chunk 830001 to 840000 processed.\n",
            "⏳ Processing chunk 840001 to 850000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_840001_850000.csv\n",
            "✅ Chunk 840001 to 850000 processed.\n",
            "⏳ Processing chunk 850001 to 860000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_850001_860000.csv\n",
            "✅ Chunk 850001 to 860000 processed.\n",
            "⏳ Processing chunk 860001 to 870000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_860001_870000.csv\n",
            "✅ Chunk 860001 to 870000 processed.\n",
            "⏳ Processing chunk 870001 to 880000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_870001_880000.csv\n",
            "✅ Chunk 870001 to 880000 processed.\n",
            "⏳ Processing chunk 880001 to 890000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_880001_890000.csv\n",
            "✅ Chunk 880001 to 890000 processed.\n",
            "⏳ Processing chunk 890001 to 900000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_890001_900000.csv\n",
            "✅ Chunk 890001 to 900000 processed.\n",
            "⏳ Processing chunk 900001 to 910000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_900001_910000.csv\n",
            "✅ Chunk 900001 to 910000 processed.\n",
            "⏳ Processing chunk 910001 to 920000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_910001_920000.csv\n",
            "✅ Chunk 910001 to 920000 processed.\n",
            "⏳ Processing chunk 920001 to 930000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_920001_930000.csv\n",
            "✅ Chunk 920001 to 930000 processed.\n",
            "⏳ Processing chunk 930001 to 940000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_930001_940000.csv\n",
            "✅ Chunk 930001 to 940000 processed.\n",
            "⏳ Processing chunk 940001 to 950000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_940001_950000.csv\n",
            "✅ Chunk 940001 to 950000 processed.\n",
            "⏳ Processing chunk 950001 to 960000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_950001_960000.csv\n",
            "✅ Chunk 950001 to 960000 processed.\n",
            "⏳ Processing chunk 960001 to 970000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_960001_970000.csv\n",
            "✅ Chunk 960001 to 970000 processed.\n",
            "⏳ Processing chunk 970001 to 980000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_970001_980000.csv\n",
            "✅ Chunk 970001 to 980000 processed.\n",
            "⏳ Processing chunk 980001 to 990000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_980001_990000.csv\n",
            "✅ Chunk 980001 to 990000 processed.\n",
            "⏳ Processing chunk 990001 to 1000000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_990001_1000000.csv\n",
            "✅ Chunk 990001 to 1000000 processed.\n",
            "⏳ Processing chunk 1000001 to 1010000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1000001_1010000.csv\n",
            "✅ Chunk 1000001 to 1010000 processed.\n",
            "⏳ Processing chunk 1010001 to 1020000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1010001_1020000.csv\n",
            "✅ Chunk 1010001 to 1020000 processed.\n",
            "⏳ Processing chunk 1020001 to 1030000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1020001_1030000.csv\n",
            "✅ Chunk 1020001 to 1030000 processed.\n",
            "⏳ Processing chunk 1030001 to 1040000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1030001_1040000.csv\n",
            "✅ Chunk 1030001 to 1040000 processed.\n",
            "⏳ Processing chunk 1040001 to 1050000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1040001_1050000.csv\n",
            "✅ Chunk 1040001 to 1050000 processed.\n",
            "⏳ Processing chunk 1050001 to 1060000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1050001_1060000.csv\n",
            "✅ Chunk 1050001 to 1060000 processed.\n",
            "⏳ Processing chunk 1060001 to 1070000\n",
            "⚠️ High population in chunk 1060001-1070000: 24,248,554\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1060001_1070000.csv\n",
            "✅ Chunk 1060001 to 1070000 processed.\n",
            "⏳ Processing chunk 1070001 to 1080000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1070001_1080000.csv\n",
            "✅ Chunk 1070001 to 1080000 processed.\n",
            "⏳ Processing chunk 1080001 to 1090000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1080001_1090000.csv\n",
            "✅ Chunk 1080001 to 1090000 processed.\n",
            "⏳ Processing chunk 1090001 to 1100000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1090001_1100000.csv\n",
            "✅ Chunk 1090001 to 1100000 processed.\n",
            "⏳ Processing chunk 1100001 to 1110000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1100001_1110000.csv\n",
            "✅ Chunk 1100001 to 1110000 processed.\n",
            "⏳ Processing chunk 1110001 to 1120000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1110001_1120000.csv\n",
            "✅ Chunk 1110001 to 1120000 processed.\n",
            "⏳ Processing chunk 1120001 to 1130000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1120001_1130000.csv\n",
            "✅ Chunk 1120001 to 1130000 processed.\n",
            "⏳ Processing chunk 1130001 to 1140000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1130001_1140000.csv\n",
            "✅ Chunk 1130001 to 1140000 processed.\n",
            "⏳ Processing chunk 1140001 to 1150000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1140001_1150000.csv\n",
            "✅ Chunk 1140001 to 1150000 processed.\n",
            "⏳ Processing chunk 1150001 to 1160000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1150001_1160000.csv\n",
            "✅ Chunk 1150001 to 1160000 processed.\n",
            "⏳ Processing chunk 1160001 to 1170000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1160001_1170000.csv\n",
            "✅ Chunk 1160001 to 1170000 processed.\n",
            "⏳ Processing chunk 1170001 to 1180000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1170001_1180000.csv\n",
            "✅ Chunk 1170001 to 1180000 processed.\n",
            "⏳ Processing chunk 1180001 to 1190000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1180001_1190000.csv\n",
            "✅ Chunk 1180001 to 1190000 processed.\n",
            "⏳ Processing chunk 1190001 to 1200000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1190001_1200000.csv\n",
            "✅ Chunk 1190001 to 1200000 processed.\n",
            "⏳ Processing chunk 1200001 to 1210000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1200001_1210000.csv\n",
            "✅ Chunk 1200001 to 1210000 processed.\n",
            "⏳ Processing chunk 1210001 to 1220000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1210001_1220000.csv\n",
            "✅ Chunk 1210001 to 1220000 processed.\n",
            "⏳ Processing chunk 1220001 to 1230000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1220001_1230000.csv\n",
            "✅ Chunk 1220001 to 1230000 processed.\n",
            "⏳ Processing chunk 1230001 to 1240000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1230001_1240000.csv\n",
            "✅ Chunk 1230001 to 1240000 processed.\n",
            "⏳ Processing chunk 1240001 to 1250000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1240001_1250000.csv\n",
            "✅ Chunk 1240001 to 1250000 processed.\n",
            "⏳ Processing chunk 1250001 to 1260000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1250001_1260000.csv\n",
            "✅ Chunk 1250001 to 1260000 processed.\n",
            "⏳ Processing chunk 1260001 to 1270000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1260001_1270000.csv\n",
            "✅ Chunk 1260001 to 1270000 processed.\n",
            "⏳ Processing chunk 1270001 to 1280000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1270001_1280000.csv\n",
            "✅ Chunk 1270001 to 1280000 processed.\n",
            "⏳ Processing chunk 1280001 to 1290000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1280001_1290000.csv\n",
            "✅ Chunk 1280001 to 1290000 processed.\n",
            "⏳ Processing chunk 1290001 to 1300000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1290001_1300000.csv\n",
            "✅ Chunk 1290001 to 1300000 processed.\n",
            "⏳ Processing chunk 1300001 to 1310000\n",
            "⚠️ High population in chunk 1300001-1310000: 20,109,050\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1300001_1310000.csv\n",
            "✅ Chunk 1300001 to 1310000 processed.\n",
            "⏳ Processing chunk 1310001 to 1320000\n",
            "⚠️ High population in chunk 1310001-1320000: 24,321,656\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1310001_1320000.csv\n",
            "✅ Chunk 1310001 to 1320000 processed.\n",
            "⏳ Processing chunk 1320001 to 1330000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1320001_1330000.csv\n",
            "✅ Chunk 1320001 to 1330000 processed.\n",
            "⏳ Processing chunk 1330001 to 1340000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1330001_1340000.csv\n",
            "✅ Chunk 1330001 to 1340000 processed.\n",
            "⏳ Processing chunk 1340001 to 1350000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1340001_1350000.csv\n",
            "✅ Chunk 1340001 to 1350000 processed.\n",
            "⏳ Processing chunk 1350001 to 1360000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1350001_1360000.csv\n",
            "✅ Chunk 1350001 to 1360000 processed.\n",
            "⏳ Processing chunk 1360001 to 1370000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1360001_1370000.csv\n",
            "✅ Chunk 1360001 to 1370000 processed.\n",
            "⏳ Processing chunk 1370001 to 1380000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1370001_1380000.csv\n",
            "✅ Chunk 1370001 to 1380000 processed.\n",
            "⏳ Processing chunk 1380001 to 1390000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1380001_1390000.csv\n",
            "✅ Chunk 1380001 to 1390000 processed.\n",
            "⏳ Processing chunk 1390001 to 1400000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1390001_1400000.csv\n",
            "✅ Chunk 1390001 to 1400000 processed.\n",
            "⏳ Processing chunk 1400001 to 1410000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1400001_1410000.csv\n",
            "✅ Chunk 1400001 to 1410000 processed.\n",
            "⏳ Processing chunk 1410001 to 1420000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1410001_1420000.csv\n",
            "✅ Chunk 1410001 to 1420000 processed.\n",
            "⏳ Processing chunk 1420001 to 1430000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1420001_1430000.csv\n",
            "✅ Chunk 1420001 to 1430000 processed.\n",
            "⏳ Processing chunk 1430001 to 1440000\n",
            "⚠️ High population in chunk 1430001-1440000: 24,404,648\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1430001_1440000.csv\n",
            "✅ Chunk 1430001 to 1440000 processed.\n",
            "⏳ Processing chunk 1440001 to 1450000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1440001_1450000.csv\n",
            "✅ Chunk 1440001 to 1450000 processed.\n",
            "⏳ Processing chunk 1450001 to 1460000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1450001_1460000.csv\n",
            "✅ Chunk 1450001 to 1460000 processed.\n",
            "⏳ Processing chunk 1460001 to 1470000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1460001_1470000.csv\n",
            "✅ Chunk 1460001 to 1470000 processed.\n",
            "⏳ Processing chunk 1470001 to 1480000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1470001_1480000.csv\n",
            "✅ Chunk 1470001 to 1480000 processed.\n",
            "⏳ Processing chunk 1480001 to 1490000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1480001_1490000.csv\n",
            "✅ Chunk 1480001 to 1490000 processed.\n",
            "⏳ Processing chunk 1490001 to 1500000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1490001_1500000.csv\n",
            "✅ Chunk 1490001 to 1500000 processed.\n",
            "⏳ Processing chunk 1500001 to 1510000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1500001_1510000.csv\n",
            "✅ Chunk 1500001 to 1510000 processed.\n",
            "⏳ Processing chunk 1510001 to 1520000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1510001_1520000.csv\n",
            "✅ Chunk 1510001 to 1520000 processed.\n",
            "⏳ Processing chunk 1520001 to 1530000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1520001_1530000.csv\n",
            "✅ Chunk 1520001 to 1530000 processed.\n",
            "⏳ Processing chunk 1530001 to 1540000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1530001_1540000.csv\n",
            "✅ Chunk 1530001 to 1540000 processed.\n",
            "⏳ Processing chunk 1540001 to 1550000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1540001_1550000.csv\n",
            "✅ Chunk 1540001 to 1550000 processed.\n",
            "⏳ Processing chunk 1550001 to 1560000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1550001_1560000.csv\n",
            "✅ Chunk 1550001 to 1560000 processed.\n",
            "⏳ Processing chunk 1560001 to 1570000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1560001_1570000.csv\n",
            "✅ Chunk 1560001 to 1570000 processed.\n",
            "⏳ Processing chunk 1570001 to 1580000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1570001_1580000.csv\n",
            "✅ Chunk 1570001 to 1580000 processed.\n",
            "⏳ Processing chunk 1580001 to 1590000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1580001_1590000.csv\n",
            "✅ Chunk 1580001 to 1590000 processed.\n",
            "⏳ Processing chunk 1590001 to 1600000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1590001_1600000.csv\n",
            "✅ Chunk 1590001 to 1600000 processed.\n",
            "⏳ Processing chunk 1600001 to 1610000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1600001_1610000.csv\n",
            "✅ Chunk 1600001 to 1610000 processed.\n",
            "⏳ Processing chunk 1610001 to 1620000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1610001_1620000.csv\n",
            "✅ Chunk 1610001 to 1620000 processed.\n",
            "⏳ Processing chunk 1620001 to 1630000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1620001_1630000.csv\n",
            "✅ Chunk 1620001 to 1630000 processed.\n",
            "⏳ Processing chunk 1630001 to 1640000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1630001_1640000.csv\n",
            "✅ Chunk 1630001 to 1640000 processed.\n",
            "⏳ Processing chunk 1640001 to 1650000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1640001_1650000.csv\n",
            "✅ Chunk 1640001 to 1650000 processed.\n",
            "⏳ Processing chunk 1650001 to 1660000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1650001_1660000.csv\n",
            "✅ Chunk 1650001 to 1660000 processed.\n",
            "⏳ Processing chunk 1660001 to 1670000\n",
            "⚠️ High population in chunk 1660001-1670000: 20,053,000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1660001_1670000.csv\n",
            "✅ Chunk 1660001 to 1670000 processed.\n",
            "⏳ Processing chunk 1670001 to 1680000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1670001_1680000.csv\n",
            "✅ Chunk 1670001 to 1680000 processed.\n",
            "⏳ Processing chunk 1680001 to 1690000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1680001_1690000.csv\n",
            "✅ Chunk 1680001 to 1690000 processed.\n",
            "⏳ Processing chunk 1690001 to 1700000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1690001_1700000.csv\n",
            "✅ Chunk 1690001 to 1700000 processed.\n",
            "⏳ Processing chunk 1700001 to 1710000\n",
            "⚠️ High population in chunk 1700001-1710000: 21,065,980\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1700001_1710000.csv\n",
            "✅ Chunk 1700001 to 1710000 processed.\n",
            "⏳ Processing chunk 1710001 to 1720000\n",
            "⚠️ High population in chunk 1710001-1720000: 20,726,924\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1710001_1720000.csv\n",
            "✅ Chunk 1710001 to 1720000 processed.\n",
            "⏳ Processing chunk 1720001 to 1730000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1720001_1730000.csv\n",
            "✅ Chunk 1720001 to 1730000 processed.\n",
            "⏳ Processing chunk 1730001 to 1740000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1730001_1740000.csv\n",
            "✅ Chunk 1730001 to 1740000 processed.\n",
            "⏳ Processing chunk 1740001 to 1750000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1740001_1750000.csv\n",
            "✅ Chunk 1740001 to 1750000 processed.\n",
            "⏳ Processing chunk 1750001 to 1760000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1750001_1760000.csv\n",
            "✅ Chunk 1750001 to 1760000 processed.\n",
            "⏳ Processing chunk 1760001 to 1770000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1760001_1770000.csv\n",
            "✅ Chunk 1760001 to 1770000 processed.\n",
            "⏳ Processing chunk 1770001 to 1780000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1770001_1780000.csv\n",
            "✅ Chunk 1770001 to 1780000 processed.\n",
            "⏳ Processing chunk 1780001 to 1790000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1780001_1790000.csv\n",
            "✅ Chunk 1780001 to 1790000 processed.\n",
            "⏳ Processing chunk 1790001 to 1800000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1790001_1800000.csv\n",
            "✅ Chunk 1790001 to 1800000 processed.\n",
            "⏳ Processing chunk 1800001 to 1810000\n",
            "⚠️ High population in chunk 1800001-1810000: 20,314,060\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1800001_1810000.csv\n",
            "✅ Chunk 1800001 to 1810000 processed.\n",
            "⏳ Processing chunk 1810001 to 1820000\n",
            "⚠️ High population in chunk 1810001-1820000: 20,030,300\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1810001_1820000.csv\n",
            "✅ Chunk 1810001 to 1820000 processed.\n",
            "⏳ Processing chunk 1820001 to 1830000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1820001_1830000.csv\n",
            "✅ Chunk 1820001 to 1830000 processed.\n",
            "⏳ Processing chunk 1830001 to 1840000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1830001_1840000.csv\n",
            "✅ Chunk 1830001 to 1840000 processed.\n",
            "⏳ Processing chunk 1840001 to 1850000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1840001_1850000.csv\n",
            "✅ Chunk 1840001 to 1850000 processed.\n",
            "⏳ Processing chunk 1850001 to 1860000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1850001_1860000.csv\n",
            "✅ Chunk 1850001 to 1860000 processed.\n",
            "⏳ Processing chunk 1860001 to 1870000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1860001_1870000.csv\n",
            "✅ Chunk 1860001 to 1870000 processed.\n",
            "⏳ Processing chunk 1870001 to 1880000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1870001_1880000.csv\n",
            "✅ Chunk 1870001 to 1880000 processed.\n",
            "⏳ Processing chunk 1880001 to 1890000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1880001_1890000.csv\n",
            "✅ Chunk 1880001 to 1890000 processed.\n",
            "⏳ Processing chunk 1890001 to 1900000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1890001_1900000.csv\n",
            "✅ Chunk 1890001 to 1900000 processed.\n",
            "⏳ Processing chunk 1900001 to 1910000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1900001_1910000.csv\n",
            "✅ Chunk 1900001 to 1910000 processed.\n",
            "⏳ Processing chunk 1910001 to 1920000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1910001_1920000.csv\n",
            "✅ Chunk 1910001 to 1920000 processed.\n",
            "⏳ Processing chunk 1920001 to 1930000\n",
            "📁 Saved chunk to: D:\\NDIS_Database\\zonal_chunks\\chunk_1920001_1930000.csv\n",
            "✅ Chunk 1920001 to 1930000 processed.\n",
            "⏳ Processing chunk 1930001 to 1938350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgisclone\\Lib\\site-packages\\geopandas\\geoseries.py:786: UserWarning: GeoSeries.notna() previously returned False for both missing (None) and empty geometries. Now, it only returns False for missing values. Since the calling GeoSeries contains empty geometries, the result has changed compared to previous versions of GeoPandas.\n",
            "Given a GeoSeries 's', you can use '~s.is_empty & s.notna()' to get back the old behaviour.\n",
            "\n",
            "To further ignore this warning, you can do: \n",
            "import warnings; warnings.filterwarnings('ignore', 'GeoSeries.notna', UserWarning)\n",
            "  return self.notna()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Error in chunk 1930001 to 1938350: 'NoneType' object has no attribute 'get'\n",
            "🟡 Saved 24 suspicious rows for manual review.\n",
            "🎉 All done.\n",
            "✅ Combined all chunks into final_gdf\n",
            "✅ All processing completed! Elapsed time: 419.9807786049999 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "# Parameters\n",
        "population_raster = r\"D:\\NDIS_Database\\12_Population_synthetic\\nasapopct.tif\"\n",
        "buffer_dist = 30000  # 30 km\n",
        "chunk_size = 10000\n",
        "\n",
        "output_dir = r\"D:\\NDIS_Database\\zonal_chunks\"\n",
        "\n",
        "# Check if it's a file, not a folder\n",
        "if os.path.exists(output_dir) and not os.path.isdir(output_dir):\n",
        "    os.remove(output_dir)\n",
        "\n",
        "# Now safely create the directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convert DataFrame to GeoDataFrame\n",
        "ghz_pap[\"geometry\"] = ghz_pap.apply(\n",
        "    lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1\n",
        ")\n",
        "input_gdf = gpd.GeoDataFrame(ghz_pap, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "\n",
        "# Buffer in degrees (WGS84 safe approx)\n",
        "buffer_deg = buffer_dist / 111320.0\n",
        "\n",
        "# Tracking\n",
        "total = len(input_gdf)\n",
        "print(f\"🔹 Total features: {total}\")\n",
        "final_chunks = []\n",
        "suspicious_chunks = []\n",
        "\n",
        "for start in range(0, total, chunk_size):\n",
        "    end = min(start + chunk_size, total)\n",
        "    print(f\"⏳ Processing chunk {start+1} to {end}\")\n",
        "\n",
        "    chunk = input_gdf.iloc[start:end].copy()\n",
        "\n",
        "    # Suppress geographic CRS buffer warning\n",
        "    warnings.filterwarnings(\"ignore\", message=\"Geometry is in a geographic CRS.*\")\n",
        "    chunk[\"geometry\"] = chunk.geometry.buffer(buffer_deg)\n",
        "\n",
        "    # Drop bad geometries\n",
        "    chunk = chunk[chunk[\"geometry\"].notnull()]\n",
        "    chunk = chunk[chunk.is_valid]\n",
        "\n",
        "    if chunk.empty:\n",
        "        print(f\"⚠️ Skipping empty/invalid chunk {start+1} to {end}\")\n",
        "        continue\n",
        "\n",
        "    # Compute zonal stats with overflow suppression\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "        try:\n",
        "            stats = zonal_stats(\n",
        "                chunk,\n",
        "                population_raster,\n",
        "                stats=[\"sum\"],\n",
        "                geojson_out=False,\n",
        "                nodata=-9999  # Or None if unknown\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in chunk {start+1} to {end}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not stats or all(row.get(\"sum\") is None for row in stats):\n",
        "        print(f\"⚠️ No stats found for chunk {start+1} to {end}\")\n",
        "        chunk[\"pop\"] = 0\n",
        "    else:\n",
        "        chunk[\"pop\"] = [float(row.get(\"sum\", 0) or 0) for row in stats]\n",
        "\n",
        "    # Flag suspicious high-pop zones\n",
        "    chunk[\"pop_flagged\"] = chunk[\"pop\"].apply(lambda x: \"⚠️ check\" if x > 20_000_000 else \"\")\n",
        "    max_pop = chunk[\"pop\"].max()\n",
        "    if max_pop > 20_000_000:\n",
        "        print(f\"⚠️ High population in chunk {start+1}-{end}: {max_pop:,.0f}\")\n",
        "        suspicious_chunks.append(chunk[chunk[\"pop\"] > 20_000_000].copy())\n",
        "\n",
        "    # Save chunk to CSV immediately\n",
        "    chunk_out_path = os.path.join(output_dir, f\"chunk_{start+1}_{end}.csv\")\n",
        "    chunk.drop(columns=\"geometry\").to_csv(chunk_out_path, index=False)\n",
        "    print(f\"📁 Saved chunk to: {chunk_out_path}\")\n",
        "\n",
        "    print(f\"✅ Chunk {start+1} to {end} processed.\")\n",
        "    # Append to final result in memory\n",
        "    final_chunks.append(chunk.copy())  # keep geometry for now\n",
        "\n",
        "    # Save chunk to disk (crash recovery)\n",
        "    chunk_out_path = os.path.join(output_dir, f\"chunk_{start+1}_{end}.csv\")\n",
        "    chunk.drop(columns=\"geometry\").to_csv(chunk_out_path, index=False)\n",
        "\n",
        "    # Memory cleanup\n",
        "    del chunk, stats\n",
        "    gc.collect()\n",
        "\n",
        "# Save suspicious rows summary\n",
        "if suspicious_chunks:\n",
        "    suspicious_df = pd.concat(suspicious_chunks, ignore_index=True)\n",
        "    suspicious_df.to_csv(os.path.join(output_dir, \"suspicious_population_zones.csv\"), index=False)\n",
        "    print(f\"🟡 Saved {len(suspicious_df)} suspicious rows for manual review.\")\n",
        "else:\n",
        "    print(\"✅ No suspicious population zones found.\")\n",
        "\n",
        "print(\"🎉 All done.\")\n",
        "\n",
        "\n",
        "# Combine all chunks in memory\n",
        "final_gdf = pd.concat(final_chunks, ignore_index=True)\n",
        "print(\"✅ Combined all chunks into final_gdf\")\n",
        "\n",
        "final_gdf.to_csv(r\"D:\\NDIS_Database\\ghz_pop.csv\", index=False)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"\\u2705 All processing completed! Elapsed time: %s minutes\"%str(elapsed/60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH2t_bqKWg4V",
        "outputId": "f992d6f1-7149-45dc-9593-28a50f502f27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24404648.0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(final_gdf['pop'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aLrCIoQWg4W",
        "outputId": "bbca8f47-0d50-42bb-d365-cf7d64cf876c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 24 entries, 0 to 23\n",
            "Data columns (total 13 columns):\n",
            " #   Column                 Non-Null Count  Dtype   \n",
            "---  ------                 --------------  -----   \n",
            " 0   HazardID               24 non-null     int64   \n",
            " 1   latitude               24 non-null     float64 \n",
            " 2   longitude              24 non-null     float64 \n",
            " 3   HazardType             24 non-null     object  \n",
            " 4   distance               24 non-null     float64 \n",
            " 5   intensity              24 non-null     float64 \n",
            " 6   economic_loss_million  24 non-null     float64 \n",
            " 7   duration_minutes       24 non-null     float64 \n",
            " 8   travel_time            24 non-null     float64 \n",
            " 9   cpm_total_time         23 non-null     float64 \n",
            " 10  geometry               24 non-null     geometry\n",
            " 11  pop                    24 non-null     float64 \n",
            " 12  pop_flagged            24 non-null     object  \n",
            "dtypes: float64(9), geometry(1), int64(1), object(2)\n",
            "memory usage: 2.6+ KB\n"
          ]
        }
      ],
      "source": [
        "suspicious_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzsjV_qMWg4X",
        "outputId": "d7add765-e03a-4f2b-c87b-9e914e32b580"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgisclone\\Lib\\site-packages\\geopandas\\geoseries.py:786: UserWarning: GeoSeries.notna() previously returned False for both missing (None) and empty geometries. Now, it only returns False for missing values. Since the calling GeoSeries contains empty geometries, the result has changed compared to previous versions of GeoPandas.\n",
            "Given a GeoSeries 's', you can use '~s.is_empty & s.notna()' to get back the old behaviour.\n",
            "\n",
            "To further ignore this warning, you can do: \n",
            "import warnings; warnings.filterwarnings('ignore', 'GeoSeries.notna', UserWarning)\n",
            "  return self.notna()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Patched chunk saved to D:\\NDIS_Database\\zonal_chunks\\chunk_1930001_1938350.csv\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Reload or reuse original input GeoDataFrame\n",
        "chunk = input_gdf.iloc[1930000:1938350].copy()  # Python is 0-based\n",
        "\n",
        "# Step 2: Buffer and clean geometry\n",
        "warnings.filterwarnings(\"ignore\", message=\"Geometry is in a geographic CRS.*\")\n",
        "chunk[\"geometry\"] = chunk.geometry.buffer(buffer_deg)\n",
        "chunk = chunk[chunk[\"geometry\"].notnull()]\n",
        "chunk = chunk[~chunk[\"geometry\"].is_empty]\n",
        "chunk = chunk[chunk.is_valid]\n",
        "\n",
        "# Step 3: Rerun zonal stats safely\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "    stats = zonal_stats(\n",
        "        chunk,\n",
        "        population_raster,\n",
        "        stats=[\"sum\"],\n",
        "        geojson_out=False,\n",
        "        nodata=-9999\n",
        "    )\n",
        "\n",
        "# Step 4: Fill population values\n",
        "chunk[\"pop\"] = [float(row.get(\"sum\", 0) or 0) for row in stats]\n",
        "chunk[\"pop_flagged\"] = chunk[\"pop\"].apply(lambda x: \"⚠️ check\" if x > 20_000_000 else \"\")\n",
        "\n",
        "# Step 5: Save the corrected chunk\n",
        "chunk_out_path = os.path.join(output_dir, \"chunk_1930001_1938350.csv\")\n",
        "chunk.drop(columns=\"geometry\").to_csv(chunk_out_path, index=False)\n",
        "print(f\"✅ Patched chunk saved to {chunk_out_path}\")\n",
        "\n",
        "# Optional: append to final in-memory result\n",
        "#final_chunks.append(chunk.copy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq551vD0Wg4X"
      },
      "outputs": [],
      "source": [
        "null_geom_ids = [\n",
        "    1045, 14943, 14999, 15003, 15037, 15052, 15108, 18189, 64503, 72741, 99537,\n",
        "    102208, 103016, 105219, 114251, 114516, 115189, 116052, 116932, 116991,\n",
        "    117447, 117792, 118519, 121364, 139022, 355328, 359478, 370280, 370413,\n",
        "    371531, 386363, 386367, 386387, 388549, 389557, 390083, 393224, 393645,\n",
        "    394422, 394774, 403304, 404977, 476193, 539023, 867092, 895514, 927888,\n",
        "    987286, 988385, 1110501, 1112965, 1112970, 1163972, 1178798, 1183599,\n",
        "    1289453, 1289586, 1338653, 1340317, 1340620, 1520597, 1527977, 1527982,\n",
        "    1582745, 1585801, 1619277, 1620106, 1621234, 1622439, 1630938, 1633828,\n",
        "    1633854, 1648844, 1821680, 1888743, 1888745, 1888748, 1888750, 1888752,\n",
        "    1888754, 1888926, 1903415, 1903418, 1903419, 1903420\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uX448lxWg4Y"
      },
      "outputs": [],
      "source": [
        "# ArcGIS ObjectID starts at 1, but pandas index starts at 0\n",
        "# So subtract 1\n",
        "pandas_row_ids = [i - 1 for i in null_geom_ids]\n",
        "\n",
        "# Isolate the rows from final_gdf\n",
        "null_rows = final_gdf.iloc[pandas_row_ids].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxMYZjFKWg4Y",
        "outputId": "dc0bf3a9-5003-487b-eece-7317906bd180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-80.44\n",
            "151.0\n",
            "0.0\n",
            "43.05\n"
          ]
        }
      ],
      "source": [
        "print(min(null_rows.longitude))\n",
        "print(max(null_rows.longitude))\n",
        "print(min(null_rows.latitude))\n",
        "print(max(null_rows.latitude))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUgLcfhgWg4Y"
      },
      "outputs": [],
      "source": [
        "# List of ArcGIS-reported IDs\n",
        "arcgis_oids = [\n",
        "    1045, 14943, 14999, 15003, 15037, 15052, 15108, 18189, 64503, 72741,\n",
        "    99537, 102208, 103016, 105219, 114251, 114516, 115189, 116052, 116932,\n",
        "    116991, 117447, 117792, 118519, 121364, 139022, 355328, 359478, 370280,\n",
        "    370413, 371531, 386363, 386367, 386387, 388549, 389557, 390083, 393224,\n",
        "    393645, 394422, 394774, 403304, 404977, 476193, 539023, 867092, 895514,\n",
        "    927888, 987286, 988385, 1110501, 1112965, 1112970, 1163972, 1178798,\n",
        "    1183599, 1289453, 1289586, 1338653, 1340317, 1340620, 1520597, 1527977,\n",
        "    1527982, 1582745, 1585801, 1619277, 1620106, 1621234, 1622439, 1630938,\n",
        "    1633828, 1633854, 1648844, 1821680, 1888743, 1888745, 1888748, 1888750,\n",
        "    1888752, 1888754, 1888926, 1903415, 1903418, 1903419, 1903420\n",
        "]\n",
        "\n",
        "# Extract suspicious rows\n",
        "sus_rows = final_gdf.iloc[arcgis_oids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "u5mDOlevWg4Z",
        "outputId": "77204737-d81f-488a-b9bc-2e77c131c3ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HazardID</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>HazardType</th>\n",
              "      <th>distance</th>\n",
              "      <th>intensity</th>\n",
              "      <th>economic_loss_million</th>\n",
              "      <th>duration_minutes</th>\n",
              "      <th>travel_time</th>\n",
              "      <th>cpm_total_time</th>\n",
              "      <th>geometry</th>\n",
              "      <th>pop</th>\n",
              "      <th>pop_flagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>0.355162</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.97</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>48.000269</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14942</th>\n",
              "      <td>21122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>2494.398029</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.944848</td>\n",
              "      <td>121.889695</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>21178</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>2451.697959</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.928673</td>\n",
              "      <td>60.857347</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15002</th>\n",
              "      <td>21183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>1181.439960</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.96</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.447515</td>\n",
              "      <td>144.895030</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>21217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>710.959400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.73</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.269303</td>\n",
              "      <td>46.538606</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15051</th>\n",
              "      <td>21232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>457.913528</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.58</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.173452</td>\n",
              "      <td>62.346904</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15107</th>\n",
              "      <td>27998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Landslide</td>\n",
              "      <td>338.778100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.66</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.128325</td>\n",
              "      <td>41.256650</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888742</th>\n",
              "      <td>618327912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888744</th>\n",
              "      <td>618328657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888747</th>\n",
              "      <td>618328671</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888749</th>\n",
              "      <td>618328677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888751</th>\n",
              "      <td>618328694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888753</th>\n",
              "      <td>618328687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1903414</th>\n",
              "      <td>618327922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1903417</th>\n",
              "      <td>618328653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1903418</th>\n",
              "      <td>618328675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1903419</th>\n",
              "      <td>618328695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Earthquake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0...</td>\n",
              "      <td>-inf</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          HazardID  latitude  longitude  HazardType     distance  intensity  \\\n",
              "1044             0       0.0        0.0   Landslide     0.355162        1.0   \n",
              "14942        21122       0.0        0.0   Landslide  2494.398029        2.0   \n",
              "14998        21178       0.0        0.0   Landslide  2451.697959        1.0   \n",
              "15002        21183       0.0        0.0   Landslide  1181.439960        0.0   \n",
              "15036        21217       0.0        0.0   Landslide   710.959400        0.0   \n",
              "15051        21232       0.0        0.0   Landslide   457.913528        0.0   \n",
              "15107        27998       0.0        0.0   Landslide   338.778100        1.0   \n",
              "1888742  618327912       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1888744  618328657       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1888747  618328671       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1888749  618328677       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1888751  618328694       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1888753  618328687       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1903414  618327922       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1903417  618328653       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1903418  618328675       0.0        0.0  Earthquake          NaN        NaN   \n",
              "1903419  618328695       0.0        0.0  Earthquake          NaN        NaN   \n",
              "\n",
              "         economic_loss_million  duration_minutes  travel_time  cpm_total_time  \\\n",
              "1044                      0.97              48.0     0.000135       48.000269   \n",
              "14942                     0.05             120.0     0.944848      121.889695   \n",
              "14998                     0.01              59.0     0.928673       60.857347   \n",
              "15002                     2.96             144.0     0.447515      144.895030   \n",
              "15036                     2.73              46.0     0.269303       46.538606   \n",
              "15051                     0.58              62.0     0.173452       62.346904   \n",
              "15107                    11.66              41.0     0.128325       41.256650   \n",
              "1888742                    NaN               NaN          NaN             NaN   \n",
              "1888744                    NaN               NaN          NaN             NaN   \n",
              "1888747                    NaN               NaN          NaN             NaN   \n",
              "1888749                    NaN               NaN          NaN             NaN   \n",
              "1888751                    NaN               NaN          NaN             NaN   \n",
              "1888753                    NaN               NaN          NaN             NaN   \n",
              "1903414                    NaN               NaN          NaN             NaN   \n",
              "1903417                    NaN               NaN          NaN             NaN   \n",
              "1903418                    NaN               NaN          NaN             NaN   \n",
              "1903419                    NaN               NaN          NaN             NaN   \n",
              "\n",
              "                                                  geometry  pop pop_flagged  \n",
              "1044     POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "14942    POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "14998    POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "15002    POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "15036    POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "15051    POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "15107    POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1888742  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1888744  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1888747  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1888749  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1888751  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1888753  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1903414  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1903417  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1903418  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              \n",
              "1903419  POLYGON ((0.26949 0.00000, 0.26820 -0.02641, 0... -inf              "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "at_origin_coords = final_gdf[\n",
        "    (final_gdf[\"longitude\"] == 0.0) & (final_gdf[\"latitude\"] == 0.0)\n",
        "]\n",
        "at_origin_coords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybeb80iTWg4Z",
        "outputId": "dae524c3-8d64-4639-e3b8-47f1913a21c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "Index: 17 entries, 1044 to 1903419\n",
            "Data columns (total 13 columns):\n",
            " #   Column                 Non-Null Count  Dtype   \n",
            "---  ------                 --------------  -----   \n",
            " 0   HazardID               17 non-null     int64   \n",
            " 1   latitude               17 non-null     float64 \n",
            " 2   longitude              17 non-null     float64 \n",
            " 3   HazardType             17 non-null     object  \n",
            " 4   distance               7 non-null      float64 \n",
            " 5   intensity              7 non-null      float64 \n",
            " 6   economic_loss_million  7 non-null      float64 \n",
            " 7   duration_minutes       7 non-null      float64 \n",
            " 8   travel_time            7 non-null      float64 \n",
            " 9   cpm_total_time         7 non-null      float64 \n",
            " 10  geometry               17 non-null     geometry\n",
            " 11  pop                    17 non-null     float64 \n",
            " 12  pop_flagged            17 non-null     object  \n",
            "dtypes: float64(9), geometry(1), int64(1), object(2)\n",
            "memory usage: 1.9+ KB\n"
          ]
        }
      ],
      "source": [
        "at_origin_coords.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIWOl1OaWg4Z"
      },
      "outputs": [],
      "source": [
        "invalid_coords = final_gdf[\n",
        "    (final_gdf[\"latitude\"] > 90) | (final_gdf[\"latitude\"] < -90) |\n",
        "    (final_gdf[\"longitude\"] > 180) | (final_gdf[\"longitude\"] < -180)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btkZ-WBEWg4a",
        "outputId": "cce564a2-c411-4bc6-e00f-901ded116e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔁 Total to reprocess: 1374661 rows\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Get the final chunk (assuming input_gdf is still in memory)\n",
        "final_chunk = input_gdf.iloc[1930000:1938350].copy()\n",
        "\n",
        "# Step 2: Extract rows with inf population from final_gdf\n",
        "inf_rows = final_gdf[np.isinf(final_gdf[\"pop\"])].copy()\n",
        "\n",
        "# Step 3: Drop geometry and rebuild clean GeoDataFrame\n",
        "inf_rows = inf_rows.drop(columns=\"geometry\", errors=\"ignore\")\n",
        "inf_rows[\"geometry\"] = inf_rows.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
        "inf_gdf = gpd.GeoDataFrame(inf_rows, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "\n",
        "# Step 4: Combine both sets (resetting index not strictly necessary but keeps things tidy)\n",
        "redo_gdf = pd.concat([final_chunk, inf_gdf], ignore_index=True)\n",
        "\n",
        "print(f\"🔁 Total to reprocess: {len(redo_gdf)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzMaocyYWg4a",
        "outputId": "2f6e7218-36a7-4474-99c7-ca8e81f30a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1938350 entries, 0 to 1938349\n",
            "Data columns (total 11 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   travel_time            float64\n",
            " 9   cpm_total_time         float64\n",
            " 10  geometry               object \n",
            "dtypes: float64(8), int64(1), object(2)\n",
            "memory usage: 162.7+ MB\n"
          ]
        }
      ],
      "source": [
        "ghz_pap.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbdMPIwSWg4b"
      },
      "outputs": [],
      "source": [
        "null_or_empty_geom_df = ghz_pap[ghz_pap[\"latitude\"].isna() | ghz_pap[\"longitude\"].isna()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31IMcAPWg4b",
        "outputId": "a202a9fb-2755-4626-91d6-f5d35894bd7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2625 entries, 1935725 to 1938349\n",
            "Data columns (total 11 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   HazardID               2625 non-null   int64  \n",
            " 1   latitude               0 non-null      float64\n",
            " 2   longitude              0 non-null      float64\n",
            " 3   HazardType             2625 non-null   object \n",
            " 4   distance               0 non-null      float64\n",
            " 5   intensity              2625 non-null   float64\n",
            " 6   economic_loss_million  2625 non-null   float64\n",
            " 7   duration_minutes       2625 non-null   float64\n",
            " 8   travel_time            0 non-null      float64\n",
            " 9   cpm_total_time         0 non-null      float64\n",
            " 10  geometry               2625 non-null   object \n",
            "dtypes: float64(8), int64(1), object(2)\n",
            "memory usage: 246.1+ KB\n"
          ]
        }
      ],
      "source": [
        "null_or_empty_geom_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Lys8VDWg4b"
      },
      "source": [
        "# Tsunami Reprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6S0WuO8Wg4c",
        "outputId": "513e29a1-1b06-42e7-a03b-ff3f172507d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2625 entries, 0 to 2624\n",
            "Data columns (total 81 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   UNIQUE_ID                      2625 non-null   int64  \n",
            " 1   YEAR                           2625 non-null   int64  \n",
            " 2   MONTH                          2514 non-null   float64\n",
            " 3   DAY                            2430 non-null   float64\n",
            " 4   HOUR                           1556 non-null   float64\n",
            " 5   MINUTE                         1472 non-null   float64\n",
            " 6   SECOND                         1047 non-null   float64\n",
            " 7   DATE_STRING                    2625 non-null   object \n",
            " 8   EVENT_DATE                     2596 non-null   object \n",
            " 9   LATITUDE                       2625 non-null   float64\n",
            " 10  LONGITUDE                      2625 non-null   float64\n",
            " 11  LOCATION_NAME                  2624 non-null   object \n",
            " 12  AREA                           234 non-null    object \n",
            " 13  COUNTRY                        2625 non-null   object \n",
            " 14  REGION_CODE                    2624 non-null   float64\n",
            " 15  REGION                         2624 non-null   object \n",
            " 16  CAUSE_CODE                     2623 non-null   float64\n",
            " 17  CAUSE                          2623 non-null   object \n",
            " 18  EVENT_VALIDITY_CODE            2625 non-null   int64  \n",
            " 19  EVENT_VALIDITY                 2625 non-null   object \n",
            " 20  EQ_MAG_UNK                     111 non-null    float64\n",
            " 21  EQ_MAG_MB                      433 non-null    float64\n",
            " 22  EQ_MAG_MS                      1395 non-null   float64\n",
            " 23  EQ_MAG_MW                      670 non-null    float64\n",
            " 24  EQ_MAG_ML                      41 non-null     float64\n",
            " 25  EQ_MAG_MFA                     9 non-null      float64\n",
            " 26  EQ_MAGNITUDE                   1713 non-null   float64\n",
            " 27  EQ_MAGNITUDE_RANK              1713 non-null   float64\n",
            " 28  EQ_DEPTH                       1077 non-null   float64\n",
            " 29  MAX_EVENT_RUNUP                1293 non-null   float64\n",
            " 30  TS_MT_ABE                      2 non-null      float64\n",
            " 31  TS_MT_II                       711 non-null    float64\n",
            " 32  TS_INTENSITY                   1176 non-null   float64\n",
            " 33  DAMAGE_MILLIONS_DOLLARS        48 non-null     float64\n",
            " 34  DAMAGE_AMOUNT_ORDER            649 non-null    float64\n",
            " 35  DAMAGE_DESCRIPTION             649 non-null    object \n",
            " 36  HOUSES_DESTROYED               101 non-null    float64\n",
            " 37  HOUSES_AMOUNT_ORDER            282 non-null    float64\n",
            " 38  HOUSES_DESCRIPTION             282 non-null    object \n",
            " 39  DEATHS                         258 non-null    float64\n",
            " 40  DEATHS_AMOUNT_ORDER            2625 non-null   float64\n",
            " 41  DEATHS_DESCRIPTION             353 non-null    object \n",
            " 42  INJURIES                       72 non-null     float64\n",
            " 43  INJURIES_AMOUNT_ORDER          84 non-null     float64\n",
            " 44  INJURIES_DESCRIPTION           84 non-null     object \n",
            " 45  MISSING                        6 non-null      float64\n",
            " 46  MISSING_AMOUNT_ORDER           7 non-null      float64\n",
            " 47  MISSING_DESCRIPTION            7 non-null      object \n",
            " 48  NUM_RUNUP                      2625 non-null   int64  \n",
            " 49  DAMAGE_MILLIONS_DOLLARS_TOTAL  172 non-null    float64\n",
            " 50  DAMAGE_AMOUNT_ORDER_TOTAL      1316 non-null   float64\n",
            " 51  DAMAGE_TOTAL_DESCRIPTION       1316 non-null   object \n",
            " 52  HOUSES_DESTROYED_TOTAL         266 non-null    float64\n",
            " 53  HOUSES_AMOUNT_ORDER_TOTAL      719 non-null    float64\n",
            " 54  HOUSES_TOTAL_DESCRIPTION       719 non-null    object \n",
            " 55  DEATHS_TOTAL                   668 non-null    float64\n",
            " 56  DEATHS_AMOUNT_ORDER_TOTAL      821 non-null    float64\n",
            " 57  DEATHS_TOTAL_DESCRIPTION       821 non-null    object \n",
            " 58  INJURIES_TOTAL                 323 non-null    float64\n",
            " 59  INJURIES_AMOUNT_ORDER_TOTAL    380 non-null    float64\n",
            " 60  INJURIES_TOTAL_DESCRIPTION     380 non-null    object \n",
            " 61  MISSING_TOTAL                  16 non-null     float64\n",
            " 62  MISSING_AMOUNT_ORDER_TOTAL     20 non-null     float64\n",
            " 63  MISSING_TOTAL_DESCRIPTION      20 non-null     object \n",
            " 64  HOUSES_DAMAGED                 17 non-null     float64\n",
            " 65  HOUSES_DAMAGED_AMOUNT_ORDER    65 non-null     float64\n",
            " 66  HOUSES_DAM_DESCRIPTION         65 non-null     object \n",
            " 67  HOUSES_DAMAGED_TOTAL           106 non-null    float64\n",
            " 68  HOUSES_DAM_AMOUNT_ORDER_TOTAL  289 non-null    float64\n",
            " 69  HOUSES_DAM_TOTAL_DESCRIPTION   289 non-null    object \n",
            " 70  CAUSE_SYMBOL                   2625 non-null   float64\n",
            " 71  URL                            2625 non-null   object \n",
            " 72  COMMENTS                       2455 non-null   object \n",
            " 73  HazardID                       2625 non-null   int64  \n",
            " 74  MAP_SYMBOL                     2625 non-null   int64  \n",
            " 75  SHAPE                          2625 non-null   object \n",
            " 76  intensity                      2625 non-null   float64\n",
            " 77  intensity_source               2625 non-null   object \n",
            " 78  duration_minutes               2625 non-null   int64  \n",
            " 79  damage_desc_est                1316 non-null   float64\n",
            " 80  economic_loss_million          2625 non-null   float64\n",
            "dtypes: float64(50), int64(7), object(24)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ],
      "source": [
        "tsunami = pd.read_csv(r\"D:\\NDIS_Database\\03_Tsunami\\tsunami_paper.csv\")\n",
        "tsunami.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVWbIKE2Wg4c",
        "outputId": "0c570cdd-5b46-4f85-8a7e-decd78437979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2625 entries, 0 to 2624\n",
            "Data columns (total 6 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   UNIQUE_ID              2625 non-null   int64  \n",
            " 1   LATITUDE               2625 non-null   float64\n",
            " 2   LONGITUDE              2625 non-null   float64\n",
            " 3   intensity              2625 non-null   float64\n",
            " 4   economic_loss_million  2625 non-null   float64\n",
            " 5   duration_minutes       2625 non-null   int64  \n",
            "dtypes: float64(4), int64(2)\n",
            "memory usage: 123.2 KB\n"
          ]
        }
      ],
      "source": [
        "# Select only the desired columns from merged_df_final\n",
        "tsun_2concat = tsunami[[\n",
        "    \"UNIQUE_ID\",\n",
        "    \"LATITUDE\",\n",
        "    \"LONGITUDE\",\n",
        "    \"intensity\",\n",
        "    \"economic_loss_million\",\n",
        "    \"duration_minutes\"\n",
        "]].copy()\n",
        "tsun_2concat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6afHsgpWg4c",
        "outputId": "53c646c1-833a-4137-be5e-b6f390365287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2625 entries, 0 to 2624\n",
            "Data columns (total 6 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   HazardID               2625 non-null   int64  \n",
            " 1   latitude               2625 non-null   float64\n",
            " 2   longitude              2625 non-null   float64\n",
            " 3   intensity              2625 non-null   float64\n",
            " 4   economic_loss_million  2625 non-null   float64\n",
            " 5   duration_minutes       2625 non-null   int64  \n",
            "dtypes: float64(4), int64(2)\n",
            "memory usage: 123.2 KB\n"
          ]
        }
      ],
      "source": [
        "# Rename fields to match geohazard schema\n",
        "tsun_2concat = tsunami[[\n",
        "    \"UNIQUE_ID\",\n",
        "    \"LATITUDE\",\n",
        "    \"LONGITUDE\",\n",
        "    \"intensity\",\n",
        "    \"economic_loss_million\",\n",
        "    \"duration_minutes\"\n",
        "]].copy()\n",
        "\n",
        "# Rename columns\n",
        "tsun_2concat.rename(columns={\n",
        "    \"UNIQUE_ID\": \"HazardID\",\n",
        "    \"LATITUDE\": \"latitude\",\n",
        "    \"LONGITUDE\": \"longitude\"\n",
        "}, inplace=True)\n",
        "tsun_2concat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFdUQIUNWg4d",
        "outputId": "17dbeb41-84d5-4531-c0f4-49e14ec7685a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HazardID</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>intensity</th>\n",
              "      <th>economic_loss_million</th>\n",
              "      <th>duration_minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>762134</td>\n",
              "      <td>35.683</td>\n",
              "      <td>35.80</td>\n",
              "      <td>5.0</td>\n",
              "      <td>50.00</td>\n",
              "      <td>478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>762135</td>\n",
              "      <td>36.400</td>\n",
              "      <td>25.40</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>762136</td>\n",
              "      <td>35.683</td>\n",
              "      <td>35.80</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>762137</td>\n",
              "      <td>39.960</td>\n",
              "      <td>26.24</td>\n",
              "      <td>4.0</td>\n",
              "      <td>466.84</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>762138</td>\n",
              "      <td>33.270</td>\n",
              "      <td>35.22</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1097.06</td>\n",
              "      <td>649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   HazardID  latitude  longitude  intensity  economic_loss_million  \\\n",
              "0    762134    35.683      35.80        5.0                  50.00   \n",
              "1    762135    36.400      25.40        5.0                  15.00   \n",
              "2    762136    35.683      35.80        5.0                  15.00   \n",
              "3    762137    39.960      26.24        4.0                 466.84   \n",
              "4    762138    33.270      35.22        5.0                1097.06   \n",
              "\n",
              "   duration_minutes  \n",
              "0               478  \n",
              "1               476  \n",
              "2               495  \n",
              "3               275  \n",
              "4               649  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save to CSV for ArcGIS processing\n",
        "csv_path = \"D:/ArcGISProjects/GeohazardDB/tsunami_standardized.csv\"\n",
        "tsun_2concat.to_csv(csv_path, index=False)\n",
        "\n",
        "tsun_2concat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPrxykg8Wg4d",
        "outputId": "871b1091-b0b3-468d-a5e6-d9e6c05b0ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Clipped road_MNE saved at: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\road_MNE\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"\n",
        "country_layer = os.path.join(gdb_path, \"eez_country\")\n",
        "road_layer = os.path.join(gdb_path, \"roads\")  # Assuming the full global road dataset is here\n",
        "output_clip = os.path.join(gdb_path, \"road_MNE\")\n",
        "\n",
        "# Get geometry of MNE\n",
        "where_clause = \"ISO_TER1 = 'MNE'\"\n",
        "\n",
        "# Temporary layer\n",
        "arcpy.MakeFeatureLayer_management(country_layer, \"country_lyr\", where_clause)\n",
        "\n",
        "# Clip road layer\n",
        "arcpy.Clip_analysis(\n",
        "    in_features=road_layer,\n",
        "    clip_features=\"country_lyr\",\n",
        "    out_feature_class=output_clip\n",
        ")\n",
        "\n",
        "print(f\"✅ Clipped road_MNE saved at: {output_clip}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cno1dXJFWg4e",
        "outputId": "8ed5cd50-dc69-4bbd-d334-af91ff6b6aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Processing JOR (1/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOR\n",
            "⏳ Processing BDI (2/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BDI\n",
            "⏳ Processing URJ (3/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_URJ\n",
            "⏳ Processing LVA (4/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LVA\n",
            "⏳ Processing BDZ (5/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BDZ\n",
            "⏳ Processing BLR (6/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BLR\n",
            "⏳ Processing HUN (7/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HUN\n",
            "⏳ Processing TJK (8/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TJK\n",
            "⏳ Processing SOD (9/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SOD\n",
            "⏳ Processing BHS (10/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BHS\n",
            "⏳ Processing COK (11/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COK\n",
            "⏳ Processing ICH (12/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ICH\n",
            "⏳ Processing RUS (13/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_RUS\n",
            "⏳ Processing LTU (14/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LTU\n",
            "⏳ Processing ISR (15/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ISR\n",
            "⏳ Processing WLF (16/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_WLF\n",
            "⏳ Processing BRA (17/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BRA\n",
            "⏳ Processing KEN (18/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KEN\n",
            "⏳ Processing SOM (19/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SOM\n",
            "⏳ Processing COM (20/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COM\n",
            "⏳ Processing BGD (21/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BGD\n",
            "⏳ Processing IRL (22/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IRL\n",
            "⏳ Processing MHL (23/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MHL\n",
            "⏳ Processing MNE (24/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MNE\n",
            "⏳ Processing NZL (25/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NZL\n",
            "⏳ Processing SPM (26/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SPM\n",
            "⏳ Processing PRY (27/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PRY\n",
            "⏳ Processing SVK (28/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SVK\n",
            "⏳ Processing MKD (29/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MKD\n",
            "⏳ Processing PSE (30/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PSE\n",
            "⏳ Processing CMR (31/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CMR\n",
            "⏳ Processing ASK (32/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ASK\n",
            "⏳ Processing BIH (33/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BIH\n",
            "⏳ Processing ARG (34/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ARG\n",
            "⏳ Processing BEL (35/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BEL\n",
            "⏳ Processing RDA (36/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_RDA\n",
            "⏳ Processing OVN (37/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVN\n",
            "⏳ Processing TKM (38/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TKM\n",
            "⏳ Processing KEK (39/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KEK\n",
            "⏳ Processing BGR (40/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BGR\n",
            "⏳ Processing CUW (41/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CUW\n",
            "⏳ Processing POL (42/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_POL\n",
            "⏳ Processing MEX (43/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MEX\n",
            "⏳ Processing JEY (44/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JEY\n",
            "⏳ Processing NIU (45/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NIU\n",
            "⏳ Processing VGB (46/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VGB\n",
            "⏳ Processing MLI (47/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MLI\n",
            "⏳ Processing LBY (48/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LBY\n",
            "⏳ Processing THA (49/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_THA\n",
            "⏳ Processing FJI (50/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FJI\n",
            "⏳ Processing NER (51/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NER\n",
            "⏳ Processing JOE (52/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOE\n",
            "⏳ Processing LSO (53/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LSO\n",
            "⏳ Processing PYF (54/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PYF\n",
            "⏳ Processing LBR (55/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LBR\n",
            "⏳ Processing DMA (56/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DMA\n",
            "⏳ Processing MOZ (57/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MOZ\n",
            "⏳ Processing ETH (58/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ETH\n",
            "⏳ Processing UGA (59/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UGA\n",
            "⏳ Processing BVT (60/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BVT\n",
            "⏳ Processing JOF (61/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOF\n",
            "⏳ Processing UBM (62/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UBM\n",
            "⏳ Processing PAJ (63/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PAJ\n",
            "⏳ Processing DNK (64/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DNK\n",
            "⏳ Processing RÉQ (65/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_RÉQ\n",
            "⏳ Processing CRI (66/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CRI\n",
            "⏳ Processing OMN (67/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OMN\n",
            "⏳ Processing CAW (68/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CAW\n",
            "⏳ Processing SAB (69/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SAB\n",
            "⏳ Processing SUR (70/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SUR\n",
            "⏳ Processing JAN (71/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JAN\n",
            "⏳ Processing PAK (72/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PAK\n",
            "⏳ Processing GIN (73/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GIN\n",
            "⏳ Processing SAU (74/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SAU\n",
            "⏳ Processing VEZ (75/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VEZ\n",
            "⏳ Processing GEO (76/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GEO\n",
            "⏳ Processing JAC (77/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JAC\n",
            "⏳ Processing SXM (78/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SXM\n",
            "⏳ Processing CUB (79/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CUB\n",
            "⏳ Processing VUT (80/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VUT\n",
            "⏳ Processing CHE (81/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CHE\n",
            "⏳ Processing QAE (82/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_QAE\n",
            "⏳ Processing ERI (83/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ERI\n",
            "⏳ Processing AMO (84/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AMO\n",
            "⏳ Processing SWE (85/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SWE\n",
            "⏳ Processing CHP (86/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CHP\n",
            "⏳ Processing SRZ (87/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SRZ\n",
            "⏳ Processing CHB (88/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CHB\n",
            "⏳ Processing GNQ (89/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GNQ\n",
            "⏳ Processing GRC (90/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GRC\n",
            "⏳ Processing ZMB (91/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ZMB\n",
            "⏳ Processing QAJ (92/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_QAJ\n",
            "⏳ Processing MDG (93/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MDG\n",
            "⏳ Processing SYC (94/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SYC\n",
            "⏳ Processing AUS (95/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AUS\n",
            "⏳ Processing ABW (96/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ABW\n",
            "⏳ Processing TON (97/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TON\n",
            "⏳ Processing SAH (98/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SAH\n",
            "⏳ Processing KHM (99/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KHM\n",
            "⏳ Processing NLD (100/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NLD\n",
            "⏳ Processing BAV (101/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BAV\n",
            "⏳ Processing FSM (102/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FSM\n",
            "⏳ Processing SMR (103/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SMR\n",
            "⏳ Processing SJK (104/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SJK\n",
            "⏳ Processing ZGK (105/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ZGK\n",
            "⏳ Processing MRT (106/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MRT\n",
            "⏳ Processing BEN (107/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BEN\n",
            "⏳ Processing BMU (108/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BMU\n",
            "⏳ Processing MVF (109/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MVF\n",
            "⏳ Processing LCA (110/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LCA\n",
            "⏳ Processing PHL (111/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PHL\n",
            "⏳ Processing PAR (112/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PAR\n",
            "⏳ Processing OVB (113/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVB\n",
            "⏳ Processing NFK (114/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NFK\n",
            "⏳ Processing IND (115/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IND\n",
            "⏳ Processing COD (116/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COD\n",
            "⏳ Processing ZWE (117/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ZWE\n",
            "⏳ Processing SRB (118/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SRB\n",
            "⏳ Processing ASM (119/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ASM\n",
            "⏳ Processing UKR (120/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UKR\n",
            "⏳ Processing NCL (121/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NCL\n",
            "⏳ Processing GLP (122/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GLP\n",
            "⏳ Processing SLB (123/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SLB\n",
            "⏳ Processing NRU (124/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NRU\n",
            "⏳ Processing BOL (125/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BOL\n",
            "⏳ Processing AUT (126/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AUT\n",
            "⏳ Processing KGZ (127/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KGZ\n",
            "⏳ Processing ESP (128/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ESP\n",
            "⏳ Processing SYR (129/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SYR\n",
            "⏳ Processing JOK (130/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOK\n",
            "⏳ Processing UAS (131/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UAS\n",
            "⏳ Processing TUV (132/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TUV\n",
            "⏳ Processing RJT (133/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_RJT\n",
            "⏳ Processing JOT (134/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOT\n",
            "⏳ Processing SVU (135/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SVU\n",
            "⏳ Processing GIC (136/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GIC\n",
            "⏳ Processing SAZ (137/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SAZ\n",
            "⏳ Processing NPL (138/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NPL\n",
            "⏳ Processing TCD (139/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TCD\n",
            "⏳ Processing GUE (140/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GUE\n",
            "⏳ Processing EGD (141/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_EGD\n",
            "⏳ Processing SLE (142/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SLE\n",
            "⏳ Processing GRD (143/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GRD\n",
            "⏳ Processing STG (144/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_STG\n",
            "⏳ Processing FIN (145/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FIN\n",
            "⏳ Processing BFA (146/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BFA\n",
            "⏳ Processing MNG (147/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MNG\n",
            "⏳ Processing HTI (148/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HTI\n",
            "⏳ Processing MUS (149/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MUS\n",
            "⏳ Processing ALB (150/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ALB\n",
            "⏳ Processing NOF (151/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NOF\n",
            "⏳ Processing TUR (152/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TUR\n",
            "⏳ Processing GGY (153/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GGY\n",
            "⏳ Processing LII (154/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LII\n",
            "⏳ Processing PRT (155/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PRT\n",
            "⏳ Processing CXR (156/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CXR\n",
            "⏳ Processing WSM (157/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_WSM\n",
            "⏳ Processing TTO (158/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TTO\n",
            "⏳ Processing CYM (159/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CYM\n",
            "⏳ Processing VAT (160/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VAT\n",
            "⏳ Processing UNW (161/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UNW\n",
            "⏳ Processing LAO (162/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LAO\n",
            "⏳ Processing MDA (163/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MDA\n",
            "⏳ Processing BTN (164/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BTN\n",
            "⏳ Processing SSD (165/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SSD\n",
            "⏳ Processing JOH (166/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOH\n",
            "⏳ Processing JOD (167/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOD\n",
            "⏳ Processing TLS (168/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TLS\n",
            "⏳ Processing JOG (169/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOG\n",
            "⏳ Processing NGA (170/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NGA\n",
            "⏳ Processing WAW (171/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_WAW\n",
            "⏳ Processing OVX (172/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVX\n",
            "⏳ Processing VNM (173/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VNM\n",
            "⏳ Processing SIN (174/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SIN\n",
            "⏳ Processing ESH (175/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ESH\n",
            "⏳ Processing DLL (176/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DLL\n",
            "⏳ Processing TWN (177/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TWN\n",
            "⏳ Processing ITA (178/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ITA\n",
            "⏳ Processing PEG (179/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PEG\n",
            "⏳ Processing JOO (180/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOO\n",
            "⏳ Processing GHA (181/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GHA\n",
            "⏳ Processing ARE (182/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ARE\n",
            "⏳ Processing MSR (183/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MSR\n",
            "⏳ Processing FLK (184/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FLK\n",
            "⏳ Processing IDN (185/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IDN\n",
            "⏳ Processing PRK (186/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PRK\n",
            "⏳ Processing FRD (187/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FRD\n",
            "⏳ Processing MAY (188/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MAY\n",
            "⏳ Processing MAR (189/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MAR\n",
            "⏳ Processing SDN (190/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SDN\n",
            "⏳ Processing BAS (191/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BAS\n",
            "⏳ Processing RWN (192/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_RWN\n",
            "⏳ Processing MCO (193/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MCO\n",
            "⏳ Processing OVV (194/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVV\n",
            "⏳ Processing LUX (195/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LUX\n",
            "⏳ Processing TUN (196/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TUN\n",
            "⏳ Processing BRN (197/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BRN\n",
            "⏳ Processing MNP (198/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MNP\n",
            "⏳ Processing DHK (199/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DHK\n",
            "⏳ Processing GDY (200/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GDY\n",
            "⏳ Processing TKL (201/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TKL\n",
            "⏳ Processing ARM (202/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ARM\n",
            "⏳ Processing EVZ (203/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_EVZ\n",
            "⏳ Processing BWA (204/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BWA\n",
            "⏳ Processing SLV (205/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SLV\n",
            "⏳ Processing QHB (206/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_QHB\n",
            "⏳ Processing ROU (207/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ROU\n",
            "⏳ Processing KWT (208/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KWT\n",
            "⏳ Processing GAB (209/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GAB\n",
            "⏳ Processing WLM (210/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_WLM\n",
            "⏳ Processing JOW (211/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOW\n",
            "⏳ Processing AIA (212/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AIA\n",
            "⏳ Processing HMD (213/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HMD\n",
            "⏳ Processing MAF (214/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MAF\n",
            "⏳ Processing COJ (215/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COJ\n",
            "⏳ Processing CYP (216/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CYP\n",
            "⏳ Processing GUM (217/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GUM\n",
            "⏳ Processing GRL (218/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GRL\n",
            "⏳ Processing IMN (219/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IMN\n",
            "⏳ Processing JOP (220/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOP\n",
            "⏳ Processing UNM (221/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UNM\n",
            "⏳ Processing CCK (222/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CCK\n",
            "⏳ Processing ECR (223/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ECR\n",
            "⏳ Processing CIV (224/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CIV\n",
            "⏳ Processing NGL (225/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NGL\n",
            "⏳ Processing COG (226/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COG\n",
            "⏳ Processing JAQ (227/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JAQ\n",
            "⏳ Processing AGO (228/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AGO\n",
            "⏳ Processing GTM (229/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GTM\n",
            "⏳ Processing CAF (230/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CAF\n",
            "⏳ Processing OKD (231/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OKD\n",
            "⏳ Processing YYJ (232/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_YYJ\n",
            "⏳ Processing BOF (233/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BOF\n",
            "⏳ Processing AZE (234/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AZE\n",
            "⏳ Processing COQ (235/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_COQ\n",
            "⏳ Processing BDY (236/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BDY\n",
            "⏳ Processing HOD (237/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HOD\n",
            "⏳ Processing TRM (238/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TRM\n",
            "⏳ Processing CRC (239/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CRC\n",
            "⏳ Processing MWI (240/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MWI\n",
            "⏳ Processing TCA (241/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TCA\n",
            "⏳ Processing LKA (242/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LKA\n",
            "⏳ Processing SEF (243/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SEF\n",
            "⏳ Processing MTQ (244/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MTQ\n",
            "⏳ Processing QGI (245/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_QGI\n",
            "⏳ Processing MMR (246/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MMR\n",
            "⏳ Processing MDV (247/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MDV\n",
            "⏳ Processing UZB (248/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_UZB\n",
            "⏳ Processing JOU (249/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOU\n",
            "⏳ Processing SWZ (250/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SWZ\n",
            "⏳ Processing DOJ (251/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DOJ\n",
            "⏳ Processing HOJ (252/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HOJ\n",
            "⏳ Processing EMQ (253/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_EMQ\n",
            "⏳ Processing LBN (254/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LBN\n",
            "⏳ Processing BLM (255/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BLM\n",
            "⏳ Processing PUR (256/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PUR\n",
            "⏳ Processing QIB (257/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_QIB\n",
            "⏳ Processing MUJ (258/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MUJ\n",
            "⏳ Processing GIB (259/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GIB\n",
            "⏳ Processing JOL (260/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOL\n",
            "⏳ Processing KNA (261/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KNA\n",
            "⏳ Processing JUW (262/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JUW\n",
            "⏳ Processing BHR (263/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BHR\n",
            "⏳ Processing PME (264/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PME\n",
            "⏳ Processing AND (265/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AND\n",
            "⏳ Processing CZE (266/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CZE\n",
            "⏳ Processing PHV (267/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PHV\n",
            "⏳ Processing NIC (268/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NIC\n",
            "⏳ Processing KAZ (269/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_KAZ\n",
            "⏳ Processing GNB (270/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GNB\n",
            "⏳ Processing OVZ (271/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVZ\n",
            "⏳ Processing IRN (272/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IRN\n",
            "⏳ Processing JPN (273/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JPN\n",
            "⏳ Processing YEM (274/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_YEM\n",
            "⏳ Processing SVN (275/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SVN\n",
            "⏳ Processing AFG (276/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_AFG\n",
            "⏳ Processing JUD (277/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JUD\n",
            "⏳ Processing TZA (278/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TZA\n",
            "⏳ Processing JOM (279/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOM\n",
            "⏳ Processing PCN (280/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PCN\n",
            "⏳ Processing DEU (281/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DEU\n",
            "⏳ Processing ISP (282/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ISP\n",
            "⏳ Processing JON (283/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JON\n",
            "⏳ Processing OVE (284/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVE\n",
            "⏳ Processing GUF (285/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GUF\n",
            "⏳ Processing IRZ (286/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_IRZ\n",
            "⏳ Processing NAM (287/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_NAM\n",
            "⏳ Processing BEC (288/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BEC\n",
            "⏳ Processing ZAF (289/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ZAF\n",
            "⏳ Processing OGL (290/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OGL\n",
            "⏳ Processing EUO (291/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_EUO\n",
            "⏳ Processing JOV (292/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOV\n",
            "⏳ Processing MLT (293/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MLT\n",
            "⏳ Processing SGS (294/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SGS\n",
            "⏳ Processing VCT (295/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VCT\n",
            "⏳ Processing OVA (296/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVA\n",
            "⏳ Processing OVQ (297/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVQ\n",
            "⏳ Processing PLW (298/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PLW\n",
            "⏳ Processing ATG (299/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_ATG\n",
            "⏳ Processing DJI (300/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DJI\n",
            "⏳ Processing SAN (301/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SAN\n",
            "⏳ Processing VIR (302/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_VIR\n",
            "⏳ Processing SGP (303/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SGP\n",
            "⏳ Processing JOI (304/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOI\n",
            "⏳ Processing CPV (305/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CPV\n",
            "⏳ Processing CSH (306/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_CSH\n",
            "⏳ Processing DZA (307/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_DZA\n",
            "⏳ Processing JOB (308/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOB\n",
            "⏳ Processing JOZ (309/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOZ\n",
            "⏳ Processing EST (310/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_EST\n",
            "⏳ Processing TGO (311/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_TGO\n",
            "⏳ Processing MYT (312/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_MYT\n",
            "⏳ Processing JOA (313/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOA\n",
            "⏳ Processing GMB (314/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_GMB\n",
            "⏳ Processing PAN (315/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_PAN\n",
            "⏳ Processing OVH (316/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVH\n",
            "⏳ Processing JOY (317/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOY\n",
            "⏳ Processing JOX (318/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOX\n",
            "⏳ Processing HEJ (319/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_HEJ\n",
            "⏳ Processing BRR (320/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_BRR\n",
            "⏳ Processing FTR (321/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FTR\n",
            "⏳ Processing SNA (322/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_SNA\n",
            "⏳ Processing LIE (323/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LIE\n",
            "⏳ Processing OVP (324/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OVP\n",
            "⏳ Processing LPL (325/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_LPL\n",
            "⏳ Processing JOQ (326/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_JOQ\n",
            "⏳ Processing FAO (327/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_FAO\n",
            "⏳ Processing OQU (328/328)...\n",
            "  ✅ Near table created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\near_OQU\n",
            "✅ All tsunami points merged into D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\tsun_dist\n",
            "✅ Lines created: D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\\compiled_near_lines_tsun\n",
            "✅ All tsunami near analysis completed in 256.62 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "# Paths\n",
        "project_folder = r\"D:\\ArcGISProjects\\GeohazardDB\"\n",
        "input_csv = os.path.join(project_folder, \"tsunami_standardized.csv\")\n",
        "ndis_gdb = os.path.join(project_folder, \"NDIS.gdb\")\n",
        "road_gdb = os.path.join(project_folder, \"GeohazardDB.gdb\")\n",
        "road_layer_template = os.path.join(road_gdb, \"roads\")\n",
        "country_layer = os.path.join(project_folder, \"GeohazardDB.gdb\", \"eez_country\")\n",
        "\n",
        "# Convert CSV to point layer\n",
        "tsun_layer = os.path.join(ndis_gdb, \"tsun_input\")\n",
        "arcpy.management.XYTableToPoint(\n",
        "    in_table=input_csv,\n",
        "    out_feature_class=tsun_layer,\n",
        "    x_field=\"longitude\",\n",
        "    y_field=\"latitude\",\n",
        "    coordinate_system=arcpy.SpatialReference(4326)\n",
        ")\n",
        "\n",
        "# Near analysis preparation\n",
        "ghz_list = []\n",
        "near_tables = []\n",
        "\n",
        "total_countries = int(arcpy.GetCount_management(country_layer)[0])\n",
        "\n",
        "with arcpy.da.SearchCursor(country_layer, [\"ISO_TER1\", \"SHAPE@\"]) as country_cursor:\n",
        "    for index, row in enumerate(country_cursor, start=1):\n",
        "        iso = row[0]\n",
        "        shape = row[1]\n",
        "        print(f\"⏳ Processing {iso} ({index}/{total_countries})...\")\n",
        "\n",
        "        tsun_clip = os.path.join(ndis_gdb, f\"tsun_{iso}\")\n",
        "        road_clip = os.path.join(road_gdb, f\"road_{iso}\")\n",
        "        near_table = os.path.join(ndis_gdb, f\"near_{iso}\")\n",
        "\n",
        "        # Clip tsunami points\n",
        "        if arcpy.Exists(tsun_clip):\n",
        "            arcpy.Delete_management(tsun_clip)\n",
        "        arcpy.analysis.Clip(tsun_layer, shape, tsun_clip)\n",
        "\n",
        "        # Run Near (roads already pre-clipped)\n",
        "        if arcpy.Exists(near_table):\n",
        "            arcpy.Delete_management(near_table)\n",
        "        arcpy.analysis.GenerateNearTable(\n",
        "            in_features=tsun_clip,\n",
        "            near_features=road_clip,\n",
        "            out_table=near_table,\n",
        "            location=\"LOCATION\",\n",
        "            angle=\"ANGLE\",\n",
        "            closest=\"CLOSEST\",\n",
        "            method=\"GEODESIC\"\n",
        "        )\n",
        "        print(f\"  ✅ Near table created: {near_table}\")\n",
        "        near_tables.append(near_table)\n",
        "\n",
        "        # Add 'distance' to tsun_clip\n",
        "        if \"distance\" not in [f.name for f in arcpy.ListFields(tsun_clip)]:\n",
        "            arcpy.AddField_management(tsun_clip, \"distance\", \"DOUBLE\")\n",
        "\n",
        "        with arcpy.da.UpdateCursor(tsun_clip, [\"OBJECTID\", \"distance\"]) as up_cursor:\n",
        "            for up_row in up_cursor:\n",
        "                oid = up_row[0]\n",
        "                with arcpy.da.SearchCursor(near_table, [\"IN_FID\", \"NEAR_DIST\"]) as near_cursor:\n",
        "                    for near_row in near_cursor:\n",
        "                        if near_row[0] == oid:\n",
        "                            up_row[1] = near_row[1]\n",
        "                            up_cursor.updateRow(up_row)\n",
        "                            break\n",
        "\n",
        "        # Add 'HazardID' to near table\n",
        "        if \"HazardID\" not in [f.name for f in arcpy.ListFields(near_table)]:\n",
        "            arcpy.AddField_management(near_table, \"HazardID\", \"TEXT\")\n",
        "\n",
        "        with arcpy.da.UpdateCursor(near_table, [\"IN_FID\", \"HazardID\"]) as cursor:\n",
        "            for row in cursor:\n",
        "                with arcpy.da.SearchCursor(tsun_clip, [\"OBJECTID\", \"HazardID\"]) as src:\n",
        "                    for src_row in src:\n",
        "                        if row[0] == src_row[0]:\n",
        "                            row[1] = src_row[1]\n",
        "                            cursor.updateRow(row)\n",
        "                            break\n",
        "\n",
        "        ghz_list.append(tsun_clip)\n",
        "\n",
        "# Merge tsunami point results\n",
        "merged_output = os.path.join(ndis_gdb, \"tsun_dist\")\n",
        "if arcpy.Exists(merged_output):\n",
        "    arcpy.Delete_management(merged_output)\n",
        "arcpy.Merge_management(ghz_list, merged_output)\n",
        "print(f\"✅ All tsunami points merged into {merged_output}\")\n",
        "\n",
        "# Merge near tables\n",
        "compiled_near_table = os.path.join(ndis_gdb, \"compiled_near_table_tsun\")\n",
        "if arcpy.Exists(compiled_near_table):\n",
        "    arcpy.Delete_management(compiled_near_table)\n",
        "\n",
        "arcpy.CreateTable_management(ndis_gdb, \"compiled_near_table_tsun\")\n",
        "for field in [(\"FROM_X\", \"DOUBLE\"), (\"FROM_Y\", \"DOUBLE\"), (\"NEAR_X\", \"DOUBLE\"),\n",
        "              (\"NEAR_Y\", \"DOUBLE\"), (\"NEAR_FID\", \"LONG\"), (\"HazardID\", \"TEXT\")]:\n",
        "    arcpy.AddField_management(compiled_near_table, field[0], field[1])\n",
        "\n",
        "with arcpy.da.InsertCursor(compiled_near_table, [\"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\", \"NEAR_FID\", \"HazardID\"]) as insert_cursor:\n",
        "    for table in near_tables:\n",
        "        with arcpy.da.SearchCursor(table, [\"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\", \"NEAR_FID\", \"HazardID\"]) as cursor:\n",
        "            for row in cursor:\n",
        "                insert_cursor.insertRow(row)\n",
        "\n",
        "# Create line layer\n",
        "line_fc = os.path.join(ndis_gdb, \"compiled_near_lines_tsun\")\n",
        "if arcpy.Exists(line_fc):\n",
        "    arcpy.Delete_management(line_fc)\n",
        "\n",
        "arcpy.XYToLine_management(\n",
        "    compiled_near_table, line_fc,\n",
        "    \"FROM_X\", \"FROM_Y\", \"NEAR_X\", \"NEAR_Y\"\n",
        ")\n",
        "print(f\"✅ Lines created: {line_fc}\")\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(f\"✅ All tsunami near analysis completed in {elapsed/60:.2f} minutes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rAeg7xvWg4e"
      },
      "outputs": [],
      "source": [
        "tsun_fixed = gpd.read_file(r\"D:\\ArcGISProjects\\GeohazardDB\\NDIS.gdb\", layer=\"tsun_dist\")\n",
        "\n",
        "# Step 1: Drop existing tsunami rows from ghz_pap\n",
        "ghz_no_tsun = ghz_pap[ghz_pap[\"HazardType\"] != \"Tsunami\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzahC1HNWg4f"
      },
      "outputs": [],
      "source": [
        "tsun_fixed[\"HazardType\"] = \"Tsunami\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kInZOSCYWg4f"
      },
      "outputs": [],
      "source": [
        "# Step 3: Concatenate both\n",
        "ghz_all = pd.concat([ghz_no_tsun, tsun_fixed], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mgOfanbWg4f",
        "outputId": "3b515bf4-0303-46d3-90b8-a95b9b8a1bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HazardType\n",
            "Earthquake    85569\n",
            "Fault         29304\n",
            "Landslide       357\n",
            "Tsunami          49\n",
            "Volcano          46\n",
            "Name: count, dtype: int64\n",
            "Total rows with NaN in distance: 115325\n"
          ]
        }
      ],
      "source": [
        "# Check for NaN values in the \"distance\" field\n",
        "nan_rows = ghz_all[ghz_all[\"distance\"].isna()]\n",
        "\n",
        "# Display count by HazardType (if field exists)\n",
        "if \"HazardType\" in nan_rows.columns:\n",
        "    print(nan_rows[\"HazardType\"].value_counts())\n",
        "else:\n",
        "    print(\"HazardType column not found in the data.\")\n",
        "\n",
        "# Optionally: show how many total\n",
        "print(f\"Total rows with NaN in distance: {len(nan_rows)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw6G9yYoWg4g",
        "outputId": "bf30a1c9-5254-4786-a108-bf895704bd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1938335 entries, 0 to 1938334\n",
            "Data columns (total 11 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   travel_time            float64\n",
            " 9   cpm_total_time         float64\n",
            " 10  geometry               object \n",
            "dtypes: float64(8), int64(1), object(2)\n",
            "memory usage: 162.7+ MB\n"
          ]
        }
      ],
      "source": [
        "ghz_all.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SotFshGxWg4g",
        "outputId": "23f4ce12-110b-4143-ddf9-a9b36ddb3306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1938335 entries, 0 to 1938334\n",
            "Data columns (total 9 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   geometry               object \n",
            "dtypes: float64(6), int64(1), object(2)\n",
            "memory usage: 133.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Clean up temporary columns\n",
        "ghz_all.drop(columns=[\"cpm_total_time\", \"travel_time\"], inplace=True)\n",
        "ghz_all.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl4YMnQuWg4g"
      },
      "outputs": [],
      "source": [
        "ghz_all.to_csv(r\"D:\\NDIS_Database\\ghz_paper2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnrpjvtPWg4h",
        "outputId": "cf13f1ba-3077-47ae-9096-e6621f469d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved integer raster to: nasapopct_int.tif\n"
          ]
        }
      ],
      "source": [
        "import arcpy\n",
        "from arcpy.sa import *\n",
        "\n",
        "arcpy.CheckOutExtension(\"Spatial\")\n",
        "arcpy.env.overwriteOutput = True\n",
        "arcpy.env.workspace = r\"D:\\NDIS_Database\\12_Population_synthetic\"\n",
        "\n",
        "# Input raster\n",
        "input_raster = \"nasapopct.tif\"\n",
        "output_raster = \"nasapopct_int.tif\"\n",
        "\n",
        "# Convert float to int (rounded)\n",
        "int_ras = Int(Raster(input_raster) + 0.5)  # round to nearest integer\n",
        "\n",
        "# Save to file\n",
        "int_ras.save(output_raster)\n",
        "\n",
        "print(f\"✅ Saved integer raster to: {output_raster}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF7GmC4jWg4h",
        "outputId": "03be5d3a-44ac-4a0e-bf71-9ddb3fb29b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S32\n"
          ]
        }
      ],
      "source": [
        "# Confirm type\n",
        "r = arcpy.Raster(r\"D:\\NDIS_Database\\12_Population_synthetic\\nasapopct_int.tif\")\n",
        "print(r.pixelType)  # Should now be 'S32' or similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkRw6U8jWg4h",
        "outputId": "6607f95c-c93b-40e4-9d80-640c50ffab95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Forcing Int raster (wrapped): S32\n",
            "Total matching FCs: 984\n",
            "⏳ [1/984] Processing: ghz_JOR\n",
            "❌ Error in ghz_JOR: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [2/984] Processing: ghz_BDI\n",
            "❌ Error in ghz_BDI: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [3/984] Processing: ghz_URJ\n",
            "❌ Error in ghz_URJ: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [4/984] Processing: ghz_LVA\n",
            "❌ Error in ghz_LVA: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [5/984] Processing: ghz_BDZ\n",
            "❌ Error in ghz_BDZ: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [6/984] Processing: ghz_BLR\n",
            "❌ Error in ghz_BLR: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [7/984] Processing: ghz_HUN\n",
            "❌ Error in ghz_HUN: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [8/984] Processing: ghz_TJK\n",
            "❌ Error in ghz_TJK: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [9/984] Processing: ghz_SOD\n",
            "❌ Error in ghz_SOD: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [10/984] Processing: ghz_BHS\n",
            "❌ Error in ghz_BHS: ERROR 010139: Input raster %1 is not integer type.\n",
            "Failed to execute (ZonalStatisticsAsTable).\n",
            "\n",
            "⏳ [11/984] Processing: ghz_COK\n"
          ]
        }
      ],
      "source": [
        "# === SETUP ===\n",
        "arcpy.CheckOutExtension(\"Spatial\")\n",
        "\n",
        "# Paths and constants\n",
        "project_folder = r\"D:\\ArcGISProjects\\GeohazardDB\"\n",
        "gdb_ghz = os.path.join(project_folder, \"GeohazardDB.gdb\")\n",
        "gdb_ndis = os.path.join(project_folder, \"NDIS.gdb\")\n",
        "country_layer = os.path.join(gdb_ghz, \"eez_country\")\n",
        "population_raster = r\"D:\\NDIS_Database\\12_Population_synthetic\\nasapopct_int.tif\"\n",
        "output_field = \"pop_sum\"\n",
        "log_path = os.path.join(project_folder, \"pop_stat_log.txt\")\n",
        "\n",
        "# Load as Raster to ensure integer pixel type is respected\n",
        "value_raster = arcpy.sa.Int(arcpy.Raster(population_raster))\n",
        "print(f\"✅ Forcing Int raster (wrapped): {value_raster.pixelType}\")\n",
        "\n",
        "# Extract ISO codes from country layer\n",
        "iso_codes = set()\n",
        "with arcpy.da.SearchCursor(country_layer, [\"ISO_TER1\"]) as cursor:\n",
        "    for row in cursor:\n",
        "        iso = row[0]\n",
        "        if iso:\n",
        "            iso_codes.add(iso)\n",
        "\n",
        "# Find feature classes matching the ISO suffixes\n",
        "def get_matching_fcs(gdb_path, prefix):\n",
        "    arcpy.env.workspace = gdb_path\n",
        "    return [fc for fc in arcpy.ListFeatureClasses(f\"{prefix}_*\") if fc.split(\"_\")[-1] in iso_codes]\n",
        "\n",
        "ghz_fc = get_matching_fcs(gdb_ghz, \"ghz\")\n",
        "nuc_fc = get_matching_fcs(gdb_ghz, \"nuc\")\n",
        "tsun_fc = get_matching_fcs(gdb_ndis, \"tsun\")\n",
        "all_fc = ghz_fc + nuc_fc + tsun_fc\n",
        "\n",
        "print(f\"Total matching FCs: {len(all_fc)}\")\n",
        "\n",
        "# === ZONAL STATISTICS LOOP ===\n",
        "start_total = time.time()\n",
        "\n",
        "with open(log_path, \"w\", encoding=\"utf-8\") as log:\n",
        "    for idx, fc in enumerate(all_fc, start=1):\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            print(f\"⏳ [{idx}/{len(all_fc)}] Processing: {fc}\")\n",
        "            log.write(f\"[START] {fc}\\n\")\n",
        "\n",
        "            # Determine full path\n",
        "            if fc in tsun_fc:\n",
        "                fc_path = os.path.join(gdb_ndis, fc)\n",
        "            else:\n",
        "                fc_path = os.path.join(gdb_ghz, fc)\n",
        "\n",
        "            # Add population field if missing\n",
        "            field_names = [f.name for f in arcpy.ListFields(fc_path)]\n",
        "            if output_field not in field_names:\n",
        "                arcpy.AddField_management(fc_path, output_field, \"DOUBLE\")\n",
        "\n",
        "            # Zonal statistics as table\n",
        "            zone_table = os.path.join(\"in_memory\", f\"{fc}_zonal\")\n",
        "            arcpy.sa.ZonalStatisticsAsTable(\n",
        "                in_zone_data=fc_path,\n",
        "                zone_field=\"OBJECTID\",\n",
        "                in_value_raster=value_raster,\n",
        "                out_table=zone_table,\n",
        "                ignore_nodata=\"DATA\",\n",
        "                statistics_type=\"SUM\"\n",
        "            )\n",
        "\n",
        "            # Join and transfer values\n",
        "            arcpy.JoinField_management(\n",
        "                in_data=fc_path,\n",
        "                in_field=\"OBJECTID\",\n",
        "                join_table=zone_table,\n",
        "                join_field=\"OBJECTID\",\n",
        "                fields=[\"SUM\"]\n",
        "            )\n",
        "\n",
        "            if \"SUM\" in [f.name for f in arcpy.ListFields(fc_path)]:\n",
        "                with arcpy.da.UpdateCursor(fc_path, [\"SUM\", output_field]) as cursor:\n",
        "                    for row in cursor:\n",
        "                        row[1] = row[0]\n",
        "                        cursor.updateRow(row)\n",
        "                arcpy.DeleteField_management(fc_path, [\"SUM\"])\n",
        "\n",
        "            elapsed = round(time.time() - start_time, 2)\n",
        "            log.write(f\"[OK] {fc} completed in {elapsed} sec\\n\")\n",
        "            print(f\"✅ Done in {elapsed} sec\")\n",
        "\n",
        "        except Exception as e:\n",
        "            log.write(f\"[FAIL] {fc} error: {str(e)}\\n\")\n",
        "            print(f\"❌ Error in {fc}: {e}\")\n",
        "\n",
        "        # Clear in_memory and force garbage collection\n",
        "        arcpy.Delete_management(\"in_memory\")\n",
        "        gc.collect()\n",
        "\n",
        "    total_elapsed = round(time.time() - start_total, 2)\n",
        "    log.write(f\"\\n✅ All done in {total_elapsed / 60:.2f} min\\n\")\n",
        "    print(f\"\\n✅ All done in {total_elapsed / 60:.2f} min\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnlSuuVvWg4i"
      },
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_wCxFHSWg4i"
      },
      "source": [
        "# Statistics of Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44fQlT9WWg4i"
      },
      "outputs": [],
      "source": [
        "# Set the path to this geodatabase\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"  # This gdb path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpFVKAGOWg4j",
        "outputId": "71ec4bdc-7064-4e95-ab55-01180e3e727b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1855013 entries, 0 to 1855012\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Dtype  \n",
            "---  ------      -----  \n",
            " 0   OBJECTID    int64  \n",
            " 1   Shape       object \n",
            " 2   HazardID    float64\n",
            " 3   latitude    float64\n",
            " 4   longitude   float64\n",
            " 5   HazardType  int64  \n",
            " 6   distance    float64\n",
            "dtypes: float64(4), int64(2), object(1)\n",
            "memory usage: 99.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Set the path to this geodatabase\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"  # This gdb path\n",
        "# Specify the feature class name\n",
        "ghz_dist = \"ghz_dist\"  # Geohazard feature class\n",
        "ghz_path = f\"{gdb_path}\\\\{ghz_dist}\"\n",
        "\n",
        "# Use arcpy to create a list of fields\n",
        "ghz_fields = [f.name for f in arcpy.ListFields(f\"{gdb_path}\\\\{ghz_dist}\")]\n",
        "\n",
        "# Use arcpy to create a search cursor and load the data into a list of dictionaries\n",
        "ghz_data = []\n",
        "with arcpy.da.SearchCursor(f\"{gdb_path}\\\\{ghz_dist}\", ghz_fields) as cursor:\n",
        "    for row in cursor:\n",
        "        ghz_data.append(dict(zip(ghz_fields, row)))\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "ghzdf = pd.DataFrame(ghz_data)\n",
        "ghzdf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzvbqBqzWg4k",
        "outputId": "70f20f79-0128-470b-a77d-bb940f841804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of NaN values present: 36489\n"
          ]
        }
      ],
      "source": [
        "nan_in_ghz = ghzdf.isnull().sum().sum()\n",
        "\n",
        "# printing the number of values present in\n",
        "# the whole dataframe\n",
        "print('Number of NaN values present: ' + str(nan_in_ghz))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uiLM2a0Wg4k",
        "outputId": "5465413f-4505-40f6-ccc7-c29c47199016"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-9543"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1845470-1855013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMYCsK8DWg4l",
        "outputId": "bd9e29e1-6e6f-4c1c-a8ec-0bc0b3d1ef52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned data written to: D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\\cleaned_geohazard_data\n"
          ]
        }
      ],
      "source": [
        "geohazard_layer = os.path.join(gdb_path, \"ghz_dist\")\n",
        "\n",
        "# Define the output feature class\n",
        "output_fc = os.path.join(gdb_path, \"cleaned_geohazard_data\")\n",
        "\n",
        "# Retrieve data from feature class and store it in DataFrame\n",
        "fields = [\"OBJECTID\", \"Shape@\", \"HazardID\", \"latitude\", \"longitude\", \"HazardType\", \"distance\"]\n",
        "data = []\n",
        "\n",
        "# Use SearchCursor to extract data from feature class\n",
        "with arcpy.da.SearchCursor(geohazard_layer, fields) as cursor:\n",
        "    for row in cursor:\n",
        "        # Separate geometry from the non-geometry fields\n",
        "        geometry = row[1]  # Shape@ is at index 1\n",
        "        data.append(row[:1] + (geometry,) + row[2:])  # Append geometry separately\n",
        "\n",
        "# Create DataFrame without geometry\n",
        "df = pd.DataFrame(data, columns=[\"OBJECTID\", \"Shape@\", \"HazardID\", \"latitude\", \"longitude\", \"HazardType\", \"distance\"])\n",
        "\n",
        "# Convert 'distance' field to numeric, handling errors as NaN\n",
        "df['distance'] = pd.to_numeric(df['distance'], errors='coerce')\n",
        "\n",
        "# Filter out rows with NaN distance values\n",
        "df_no_nulls = df[df['distance'].notna()]\n",
        "\n",
        "# Handle duplicates by HazardID (keep row with smallest distance)\n",
        "df_no_nulls = df_no_nulls.loc[df_no_nulls.groupby('HazardID')['distance'].idxmin()]\n",
        "\n",
        "# Create the output feature class by keeping the geometry\n",
        "arcpy.management.CreateFeatureclass(\n",
        "    out_path=gdb_path,\n",
        "    out_name=\"cleaned_geohazard_data\",\n",
        "    geometry_type=\"POINT\",  # Change to 'POINT' if the geometry is a point\n",
        "    template=geohazard_layer,  # Copy schema from the original feature class\n",
        "    spatial_reference=arcpy.Describe(geohazard_layer).spatialReference\n",
        ")\n",
        "\n",
        "# Insert cleaned data into the new feature class using InsertCursor\n",
        "with arcpy.da.InsertCursor(output_fc, [\"SHAPE@\", \"HazardID\", \"latitude\", \"longitude\", \"HazardType\", \"distance\"]) as cursor:\n",
        "    for idx, row in df_no_nulls.iterrows():\n",
        "        geometry = row['Shape@']  # Retrieve geometry separately\n",
        "        cursor.insertRow([geometry, row['HazardID'], row['latitude'], row['longitude'], row['HazardType'], row['distance']])\n",
        "\n",
        "print(f\"Cleaned data written to: {output_fc}\")\n",
        "# Play sound to notify that it's done\n",
        "# playsound(r\"C:\\Windows\\Media\\Alarm09.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Vu92hFWg4s",
        "outputId": "1ec8cb58-253b-4108-b651-4e92a3f842b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:/Users/Dell/AppData/Local/Temp/ArcGISProTemp14044/xpython_14044/2550031772.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  ghz_pop = pd.read_csv(r\"D:\\NDIS_Database\\ghz_pop.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1930000 entries, 0 to 1929999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   travel_time            float64\n",
            " 9   cpm_total_time         float64\n",
            " 10  geometry               object \n",
            " 11  pop                    float64\n",
            " 12  pop_flagged            object \n",
            "dtypes: float64(9), int64(1), object(3)\n",
            "memory usage: 191.4+ MB\n"
          ]
        }
      ],
      "source": [
        "ghz_pop = pd.read_csv(r\"D:\\NDIS_Database\\ghz_pop.csv\")\n",
        "ghz_pop.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEmQPlagWg4t",
        "outputId": "27c39934-849d-45e5-875d-a062a2adebff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total problematic rows: 1366311\n"
          ]
        }
      ],
      "source": [
        "# Find rows where pop is inf, -inf, or NaN\n",
        "mask = ~np.isfinite(ghz_pop[\"pop\"])\n",
        "problematic_rows = ghz_pop[mask]\n",
        "\n",
        "print(f\"Total problematic rows: {len(problematic_rows)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-3ASw59Wg4t"
      },
      "source": [
        "-----------------------\n",
        "# Population Handle inf\n",
        "--------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJbvSctRWg4u",
        "outputId": "ce2ee0ed-abb1-4aeb-9869-0c3d15a2488c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1938335 entries, 0 to 1938334\n",
            "Data columns (total 9 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   geometry               object \n",
            "dtypes: float64(6), int64(1), object(2)\n",
            "memory usage: 133.1+ MB\n"
          ]
        }
      ],
      "source": [
        "ghz_pap = pd.read_csv(r\"D:\\NDIS_Database\\ghz_paper2.csv\")\n",
        "ghz_pap.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovTVV5TTWg4u",
        "outputId": "2de1a818-ca56-4c27-c088-dcf98bdd89c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRS: EPSG:4326\n",
            "Bounds: BoundingBox(left=-180.0, bottom=-90.0, right=179.99999999999983, top=89.99999999999991)\n",
            "Res: (0.00833333333333333, 0.00833333333333333)\n",
            "NoData: -3.4028230607370965e+38\n",
            "Dtype: float32\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with rasterio.open(r\"D:/NDIS_Database/12_Population_synthetic/nasapopct.tif\") as src:\n",
        "    print(\"CRS:\", src.crs)\n",
        "    print(\"Bounds:\", src.bounds)\n",
        "    print(\"Res:\", src.res)\n",
        "    print(\"NoData:\", src.nodata)\n",
        "    print(\"Dtype:\", src.dtypes[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMEda_AbWg4u",
        "outputId": "2a42fd4c-a8f7-4c76-ad28-099d88c9b187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRS: EPSG:4326\n",
            "Bounds: BoundingBox(left=-180.0, bottom=-90.0, right=179.99999999999983, top=89.99999999999991)\n",
            "Res: (0.00833333333333333, 0.00833333333333333)\n",
            "NoData: -3.4028230607370965e+38\n",
            "Dtype: float32\n",
            "\n",
            "Value stats:\n",
            "  NaNs: 0\n",
            "  Infs: 0\n",
            "  NoData: 710450054\n",
            "  Zeros: 40311602\n",
            "  Valid (>0): 182358344\n"
          ]
        }
      ],
      "source": [
        "src_path = r\"D:/NDIS_Database/12_Population_synthetic/nasapopct.tif\"\n",
        "\n",
        "with rasterio.open(src_path) as src:\n",
        "    data = src.read(1)\n",
        "\n",
        "    print(\"CRS:\", src.crs)\n",
        "    print(\"Bounds:\", src.bounds)\n",
        "    print(\"Res:\", src.res)\n",
        "    print(\"NoData:\", src.nodata)\n",
        "    print(\"Dtype:\", src.dtypes[0])\n",
        "\n",
        "    # Check value counts\n",
        "    nodata_val = src.nodata\n",
        "    print(\"\\nValue stats:\")\n",
        "    print(\"  NaNs:\", np.isnan(data).sum())\n",
        "    print(\"  Infs:\", np.isinf(data).sum())\n",
        "    print(\"  NoData:\", np.sum(data == nodata_val))\n",
        "    print(\"  Zeros:\", np.sum(data == 0))\n",
        "    print(\"  Valid (>0):\", np.sum(data > 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdIFOpgLWg4v",
        "outputId": "9d7dc4fc-d662-4713-f64b-11fc734ea220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved cleaned raster to: D:/NDIS_Database/12_Population_synthetic/nasapopct_fixed_int.tif\n"
          ]
        }
      ],
      "source": [
        "dst_path = r\"D:/NDIS_Database/12_Population_synthetic/nasapopct_fixed_int.tif\"\n",
        "\n",
        "with rasterio.open(src_path) as src:\n",
        "    profile = src.profile\n",
        "    data = src.read(1)\n",
        "\n",
        "    # Replace extreme NoData and other invalids\n",
        "    data[data == src.nodata] = 0\n",
        "    data[~np.isfinite(data)] = 0\n",
        "\n",
        "    # Convert to integer\n",
        "    int_data = np.round(data).astype(\"int32\")\n",
        "    profile.update(dtype=\"int32\", nodata=0)\n",
        "\n",
        "    with rasterio.open(dst_path, \"w\", **profile) as dst:\n",
        "        dst.write(int_data, 1)\n",
        "\n",
        "print(\"✅ Saved cleaned raster to:\", dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZTZ1kytWg4v",
        "outputId": "64c39994-16c1-4340-9280-0f24e898f414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved raster with int32 precision: D:/NDIS_Database/12_Population_synthetic/nasapopct_int32.tif\n"
          ]
        }
      ],
      "source": [
        "src_path = r\"D:/NDIS_Database/12_Population_synthetic/nasapopct.tif\"\n",
        "dst_path = r\"D:/NDIS_Database/12_Population_synthetic/nasapopct_int32.tif\"\n",
        "\n",
        "with rasterio.open(src_path) as src:\n",
        "    profile = src.profile\n",
        "    data = src.read(1)\n",
        "\n",
        "    # Clean invalids\n",
        "    data[~np.isfinite(data)] = 0\n",
        "    data[data == src.nodata] = 0\n",
        "\n",
        "    # to integer\n",
        "    int_data = np.round(data).astype(\"int32\")\n",
        "    profile.update(dtype='int32', nodata=0)\n",
        "\n",
        "    with rasterio.open(dst_path, 'w', **profile) as dst:\n",
        "        dst.write(int_data, 1)\n",
        "\n",
        "print(\"✅ Saved raster with int32 precision:\", dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Flo2N7wWg4v",
        "outputId": "f6f81e46-bea4-40d8-8515-a3d13bb3919a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Total features: 1938335\n",
            "⏳ Processing chunk 1 to 10000\n",
            "⚠️ High population in chunk 1-10000: 24,300,546\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1_10000.csv\n",
            "✅ Chunk 1 to 10000 processed.\n",
            "⏳ Processing chunk 10001 to 20000\n",
            "⚠️ High population in chunk 10001-20000: 25,062,986\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_10001_20000.csv\n",
            "✅ Chunk 10001 to 20000 processed.\n",
            "⏳ Processing chunk 20001 to 30000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_20001_30000.csv\n",
            "✅ Chunk 20001 to 30000 processed.\n",
            "⏳ Processing chunk 30001 to 40000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_30001_40000.csv\n",
            "✅ Chunk 30001 to 40000 processed.\n",
            "⏳ Processing chunk 40001 to 50000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_40001_50000.csv\n",
            "✅ Chunk 40001 to 50000 processed.\n",
            "⏳ Processing chunk 50001 to 60000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_50001_60000.csv\n",
            "✅ Chunk 50001 to 60000 processed.\n",
            "⏳ Processing chunk 60001 to 70000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_60001_70000.csv\n",
            "✅ Chunk 60001 to 70000 processed.\n",
            "⏳ Processing chunk 70001 to 80000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_70001_80000.csv\n",
            "✅ Chunk 70001 to 80000 processed.\n",
            "⏳ Processing chunk 80001 to 90000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_80001_90000.csv\n",
            "✅ Chunk 80001 to 90000 processed.\n",
            "⏳ Processing chunk 90001 to 100000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_90001_100000.csv\n",
            "✅ Chunk 90001 to 100000 processed.\n",
            "⏳ Processing chunk 100001 to 110000\n",
            "⚠️ High population in chunk 100001-110000: 23,064,404\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_100001_110000.csv\n",
            "✅ Chunk 100001 to 110000 processed.\n",
            "⏳ Processing chunk 110001 to 120000\n",
            "⚠️ High population in chunk 110001-120000: 21,393,787\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_110001_120000.csv\n",
            "✅ Chunk 110001 to 120000 processed.\n",
            "⏳ Processing chunk 120001 to 130000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_120001_130000.csv\n",
            "✅ Chunk 120001 to 130000 processed.\n",
            "⏳ Processing chunk 130001 to 140000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_130001_140000.csv\n",
            "✅ Chunk 130001 to 140000 processed.\n",
            "⏳ Processing chunk 140001 to 150000\n",
            "⚠️ High population in chunk 140001-150000: 20,334,463\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_140001_150000.csv\n",
            "✅ Chunk 140001 to 150000 processed.\n",
            "⏳ Processing chunk 150001 to 160000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_150001_160000.csv\n",
            "✅ Chunk 150001 to 160000 processed.\n",
            "⏳ Processing chunk 160001 to 170000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_160001_170000.csv\n",
            "✅ Chunk 160001 to 170000 processed.\n",
            "⏳ Processing chunk 170001 to 180000\n",
            "⚠️ High population in chunk 170001-180000: 21,591,047\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_170001_180000.csv\n",
            "✅ Chunk 170001 to 180000 processed.\n",
            "⏳ Processing chunk 180001 to 190000\n",
            "⚠️ High population in chunk 180001-190000: 21,048,628\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_180001_190000.csv\n",
            "✅ Chunk 180001 to 190000 processed.\n",
            "⏳ Processing chunk 190001 to 200000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_190001_200000.csv\n",
            "✅ Chunk 190001 to 200000 processed.\n",
            "⏳ Processing chunk 200001 to 210000\n",
            "⚠️ High population in chunk 200001-210000: 20,863,321\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_200001_210000.csv\n",
            "✅ Chunk 200001 to 210000 processed.\n",
            "⏳ Processing chunk 210001 to 220000\n",
            "⚠️ High population in chunk 210001-220000: 20,224,128\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_210001_220000.csv\n",
            "✅ Chunk 210001 to 220000 processed.\n",
            "⏳ Processing chunk 220001 to 230000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_220001_230000.csv\n",
            "✅ Chunk 220001 to 230000 processed.\n",
            "⏳ Processing chunk 230001 to 240000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_230001_240000.csv\n",
            "✅ Chunk 230001 to 240000 processed.\n",
            "⏳ Processing chunk 240001 to 250000\n",
            "⚠️ High population in chunk 240001-250000: 21,194,505\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_240001_250000.csv\n",
            "✅ Chunk 240001 to 250000 processed.\n",
            "⏳ Processing chunk 250001 to 260000\n",
            "⚠️ High population in chunk 250001-260000: 21,257,200\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_250001_260000.csv\n",
            "✅ Chunk 250001 to 260000 processed.\n",
            "⏳ Processing chunk 260001 to 270000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_260001_270000.csv\n",
            "✅ Chunk 260001 to 270000 processed.\n",
            "⏳ Processing chunk 270001 to 280000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_270001_280000.csv\n",
            "✅ Chunk 270001 to 280000 processed.\n",
            "⏳ Processing chunk 280001 to 290000\n",
            "⚠️ High population in chunk 280001-290000: 21,342,744\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_280001_290000.csv\n",
            "✅ Chunk 280001 to 290000 processed.\n",
            "⏳ Processing chunk 290001 to 300000\n",
            "⚠️ High population in chunk 290001-300000: 21,550,705\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_290001_300000.csv\n",
            "✅ Chunk 290001 to 300000 processed.\n",
            "⏳ Processing chunk 300001 to 310000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_300001_310000.csv\n",
            "✅ Chunk 300001 to 310000 processed.\n",
            "⏳ Processing chunk 310001 to 320000\n",
            "⚠️ High population in chunk 310001-320000: 21,598,007\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_310001_320000.csv\n",
            "✅ Chunk 310001 to 320000 processed.\n",
            "⏳ Processing chunk 320001 to 330000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_320001_330000.csv\n",
            "✅ Chunk 320001 to 330000 processed.\n",
            "⏳ Processing chunk 330001 to 340000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_330001_340000.csv\n",
            "✅ Chunk 330001 to 340000 processed.\n",
            "⏳ Processing chunk 340001 to 350000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_340001_350000.csv\n",
            "✅ Chunk 340001 to 350000 processed.\n",
            "⏳ Processing chunk 350001 to 360000\n",
            "⚠️ High population in chunk 350001-360000: 20,405,417\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_350001_360000.csv\n",
            "✅ Chunk 350001 to 360000 processed.\n",
            "⏳ Processing chunk 360001 to 370000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_360001_370000.csv\n",
            "✅ Chunk 360001 to 370000 processed.\n",
            "⏳ Processing chunk 370001 to 380000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_370001_380000.csv\n",
            "✅ Chunk 370001 to 380000 processed.\n",
            "⏳ Processing chunk 380001 to 390000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_380001_390000.csv\n",
            "✅ Chunk 380001 to 390000 processed.\n",
            "⏳ Processing chunk 390001 to 400000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_390001_400000.csv\n",
            "✅ Chunk 390001 to 400000 processed.\n",
            "⏳ Processing chunk 400001 to 410000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_400001_410000.csv\n",
            "✅ Chunk 400001 to 410000 processed.\n",
            "⏳ Processing chunk 410001 to 420000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_410001_420000.csv\n",
            "✅ Chunk 410001 to 420000 processed.\n",
            "⏳ Processing chunk 420001 to 430000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_420001_430000.csv\n",
            "✅ Chunk 420001 to 430000 processed.\n",
            "⏳ Processing chunk 430001 to 440000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_430001_440000.csv\n",
            "✅ Chunk 430001 to 440000 processed.\n",
            "⏳ Processing chunk 440001 to 450000\n",
            "⚠️ High population in chunk 440001-450000: 21,663,558\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_440001_450000.csv\n",
            "✅ Chunk 440001 to 450000 processed.\n",
            "⏳ Processing chunk 450001 to 460000\n",
            "⚠️ High population in chunk 450001-460000: 20,726,376\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_450001_460000.csv\n",
            "✅ Chunk 450001 to 460000 processed.\n",
            "⏳ Processing chunk 460001 to 470000\n",
            "⚠️ High population in chunk 460001-470000: 20,962,229\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_460001_470000.csv\n",
            "✅ Chunk 460001 to 470000 processed.\n",
            "⏳ Processing chunk 470001 to 480000\n",
            "⚠️ High population in chunk 470001-480000: 20,602,726\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_470001_480000.csv\n",
            "✅ Chunk 470001 to 480000 processed.\n",
            "⏳ Processing chunk 480001 to 490000\n",
            "⚠️ High population in chunk 480001-490000: 20,143,699\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_480001_490000.csv\n",
            "✅ Chunk 480001 to 490000 processed.\n",
            "⏳ Processing chunk 490001 to 500000\n",
            "⚠️ High population in chunk 490001-500000: 24,437,189\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_490001_500000.csv\n",
            "✅ Chunk 490001 to 500000 processed.\n",
            "⏳ Processing chunk 500001 to 510000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_500001_510000.csv\n",
            "✅ Chunk 500001 to 510000 processed.\n",
            "⏳ Processing chunk 510001 to 520000\n",
            "⚠️ High population in chunk 510001-520000: 20,559,936\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_510001_520000.csv\n",
            "✅ Chunk 510001 to 520000 processed.\n",
            "⏳ Processing chunk 520001 to 530000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_520001_530000.csv\n",
            "✅ Chunk 520001 to 530000 processed.\n",
            "⏳ Processing chunk 530001 to 540000\n",
            "⚠️ High population in chunk 530001-540000: 20,216,186\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_530001_540000.csv\n",
            "✅ Chunk 530001 to 540000 processed.\n",
            "⏳ Processing chunk 540001 to 550000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_540001_550000.csv\n",
            "✅ Chunk 540001 to 550000 processed.\n",
            "⏳ Processing chunk 550001 to 560000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_550001_560000.csv\n",
            "✅ Chunk 550001 to 560000 processed.\n",
            "⏳ Processing chunk 560001 to 570000\n",
            "⚠️ High population in chunk 560001-570000: 21,310,335\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_560001_570000.csv\n",
            "✅ Chunk 560001 to 570000 processed.\n",
            "⏳ Processing chunk 570001 to 580000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_570001_580000.csv\n",
            "✅ Chunk 570001 to 580000 processed.\n",
            "⏳ Processing chunk 580001 to 590000\n",
            "⚠️ High population in chunk 580001-590000: 21,106,316\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_580001_590000.csv\n",
            "✅ Chunk 580001 to 590000 processed.\n",
            "⏳ Processing chunk 590001 to 600000\n",
            "⚠️ High population in chunk 590001-600000: 20,242,748\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_590001_600000.csv\n",
            "✅ Chunk 590001 to 600000 processed.\n",
            "⏳ Processing chunk 600001 to 610000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_600001_610000.csv\n",
            "✅ Chunk 600001 to 610000 processed.\n",
            "⏳ Processing chunk 610001 to 620000\n",
            "⚠️ High population in chunk 610001-620000: 20,102,046\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_610001_620000.csv\n",
            "✅ Chunk 610001 to 620000 processed.\n",
            "⏳ Processing chunk 620001 to 630000\n",
            "⚠️ High population in chunk 620001-630000: 21,310,387\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_620001_630000.csv\n",
            "✅ Chunk 620001 to 630000 processed.\n",
            "⏳ Processing chunk 630001 to 640000\n",
            "⚠️ High population in chunk 630001-640000: 21,556,913\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_630001_640000.csv\n",
            "✅ Chunk 630001 to 640000 processed.\n",
            "⏳ Processing chunk 640001 to 650000\n",
            "⚠️ High population in chunk 640001-650000: 21,478,989\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_640001_650000.csv\n",
            "✅ Chunk 640001 to 650000 processed.\n",
            "⏳ Processing chunk 650001 to 660000\n",
            "⚠️ High population in chunk 650001-660000: 20,815,844\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_650001_660000.csv\n",
            "✅ Chunk 650001 to 660000 processed.\n",
            "⏳ Processing chunk 660001 to 670000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_660001_670000.csv\n",
            "✅ Chunk 660001 to 670000 processed.\n",
            "⏳ Processing chunk 670001 to 680000\n",
            "⚠️ High population in chunk 670001-680000: 20,622,786\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_670001_680000.csv\n",
            "✅ Chunk 670001 to 680000 processed.\n",
            "⏳ Processing chunk 680001 to 690000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_680001_690000.csv\n",
            "✅ Chunk 680001 to 690000 processed.\n",
            "⏳ Processing chunk 690001 to 700000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_690001_700000.csv\n",
            "✅ Chunk 690001 to 700000 processed.\n",
            "⏳ Processing chunk 700001 to 710000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_700001_710000.csv\n",
            "✅ Chunk 700001 to 710000 processed.\n",
            "⏳ Processing chunk 710001 to 720000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_710001_720000.csv\n",
            "✅ Chunk 710001 to 720000 processed.\n",
            "⏳ Processing chunk 720001 to 730000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_720001_730000.csv\n",
            "✅ Chunk 720001 to 730000 processed.\n",
            "⏳ Processing chunk 730001 to 740000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_730001_740000.csv\n",
            "✅ Chunk 730001 to 740000 processed.\n",
            "⏳ Processing chunk 740001 to 750000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_740001_750000.csv\n",
            "✅ Chunk 740001 to 750000 processed.\n",
            "⏳ Processing chunk 750001 to 760000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_750001_760000.csv\n",
            "✅ Chunk 750001 to 760000 processed.\n",
            "⏳ Processing chunk 760001 to 770000\n",
            "⚠️ High population in chunk 760001-770000: 20,744,022\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_760001_770000.csv\n",
            "✅ Chunk 760001 to 770000 processed.\n",
            "⏳ Processing chunk 770001 to 780000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_770001_780000.csv\n",
            "✅ Chunk 770001 to 780000 processed.\n",
            "⏳ Processing chunk 780001 to 790000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_780001_790000.csv\n",
            "✅ Chunk 780001 to 790000 processed.\n",
            "⏳ Processing chunk 790001 to 800000\n",
            "⚠️ High population in chunk 790001-800000: 20,080,593\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_790001_800000.csv\n",
            "✅ Chunk 790001 to 800000 processed.\n",
            "⏳ Processing chunk 800001 to 810000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_800001_810000.csv\n",
            "✅ Chunk 800001 to 810000 processed.\n",
            "⏳ Processing chunk 810001 to 820000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_810001_820000.csv\n",
            "✅ Chunk 810001 to 820000 processed.\n",
            "⏳ Processing chunk 820001 to 830000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_820001_830000.csv\n",
            "✅ Chunk 820001 to 830000 processed.\n",
            "⏳ Processing chunk 830001 to 840000\n",
            "⚠️ High population in chunk 830001-840000: 21,181,372\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_830001_840000.csv\n",
            "✅ Chunk 830001 to 840000 processed.\n",
            "⏳ Processing chunk 840001 to 850000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_840001_850000.csv\n",
            "✅ Chunk 840001 to 850000 processed.\n",
            "⏳ Processing chunk 850001 to 860000\n",
            "⚠️ High population in chunk 850001-860000: 20,069,666\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_850001_860000.csv\n",
            "✅ Chunk 850001 to 860000 processed.\n",
            "⏳ Processing chunk 860001 to 870000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_860001_870000.csv\n",
            "✅ Chunk 860001 to 870000 processed.\n",
            "⏳ Processing chunk 870001 to 880000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_870001_880000.csv\n",
            "✅ Chunk 870001 to 880000 processed.\n",
            "⏳ Processing chunk 880001 to 890000\n",
            "⚠️ High population in chunk 880001-890000: 21,524,268\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_880001_890000.csv\n",
            "✅ Chunk 880001 to 890000 processed.\n",
            "⏳ Processing chunk 890001 to 900000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_890001_900000.csv\n",
            "✅ Chunk 890001 to 900000 processed.\n",
            "⏳ Processing chunk 900001 to 910000\n",
            "⚠️ High population in chunk 900001-910000: 21,422,543\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_900001_910000.csv\n",
            "✅ Chunk 900001 to 910000 processed.\n",
            "⏳ Processing chunk 910001 to 920000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_910001_920000.csv\n",
            "✅ Chunk 910001 to 920000 processed.\n",
            "⏳ Processing chunk 920001 to 930000\n",
            "⚠️ High population in chunk 920001-930000: 20,688,110\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_920001_930000.csv\n",
            "✅ Chunk 920001 to 930000 processed.\n",
            "⏳ Processing chunk 930001 to 940000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_930001_940000.csv\n",
            "✅ Chunk 930001 to 940000 processed.\n",
            "⏳ Processing chunk 940001 to 950000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_940001_950000.csv\n",
            "✅ Chunk 940001 to 950000 processed.\n",
            "⏳ Processing chunk 950001 to 960000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_950001_960000.csv\n",
            "✅ Chunk 950001 to 960000 processed.\n",
            "⏳ Processing chunk 960001 to 970000\n",
            "⚠️ High population in chunk 960001-970000: 20,762,368\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_960001_970000.csv\n",
            "✅ Chunk 960001 to 970000 processed.\n",
            "⏳ Processing chunk 970001 to 980000\n",
            "⚠️ High population in chunk 970001-980000: 21,213,725\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_970001_980000.csv\n",
            "✅ Chunk 970001 to 980000 processed.\n",
            "⏳ Processing chunk 980001 to 990000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_980001_990000.csv\n",
            "✅ Chunk 980001 to 990000 processed.\n",
            "⏳ Processing chunk 990001 to 1000000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_990001_1000000.csv\n",
            "✅ Chunk 990001 to 1000000 processed.\n",
            "⏳ Processing chunk 1000001 to 1010000\n",
            "⚠️ High population in chunk 1000001-1010000: 20,383,493\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1000001_1010000.csv\n",
            "✅ Chunk 1000001 to 1010000 processed.\n",
            "⏳ Processing chunk 1010001 to 1020000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1010001_1020000.csv\n",
            "✅ Chunk 1010001 to 1020000 processed.\n",
            "⏳ Processing chunk 1020001 to 1030000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1020001_1030000.csv\n",
            "✅ Chunk 1020001 to 1030000 processed.\n",
            "⏳ Processing chunk 1030001 to 1040000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1030001_1040000.csv\n",
            "✅ Chunk 1030001 to 1040000 processed.\n",
            "⏳ Processing chunk 1040001 to 1050000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1040001_1050000.csv\n",
            "✅ Chunk 1040001 to 1050000 processed.\n",
            "⏳ Processing chunk 1050001 to 1060000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1050001_1060000.csv\n",
            "✅ Chunk 1050001 to 1060000 processed.\n",
            "⏳ Processing chunk 1060001 to 1070000\n",
            "⚠️ High population in chunk 1060001-1070000: 24,556,850\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1060001_1070000.csv\n",
            "✅ Chunk 1060001 to 1070000 processed.\n",
            "⏳ Processing chunk 1070001 to 1080000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1070001_1080000.csv\n",
            "✅ Chunk 1070001 to 1080000 processed.\n",
            "⏳ Processing chunk 1080001 to 1090000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1080001_1090000.csv\n",
            "✅ Chunk 1080001 to 1090000 processed.\n",
            "⏳ Processing chunk 1090001 to 1100000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1090001_1100000.csv\n",
            "✅ Chunk 1090001 to 1100000 processed.\n",
            "⏳ Processing chunk 1100001 to 1110000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1100001_1110000.csv\n",
            "✅ Chunk 1100001 to 1110000 processed.\n",
            "⏳ Processing chunk 1110001 to 1120000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1110001_1120000.csv\n",
            "✅ Chunk 1110001 to 1120000 processed.\n",
            "⏳ Processing chunk 1120001 to 1130000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1120001_1130000.csv\n",
            "✅ Chunk 1120001 to 1130000 processed.\n",
            "⏳ Processing chunk 1130001 to 1140000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1130001_1140000.csv\n",
            "✅ Chunk 1130001 to 1140000 processed.\n",
            "⏳ Processing chunk 1140001 to 1150000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1140001_1150000.csv\n",
            "✅ Chunk 1140001 to 1150000 processed.\n",
            "⏳ Processing chunk 1150001 to 1160000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1150001_1160000.csv\n",
            "✅ Chunk 1150001 to 1160000 processed.\n",
            "⏳ Processing chunk 1160001 to 1170000\n",
            "⚠️ High population in chunk 1160001-1170000: 21,624,263\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1160001_1170000.csv\n",
            "✅ Chunk 1160001 to 1170000 processed.\n",
            "⏳ Processing chunk 1170001 to 1180000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1170001_1180000.csv\n",
            "✅ Chunk 1170001 to 1180000 processed.\n",
            "⏳ Processing chunk 1180001 to 1190000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1180001_1190000.csv\n",
            "✅ Chunk 1180001 to 1190000 processed.\n",
            "⏳ Processing chunk 1190001 to 1200000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1190001_1200000.csv\n",
            "✅ Chunk 1190001 to 1200000 processed.\n",
            "⏳ Processing chunk 1200001 to 1210000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1200001_1210000.csv\n",
            "✅ Chunk 1200001 to 1210000 processed.\n",
            "⏳ Processing chunk 1210001 to 1220000\n",
            "⚠️ High population in chunk 1210001-1220000: 21,177,091\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1210001_1220000.csv\n",
            "✅ Chunk 1210001 to 1220000 processed.\n",
            "⏳ Processing chunk 1220001 to 1230000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1220001_1230000.csv\n",
            "✅ Chunk 1220001 to 1230000 processed.\n",
            "⏳ Processing chunk 1230001 to 1240000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1230001_1240000.csv\n",
            "✅ Chunk 1230001 to 1240000 processed.\n",
            "⏳ Processing chunk 1240001 to 1250000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1240001_1250000.csv\n",
            "✅ Chunk 1240001 to 1250000 processed.\n",
            "⏳ Processing chunk 1250001 to 1260000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1250001_1260000.csv\n",
            "✅ Chunk 1250001 to 1260000 processed.\n",
            "⏳ Processing chunk 1260001 to 1270000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1260001_1270000.csv\n",
            "✅ Chunk 1260001 to 1270000 processed.\n",
            "⏳ Processing chunk 1270001 to 1280000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1270001_1280000.csv\n",
            "✅ Chunk 1270001 to 1280000 processed.\n",
            "⏳ Processing chunk 1280001 to 1290000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1280001_1290000.csv\n",
            "✅ Chunk 1280001 to 1290000 processed.\n",
            "⏳ Processing chunk 1290001 to 1300000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1290001_1300000.csv\n",
            "✅ Chunk 1290001 to 1300000 processed.\n",
            "⏳ Processing chunk 1300001 to 1310000\n",
            "⚠️ High population in chunk 1300001-1310000: 21,022,893\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1300001_1310000.csv\n",
            "✅ Chunk 1300001 to 1310000 processed.\n",
            "⏳ Processing chunk 1310001 to 1320000\n",
            "⚠️ High population in chunk 1310001-1320000: 24,699,167\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1310001_1320000.csv\n",
            "✅ Chunk 1310001 to 1320000 processed.\n",
            "⏳ Processing chunk 1320001 to 1330000\n",
            "⚠️ High population in chunk 1320001-1330000: 21,150,297\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1320001_1330000.csv\n",
            "✅ Chunk 1320001 to 1330000 processed.\n",
            "⏳ Processing chunk 1330001 to 1340000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1330001_1340000.csv\n",
            "✅ Chunk 1330001 to 1340000 processed.\n",
            "⏳ Processing chunk 1340001 to 1350000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1340001_1350000.csv\n",
            "✅ Chunk 1340001 to 1350000 processed.\n",
            "⏳ Processing chunk 1350001 to 1360000\n",
            "⚠️ High population in chunk 1350001-1360000: 21,538,966\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1350001_1360000.csv\n",
            "✅ Chunk 1350001 to 1360000 processed.\n",
            "⏳ Processing chunk 1360001 to 1370000\n",
            "⚠️ High population in chunk 1360001-1370000: 20,282,472\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1360001_1370000.csv\n",
            "✅ Chunk 1360001 to 1370000 processed.\n",
            "⏳ Processing chunk 1370001 to 1380000\n",
            "⚠️ High population in chunk 1370001-1380000: 21,404,708\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1370001_1380000.csv\n",
            "✅ Chunk 1370001 to 1380000 processed.\n",
            "⏳ Processing chunk 1380001 to 1390000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1380001_1390000.csv\n",
            "✅ Chunk 1380001 to 1390000 processed.\n",
            "⏳ Processing chunk 1390001 to 1400000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1390001_1400000.csv\n",
            "✅ Chunk 1390001 to 1400000 processed.\n",
            "⏳ Processing chunk 1400001 to 1410000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1400001_1410000.csv\n",
            "✅ Chunk 1400001 to 1410000 processed.\n",
            "⏳ Processing chunk 1410001 to 1420000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1410001_1420000.csv\n",
            "✅ Chunk 1410001 to 1420000 processed.\n",
            "⏳ Processing chunk 1420001 to 1430000\n",
            "⚠️ High population in chunk 1420001-1430000: 24,746,705\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1420001_1430000.csv\n",
            "✅ Chunk 1420001 to 1430000 processed.\n",
            "⏳ Processing chunk 1430001 to 1440000\n",
            "⚠️ High population in chunk 1430001-1440000: 24,755,687\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1430001_1440000.csv\n",
            "✅ Chunk 1430001 to 1440000 processed.\n",
            "⏳ Processing chunk 1440001 to 1450000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1440001_1450000.csv\n",
            "✅ Chunk 1440001 to 1450000 processed.\n",
            "⏳ Processing chunk 1450001 to 1460000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1450001_1460000.csv\n",
            "✅ Chunk 1450001 to 1460000 processed.\n",
            "⏳ Processing chunk 1460001 to 1470000\n",
            "⚠️ High population in chunk 1460001-1470000: 22,891,558\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1460001_1470000.csv\n",
            "✅ Chunk 1460001 to 1470000 processed.\n",
            "⏳ Processing chunk 1470001 to 1480000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1470001_1480000.csv\n",
            "✅ Chunk 1470001 to 1480000 processed.\n",
            "⏳ Processing chunk 1480001 to 1490000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1480001_1490000.csv\n",
            "✅ Chunk 1480001 to 1490000 processed.\n",
            "⏳ Processing chunk 1490001 to 1500000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1490001_1500000.csv\n",
            "✅ Chunk 1490001 to 1500000 processed.\n",
            "⏳ Processing chunk 1500001 to 1510000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1500001_1510000.csv\n",
            "✅ Chunk 1500001 to 1510000 processed.\n",
            "⏳ Processing chunk 1510001 to 1520000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1510001_1520000.csv\n",
            "✅ Chunk 1510001 to 1520000 processed.\n",
            "⏳ Processing chunk 1520001 to 1530000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1520001_1530000.csv\n",
            "✅ Chunk 1520001 to 1530000 processed.\n",
            "⏳ Processing chunk 1530001 to 1540000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1530001_1540000.csv\n",
            "✅ Chunk 1530001 to 1540000 processed.\n",
            "⏳ Processing chunk 1540001 to 1550000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1540001_1550000.csv\n",
            "✅ Chunk 1540001 to 1550000 processed.\n",
            "⏳ Processing chunk 1550001 to 1560000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1550001_1560000.csv\n",
            "✅ Chunk 1550001 to 1560000 processed.\n",
            "⏳ Processing chunk 1560001 to 1570000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1560001_1570000.csv\n",
            "✅ Chunk 1560001 to 1570000 processed.\n",
            "⏳ Processing chunk 1570001 to 1580000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1570001_1580000.csv\n",
            "✅ Chunk 1570001 to 1580000 processed.\n",
            "⏳ Processing chunk 1580001 to 1590000\n",
            "⚠️ High population in chunk 1580001-1590000: 22,347,244\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1580001_1590000.csv\n",
            "✅ Chunk 1580001 to 1590000 processed.\n",
            "⏳ Processing chunk 1590001 to 1600000\n",
            "⚠️ High population in chunk 1590001-1600000: 20,147,260\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1590001_1600000.csv\n",
            "✅ Chunk 1590001 to 1600000 processed.\n",
            "⏳ Processing chunk 1600001 to 1610000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1600001_1610000.csv\n",
            "✅ Chunk 1600001 to 1610000 processed.\n",
            "⏳ Processing chunk 1610001 to 1620000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1610001_1620000.csv\n",
            "✅ Chunk 1610001 to 1620000 processed.\n",
            "⏳ Processing chunk 1620001 to 1630000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1620001_1630000.csv\n",
            "✅ Chunk 1620001 to 1630000 processed.\n",
            "⏳ Processing chunk 1630001 to 1640000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1630001_1640000.csv\n",
            "✅ Chunk 1630001 to 1640000 processed.\n",
            "⏳ Processing chunk 1640001 to 1650000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1640001_1650000.csv\n",
            "✅ Chunk 1640001 to 1650000 processed.\n",
            "⏳ Processing chunk 1650001 to 1660000\n",
            "⚠️ High population in chunk 1650001-1660000: 20,809,573\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1650001_1660000.csv\n",
            "✅ Chunk 1650001 to 1660000 processed.\n",
            "⏳ Processing chunk 1660001 to 1670000\n",
            "⚠️ High population in chunk 1660001-1670000: 20,316,267\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1660001_1670000.csv\n",
            "✅ Chunk 1660001 to 1670000 processed.\n",
            "⏳ Processing chunk 1670001 to 1680000\n",
            "⚠️ High population in chunk 1670001-1680000: 20,064,560\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1670001_1680000.csv\n",
            "✅ Chunk 1670001 to 1680000 processed.\n",
            "⏳ Processing chunk 1680001 to 1690000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1680001_1690000.csv\n",
            "✅ Chunk 1680001 to 1690000 processed.\n",
            "⏳ Processing chunk 1690001 to 1700000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1690001_1700000.csv\n",
            "✅ Chunk 1690001 to 1700000 processed.\n",
            "⏳ Processing chunk 1700001 to 1710000\n",
            "⚠️ High population in chunk 1700001-1710000: 21,419,388\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1700001_1710000.csv\n",
            "✅ Chunk 1700001 to 1710000 processed.\n",
            "⏳ Processing chunk 1710001 to 1720000\n",
            "⚠️ High population in chunk 1710001-1720000: 21,118,762\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1710001_1720000.csv\n",
            "✅ Chunk 1710001 to 1720000 processed.\n",
            "⏳ Processing chunk 1720001 to 1730000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1720001_1730000.csv\n",
            "✅ Chunk 1720001 to 1730000 processed.\n",
            "⏳ Processing chunk 1730001 to 1740000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1730001_1740000.csv\n",
            "✅ Chunk 1730001 to 1740000 processed.\n",
            "⏳ Processing chunk 1740001 to 1750000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1740001_1750000.csv\n",
            "✅ Chunk 1740001 to 1750000 processed.\n",
            "⏳ Processing chunk 1750001 to 1760000\n",
            "⚠️ High population in chunk 1750001-1760000: 20,886,933\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1750001_1760000.csv\n",
            "✅ Chunk 1750001 to 1760000 processed.\n",
            "⏳ Processing chunk 1760001 to 1770000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1760001_1770000.csv\n",
            "✅ Chunk 1760001 to 1770000 processed.\n",
            "⏳ Processing chunk 1770001 to 1780000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1770001_1780000.csv\n",
            "✅ Chunk 1770001 to 1780000 processed.\n",
            "⏳ Processing chunk 1780001 to 1790000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1780001_1790000.csv\n",
            "✅ Chunk 1780001 to 1790000 processed.\n",
            "⏳ Processing chunk 1790001 to 1800000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1790001_1800000.csv\n",
            "✅ Chunk 1790001 to 1800000 processed.\n",
            "⏳ Processing chunk 1800001 to 1810000\n",
            "⚠️ High population in chunk 1800001-1810000: 20,610,096\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1800001_1810000.csv\n",
            "✅ Chunk 1800001 to 1810000 processed.\n",
            "⏳ Processing chunk 1810001 to 1820000\n",
            "⚠️ High population in chunk 1810001-1820000: 20,894,871\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1810001_1820000.csv\n",
            "✅ Chunk 1810001 to 1820000 processed.\n",
            "⏳ Processing chunk 1820001 to 1830000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1820001_1830000.csv\n",
            "✅ Chunk 1820001 to 1830000 processed.\n",
            "⏳ Processing chunk 1830001 to 1840000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1830001_1840000.csv\n",
            "✅ Chunk 1830001 to 1840000 processed.\n",
            "⏳ Processing chunk 1840001 to 1850000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1840001_1850000.csv\n",
            "✅ Chunk 1840001 to 1850000 processed.\n",
            "⏳ Processing chunk 1850001 to 1860000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1850001_1860000.csv\n",
            "✅ Chunk 1850001 to 1860000 processed.\n",
            "⏳ Processing chunk 1860001 to 1870000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1860001_1870000.csv\n",
            "✅ Chunk 1860001 to 1870000 processed.\n",
            "⏳ Processing chunk 1870001 to 1880000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1870001_1880000.csv\n",
            "✅ Chunk 1870001 to 1880000 processed.\n",
            "⏳ Processing chunk 1880001 to 1890000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1880001_1890000.csv\n",
            "✅ Chunk 1880001 to 1890000 processed.\n",
            "⏳ Processing chunk 1890001 to 1900000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1890001_1900000.csv\n",
            "✅ Chunk 1890001 to 1900000 processed.\n",
            "⏳ Processing chunk 1900001 to 1910000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1900001_1910000.csv\n",
            "✅ Chunk 1900001 to 1910000 processed.\n",
            "⏳ Processing chunk 1910001 to 1920000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1910001_1920000.csv\n",
            "✅ Chunk 1910001 to 1920000 processed.\n",
            "⏳ Processing chunk 1920001 to 1930000\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1920001_1930000.csv\n",
            "✅ Chunk 1920001 to 1930000 processed.\n",
            "⏳ Processing chunk 1930001 to 1938335\n",
            "⚠️ High population in chunk 1930001-1938335: 23,507,224\n",
            "📁 Saved chunk to: zonal_chunks\\chunk_1930001_1938335.csv\n",
            "✅ Chunk 1930001 to 1938335 processed.\n",
            "🟡 Saved 130 suspicious rows for manual review.\n",
            "✅ No NaN rows in final result.\n",
            "🎉 All done.\n",
            "✅ All tsunami near analysis completed in 359.75 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "# === PARAMETERS ===\n",
        "population_raster = r\"D:\\NDIS_Database\\12_Population_synthetic\\nasapopct_int32.tif\"\n",
        "buffer_dist = 30000  # 30 km\n",
        "chunk_size = 10000\n",
        "output_dir = \"zonal_chunks\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === LOAD AND PREP ===\n",
        "ghz_pap[\"geometry\"] = ghz_pap.apply(\n",
        "    lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1\n",
        ")\n",
        "input_gdf = gpd.GeoDataFrame(ghz_pap, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "\n",
        "buffer_deg = buffer_dist / 111320.0\n",
        "total = len(input_gdf)\n",
        "print(f\"🔹 Total features: {total}\")\n",
        "\n",
        "suspicious_chunks = []\n",
        "nan_rows_all = []\n",
        "\n",
        "# === PROCESS IN CHUNKS ===\n",
        "for start in range(0, total, chunk_size):\n",
        "    end = min(start + chunk_size, total)\n",
        "    print(f\"⏳ Processing chunk {start+1} to {end}\")\n",
        "\n",
        "    chunk = input_gdf.iloc[start:end].copy()\n",
        "\n",
        "    # Suppress geographic CRS buffer warning\n",
        "    warnings.filterwarnings(\"ignore\", message=\"Geometry is in a geographic CRS.*\")\n",
        "    chunk[\"geometry\"] = chunk.geometry.buffer(buffer_deg)\n",
        "\n",
        "    # Drop bad geometries\n",
        "    chunk = chunk[chunk[\"geometry\"].notnull()]\n",
        "    chunk = chunk[chunk.is_valid]\n",
        "\n",
        "    if chunk.empty:\n",
        "        print(f\"⚠️ Skipping empty/invalid chunk {start+1} to {end}\")\n",
        "        continue\n",
        "\n",
        "    # Zonal stats with correct nodata and pixel inclusion\n",
        "    try:\n",
        "        stats = zonal_stats(\n",
        "            chunk,\n",
        "            population_raster,\n",
        "            stats=[\"sum\"],\n",
        "            geojson_out=False,\n",
        "            nodata=-3.4028235e+38,\n",
        "            all_touched=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in chunk {start+1} to {end}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Clean and assign population values\n",
        "    pop_vals = []\n",
        "    nan_rows = []\n",
        "    for i, row in enumerate(stats):\n",
        "        val = row.get(\"sum\", 0)\n",
        "        if val is None or not np.isfinite(val):\n",
        "            pop_vals.append(np.nan)\n",
        "            nan_rows.append(i)\n",
        "        else:\n",
        "            pop_vals.append(val)\n",
        "\n",
        "    chunk[\"pop\"] = pop_vals\n",
        "\n",
        "    # Flag very high values\n",
        "    chunk[\"pop_flagged\"] = chunk[\"pop\"].apply(\n",
        "        lambda x: \"⚠️ check\" if pd.notna(x) and x > 20_000_000 else \"\"\n",
        "    )\n",
        "\n",
        "    max_pop = chunk[\"pop\"].max()\n",
        "    if pd.notna(max_pop) and max_pop > 20_000_000:\n",
        "        print(f\"⚠️ High population in chunk {start+1}-{end}: {max_pop:,.0f}\")\n",
        "        suspicious_chunks.append(chunk[chunk[\"pop\"] > 20_000_000].copy())\n",
        "\n",
        "    # Log NaN results for QA\n",
        "    if nan_rows:\n",
        "        nan_rows_all.append(chunk.iloc[nan_rows][[\"HazardID\", \"latitude\", \"longitude\", \"pop\"]].copy())\n",
        "\n",
        "    # Save each chunk\n",
        "    chunk_out_path = os.path.join(output_dir, f\"chunk_{start+1}_{end}.csv\")\n",
        "    chunk.drop(columns=\"geometry\").to_csv(chunk_out_path, index=False)\n",
        "    print(f\"📁 Saved chunk to: {chunk_out_path}\")\n",
        "\n",
        "    # Clean up memory\n",
        "    del chunk, stats\n",
        "    gc.collect()\n",
        "    print(f\"✅ Chunk {start+1} to {end} processed.\")\n",
        "\n",
        "# === FINAL OUTPUT ===\n",
        "\n",
        "# Save suspicious rows with very high population\n",
        "if suspicious_chunks:\n",
        "    suspicious_df = pd.concat(suspicious_chunks, ignore_index=True)\n",
        "    suspicious_df.to_csv(os.path.join(output_dir, \"suspicious_population_zones.csv\"), index=False)\n",
        "    print(f\"🟡 Saved {len(suspicious_df)} suspicious rows for manual review.\")\n",
        "else:\n",
        "    print(\"✅ No suspicious population zones found.\")\n",
        "\n",
        "# Save rows with NaN population values\n",
        "if nan_rows_all:\n",
        "    nan_df = pd.concat(nan_rows_all, ignore_index=True)\n",
        "    nan_df.to_csv(os.path.join(output_dir, \"nan_population_zones.csv\"), index=False)\n",
        "    print(f\"🟠 Saved {len(nan_df)} NaN population rows for inspection.\")\n",
        "else:\n",
        "    print(\"✅ No NaN rows in final result.\")\n",
        "\n",
        "print(\"🎉 All done.\")\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(f\"✅ All tsunami near analysis completed in {elapsed/60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_orvNkeWg4w",
        "outputId": "5e0dd324-6314-4b15-85b4-096becdd8a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧩 Combined all 194 chunk CSVs into final_df with 1,938,335 rows.\n",
            "💾 Saved final combined CSV.\n"
          ]
        }
      ],
      "source": [
        "# Combine all chunk CSVs into a single DataFrame\n",
        "chunk_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.startswith(\"chunk_\") and f.endswith(\".csv\")]\n",
        "final_df = pd.concat([pd.read_csv(f) for f in chunk_files], ignore_index=True)\n",
        "print(f\"🧩 Combined all {len(chunk_files)} chunk CSVs into final_df with {len(final_df):,} rows.\")\n",
        "final_df.to_csv(os.path.join(output_dir, \"all_chunks_combined.csv\"), index=False)\n",
        "print(\"💾 Saved final combined CSV.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJdQDT7-Wg4w"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv(r\"D:\\NDIS_Database\\zonal_chunks\\all_chunks_combined.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVNctQh1Wg4x",
        "outputId": "552c61b7-d7d1-4131-98bd-483c94e90da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Earthquake', 'Landslide', 'Fault', 'Nuclear', 'Volcano',\n",
              "       'Tsunami'], dtype=object)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df.HazardType.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6KarPQ6Wg4x"
      },
      "outputs": [],
      "source": [
        "suspicious_df.to_csv(r\"D:\\NDIS_Database\\zonal_chunks\\suspicious_population.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDXUOLutWg4x",
        "outputId": "52a9530f-0957-4fe0-fb8a-6ad451185c52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:/Users/Dell/AppData/Local/Temp/ArcGISProTemp11884/xpython_11884/1754752216.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  final_df = pd.read_csv(r\"D:\\NDIS_Database\\zonal_chunks\\all_chunks_combined.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1938335 entries, 0 to 1938334\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   HazardID               int64  \n",
            " 1   latitude               float64\n",
            " 2   longitude              float64\n",
            " 3   HazardType             object \n",
            " 4   distance               float64\n",
            " 5   intensity              float64\n",
            " 6   economic_loss_million  float64\n",
            " 7   duration_minutes       float64\n",
            " 8   pop                    float64\n",
            " 9   pop_flagged            object \n",
            "dtypes: float64(7), int64(1), object(2)\n",
            "memory usage: 147.9+ MB\n"
          ]
        }
      ],
      "source": [
        "final_df = pd.read_csv(r\"D:\\NDIS_Database\\zonal_chunks\\all_chunks_combined.csv\")\n",
        "final_df.info()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ArcGISPro",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
