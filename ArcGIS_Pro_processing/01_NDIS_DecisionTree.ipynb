{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yah2evTTdbbD"
      },
      "source": [
        "# NDIS v1.0 - Processed Using Decision Tree Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u6dQUC0dbbI"
      },
      "outputs": [],
      "source": [
        "from arcgis.gis import GIS\n",
        "gis = GIS(\"home\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syqiPgv2dbbK"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# basic packages\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import timeit\n",
        "import random\n",
        "import string\n",
        "from playsound import playsound\n",
        "\n",
        "# Data management\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point  # to get points from long lat\n",
        "\n",
        "# Request service\n",
        "#from requests import Request\n",
        "import json\n",
        "import re\n",
        "from functools import reduce\n",
        "#from owslib.wfs import WebFeatureService\n",
        "\n",
        "# Plotting packages\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2fPeSU9dbbN"
      },
      "source": [
        "## Select Valuable Input Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0uFw8YLdbbQ"
      },
      "outputs": [],
      "source": [
        "# Set the path to this geodatabase\n",
        "gdb_path = r\"D:\\ArcGISProjects\\GeohazardDB\\GeohazardDB.gdb\"  # This gdb path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBlNq7Y6dbbQ"
      },
      "source": [
        "### Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT5SiEOddbbR"
      },
      "outputs": [],
      "source": [
        "# Import Database/Dataset\n",
        "# Specify the feature class name\n",
        "ghz_clean = \"cleaned_geohazard_data\"  # Geohazard feature class\n",
        "ghz_clean_path = f\"{gdb_path}\\\\{ghz_clean}\"\n",
        "\n",
        "# Use arcpy to create a list of fields\n",
        "ghz_clean_fields = [f.name for f in arcpy.ListFields(f\"{gdb_path}\\\\{ghz_clean}\")]\n",
        "\n",
        "# Use arcpy to create a search cursor and load the data into a list of dictionaries\n",
        "ghz_clean_data = []\n",
        "with arcpy.da.SearchCursor(f\"{gdb_path}\\\\{ghz_clean}\", ghz_clean_fields) as cursor:\n",
        "    for row in cursor:\n",
        "        ghz_clean_data.append(dict(zip(ghz_clean_fields, row)))\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "ghz_celan_df = pd.DataFrame(ghz_clean_data)\n",
        "ghz_celan_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgB1lfukdbbS"
      },
      "outputs": [],
      "source": [
        "# Convert the DataFrame to a CSV file\n",
        "ghz_celan_df.to_csv(r\"D:\\NDIS_Database\\ghz_processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7sCOXxMdbbT"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset to include only distances <= 500 km (500,000 m)\n",
        "filtered_geohazard = ghz_celan_df[ghz_celan_df[\"distance\"] <= 1046000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XSxp5sTdbbT"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax = fig.gca()\n",
        "\n",
        "# Set the color scheme to purple-green\n",
        "sns.set_palette(\"PRGn\")\n",
        "\n",
        "# Define adjusted bin edges: finer resolution for small distances, coarser for large ones\n",
        "adjusted_bins = np.concatenate([\n",
        "    np.arange(0, 10000, 1000),  # 0 - 10 km: 1 km bins\n",
        "    np.arange(10000, 50000, 5000),  # 10 - 50 km: 5 km bins\n",
        "    np.arange(50000, 100000, 10000),  # 50 - 100 km: 10 km bins\n",
        "    np.arange(100000, 1046000, 1046000)  # 100 - 500 km: 50 km bins\n",
        "])\n",
        "\n",
        "ax = sns.histplot(filtered_geohazard[\"distance\"], bins=adjusted_bins, kde=False, edgecolor=\"black\")\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel(\"Distance (m)\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.title(\"Distribution of Geohazard Distances (Max 1000 km)\", fontsize=14)\n",
        "plt.grid(False)\n",
        "\n",
        "# Format x and y axis labels to avoid scientific notation\n",
        "ax.ticklabel_format(style='plain', axis='x')\n",
        "ax.ticklabel_format(style='plain', axis='y')\n",
        "\n",
        "# Label each bar with frequency count\n",
        "for bar in ax.patches:\n",
        "    height = bar.get_height()\n",
        "    if height > 0:\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, height + 5000,\n",
        "                 f\"{int(height)}\", ha='center', fontsize=10, color=\"black\")\n",
        "\n",
        "# Show the plot\n",
        "# Save the plot as PNG with transparent background\n",
        "fig.savefig('D:/NDIS_Database/FE_Display/distance_dist.png', transparent=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18l6bu8OdbbV"
      },
      "source": [
        "### Pre-Processing With RPAS and Sensor Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUskG1qSdbbY"
      },
      "outputs": [],
      "source": [
        "# By Max Payload\n",
        "dc = drone_cleaned.distance_range.unique()\n",
        "dc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDkCYR5vdbbZ"
      },
      "outputs": [],
      "source": [
        "# Given range values\n",
        "range_values = np.array([\n",
        "    1.50000e+05, 4.00000e+03, 1.00000e+04, 1.80000e+04, 7.00000e+03,\n",
        "    2.00000e+03, 1.50000e+04, 8.00000e+03, 5.00000e+03, 1.00000e+03,\n",
        "    1.60000e+04, 3.50000e+04, 1.20000e+04, 2.00000e+04, 7.00000e+02,\n",
        "    1.35000e+05, 5.00000e+04, 2.10000e+01, 2.40000e+04, 3.00000e+02,\n",
        "    4.50000e+05, 3.00000e+04, 2.70000e+04, 1.04600e+06, 5.63000e+05,\n",
        "    1.04607e+05, 5.25000e+04, 4.00000e+04, 3.02400e+04, 4.50000e+04,\n",
        "    1.90000e+05, 3.00000e+03, 8.60000e+04\n",
        "])\n",
        "\n",
        "# Determine min and max for binning\n",
        "min_value = range_values.min()\n",
        "max_value = range_values.max()\n",
        "\n",
        "# Create 10 optimized bins using log spacing (to handle large range variation)\n",
        "bins = np.logspace(np.log10(min_value), np.log10(max_value), num=11)\n",
        "\n",
        "# Display the bins\n",
        "bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-WAeCnZdbba"
      },
      "outputs": [],
      "source": [
        "# Load Drone and Sensor data\n",
        "drone_data = pd.read_csv(\"D:/NDIS_Database/rpas_nonan.csv\") # Shortlisted verison of RPAS gdb with no NaN data on distance\n",
        "sensor_data = pd.read_csv(\"D:/NDIS_Database/sensor.csv\") # Geophysical sensor list\n",
        "\n",
        "# Display the first few rows to verify\n",
        "drone_data\n",
        "sensor_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3vjs3z6dbbb"
      },
      "source": [
        "## Defining Rules for Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4utPOCm0dbbb"
      },
      "outputs": [],
      "source": [
        "sample_data = pd.read_csv(\"D:/NDIS_Database/sample_data.csv\")\n",
        "sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLU0LbyIdbbc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79RLjLlDdbbc"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "geohazard_df = ghz_celan_df.copy()\n",
        "drone_df     = drone_data.copy()\n",
        "sensor_df    = sensor_data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X23Om-GYdbbd"
      },
      "source": [
        "### Sensor Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1i6ZUSNdbbd"
      },
      "outputs": [],
      "source": [
        "# Step 1: Sensor Selection (Updated with GPR priority for Landslide)\n",
        "def select_best_sensor(hazard_type, distance):\n",
        "    if hazard_type in [1, 3, 4, 5]:  # Volcano, Tsunami, Fault, Earthquake\n",
        "        matching_sensors = sensor_df[sensor_df[\"sensor_name\"] == \"Seismic\"]\n",
        "    elif hazard_type == 2:  # Landslide (prioritize GPR)\n",
        "        matching_sensors = sensor_df[sensor_df[\"sensor_name\"] == \"GPR\"]\n",
        "        if matching_sensors.empty:  # If no GPR, fallback to Magnetometer\n",
        "            matching_sensors = sensor_df[sensor_df[\"sensor_name\"] == \"Lidar\"]\n",
        "    else:\n",
        "        return \"No suitable sensor found\"\n",
        "\n",
        "    # If multiple sensors qualify, apply additional filtering\n",
        "    if len(matching_sensors) > 1:\n",
        "        if hazard_type in [4, 5]:  # Fault, Earthquake (Underground hazards)\n",
        "            best_sensor = matching_sensors.loc[matching_sensors[\"sensor_weight\"].idxmax()]\n",
        "        elif hazard_type in [1, 3]:  # Volcano, Tsunami (Surface hazards)\n",
        "            best_sensor = matching_sensors.loc[matching_sensors[\"sensor_weight\"].idxmin()]\n",
        "        elif hazard_type == 2:  # Landslide (Check distance to prefer lighter sensors if far)\n",
        "            if distance > 200:\n",
        "                best_sensor = matching_sensors.loc[matching_sensors[\"sensor_weight\"].idxmin()]\n",
        "            else:\n",
        "                best_sensor = matching_sensors.loc[matching_sensors[\"sensor_weight\"].idxmax()]\n",
        "        else:\n",
        "            best_sensor = matching_sensors.iloc[0]\n",
        "    elif len(matching_sensors) == 1:\n",
        "        best_sensor = matching_sensors.iloc[0]\n",
        "    else:\n",
        "        return \"No suitable sensor found\"\n",
        "\n",
        "    return best_sensor[\"sensor_name\"]\n",
        "\n",
        "# Apply sensor selection to dataset\n",
        "geohazard_df[\"selected_sensor\"] = geohazard_df.apply(lambda row: select_best_sensor(row[\"HazardType\"], row[\"distance\"]), axis=1)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-RHOncgdbbe"
      },
      "outputs": [],
      "source": [
        "# Step 2: Drone Selection (Updated matching logic with ±50% tolerance & special rule for large distances)\n",
        "def select_best_drone(hazard_type, hazard_distance):\n",
        "    # Step 1: Find exact matches\n",
        "    matching_drones = drone_df[drone_df[\"distance_range\"] == hazard_distance]\n",
        "\n",
        "    # Step 2: If no exact match, find drones within ±50% of hazard distance (only if < 70,000)\n",
        "    if matching_drones.empty and hazard_distance < 70000:\n",
        "        lower_bound = hazard_distance * 0.5\n",
        "        upper_bound = hazard_distance * 1.5\n",
        "        matching_drones = drone_df[(drone_df[\"distance_range\"] >= lower_bound) & (drone_df[\"distance_range\"] <= upper_bound)]\n",
        "\n",
        "    # Step 3: For large distances (> 70,000), match with the next available `distance_range`\n",
        "    if matching_drones.empty and hazard_distance >= 70000:\n",
        "        sorted_drones = drone_df.sort_values(\"distance_range\")\n",
        "        next_distance = sorted_drones[sorted_drones[\"distance_range\"] > hazard_distance][\"distance_range\"].min()\n",
        "        matching_drones = sorted_drones[sorted_drones[\"distance_range\"] == next_distance]\n",
        "\n",
        "    # Step 4: Apply hierarchical selection if multiple drones qualify\n",
        "    if len(matching_drones) > 1:\n",
        "        if hazard_type in [1, 3]:  # Volcano, Tsunami → Min Flight Time\n",
        "            best_drone = matching_drones.loc[matching_drones[\"flight_time\"].idxmin()]\n",
        "        elif hazard_type in [2, 4, 5]:  # Landslide, Fault, Earthquake → Max Flight Time\n",
        "            best_drone = matching_drones.loc[matching_drones[\"flight_time\"].idxmax()]\n",
        "        else:\n",
        "            best_drone = matching_drones.iloc[0]\n",
        "    elif len(matching_drones) == 1:\n",
        "        best_drone = matching_drones.iloc[0]\n",
        "    else:\n",
        "        return \"No suitable drone found\"\n",
        "\n",
        "    return best_drone[\"mfc_model\"]\n",
        "\n",
        "# Apply drone selection to dataset\n",
        "geohazard_df[\"selected_drone\"] = geohazard_df.apply(lambda row: select_best_drone(row[\"HazardType\"], row[\"distance\"]), axis=1)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIKIq3HCdbbc"
      },
      "outputs": [],
      "source": [
        "# Apply the function to each row in the geohazard dataset\n",
        "sample_data[\"selected_drone\"] = sample_data.apply(lambda row: select_best_drone(row[\"HazardType\"], row[\"distance\"]), axis=1)\n",
        "\n",
        "# Display the final geohazard dataset with selected drones\n",
        "sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmnib5vUdbbf"
      },
      "source": [
        "## Model Training Independent Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W9JHkQHdbbf"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrkpY4dWdbbg"
      },
      "outputs": [],
      "source": [
        "# Prepare features (X) and target variables (y)\n",
        "X = geohazard_df[['HazardType', 'distance']].copy()  # Features for training\n",
        "y_sensor = geohazard_df['selected_sensor']  # Target variable for sensor selection\n",
        "y_drone = geohazard_df['selected_drone']  # Target variable for drone selection\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train_sensor, y_test_sensor = train_test_split(X, y_sensor, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train_drone, y_test_drone = train_test_split(X, y_drone, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifiers\n",
        "sensor_clf = DecisionTreeClassifier(random_state=42)\n",
        "sensor_clf.fit(X_train, y_train_sensor)\n",
        "\n",
        "drone_clf = DecisionTreeClassifier(random_state=42)\n",
        "drone_clf.fit(X_train, y_train_drone)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_sensor = sensor_clf.predict(X_test)\n",
        "y_pred_drone = drone_clf.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "sensor_accuracy = accuracy_score(y_test_sensor, y_pred_sensor)\n",
        "drone_accuracy = accuracy_score(y_test_drone, y_pred_drone)\n",
        "\n",
        "sensor_report = classification_report(y_test_sensor, y_pred_sensor)\n",
        "drone_report = classification_report(y_test_drone, y_pred_drone)\n",
        "\n",
        "sensor_accuracy, drone_accuracy, sensor_report, drone_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcMOVwRXdbbj"
      },
      "source": [
        "-----\n",
        "\n",
        "## Model Training Combined Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdjkILm6dbbk"
      },
      "source": [
        "### Define the Target Output and Decision Criteria (Splitting Conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2YMkKm-dbbk"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "geohazard_df = ghz_celan_df.copy() # for sample data change to sample_data for real process ghz_celan_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwJ9K8ihdbbk"
      },
      "source": [
        "### Feature Selection: Select Sensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tVip1Aidbbl"
      },
      "outputs": [],
      "source": [
        "# Step 1: Filter Drone Selection Based on Sensor Selection\n",
        "\n",
        "# Function to select the best sensor based on hazard type and distance\n",
        "def select_best_sensor_v3(hazard_type, distance):\n",
        "    if hazard_type == 2:  # Landslide\n",
        "        return \"GPR\" if distance <= 100 else \"Lidar\"\n",
        "    else:\n",
        "        return \"Seismic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa-1oUxbdbbl"
      },
      "outputs": [],
      "source": [
        "# Reapply the simplified sensor selection logic\n",
        "geohazard_df[\"selected_sensor\"] = geohazard_df.apply(lambda row: select_best_sensor_v3(row[\"HazardType\"], row[\"distance\"]), axis=1)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhCKsv4odbbm"
      },
      "source": [
        "### Define Target Output: Drone Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgNQ8TtOdbbm"
      },
      "outputs": [],
      "source": [
        "# Step 2: Drone Selection Based on Sensor Selection\n",
        "\n",
        "# Function to filter drones based on sensor selection\n",
        "def filter_drones_by_sensor(sensor_name):\n",
        "    if \"Seismic\" in sensor_name:\n",
        "        return drone_df  # All drones are assumed compatible with seismic sensors\n",
        "    elif \"GPR\" in sensor_name:\n",
        "        return drone_df[drone_df[\"max_payload_weight\"] >= 3500]  # GPR needs high payload drones\n",
        "    elif \"Lidar\" in sensor_name:\n",
        "        return drone_df[drone_df[\"max_payload_weight\"] >= 900]  # Lidar needs medium payload drones\n",
        "    else:\n",
        "        return drone_df  # Default case, no filtering\n",
        "\n",
        "# Apply filtering logic\n",
        "geohazard_df[\"filtered_drones\"] = geohazard_df[\"selected_sensor\"].apply(filter_drones_by_sensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na3cq08Hdbbm"
      },
      "source": [
        "### Function to Select Drone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceQcpnK8dbbn"
      },
      "outputs": [],
      "source": [
        "# Function to select the best drone after filtering\n",
        "def select_best_drone(hazard_type, hazard_distance, filtered_drones):\n",
        "    if filtered_drones.empty:\n",
        "        return \"No suitable drone found\"\n",
        "\n",
        "    # Step 1: Find exact matches\n",
        "    matching_drones = filtered_drones[filtered_drones[\"distance_range\"] == hazard_distance]\n",
        "\n",
        "    # Step 2: If no exact match, find drones within ±50% of hazard distance (only if < 70,000)\n",
        "    if matching_drones.empty and hazard_distance < 70000:\n",
        "        lower_bound = hazard_distance * 0.5\n",
        "        upper_bound = hazard_distance * 1.5\n",
        "        matching_drones = filtered_drones[\n",
        "            (filtered_drones[\"distance_range\"] >= lower_bound) & (filtered_drones[\"distance_range\"] <= upper_bound)]\n",
        "\n",
        "    # Step 3: For large distances (> 70,000), match with the next available `distance_range`\n",
        "    if matching_drones.empty and hazard_distance >= 70000:\n",
        "        sorted_drones = filtered_drones.sort_values(\"distance_range\")\n",
        "        next_distance = sorted_drones[sorted_drones[\"distance_range\"] > hazard_distance][\"distance_range\"].min()\n",
        "        matching_drones = sorted_drones[sorted_drones[\"distance_range\"] == next_distance]\n",
        "\n",
        "    # Step 4: Apply hierarchical selection if multiple drones qualify\n",
        "    if len(matching_drones) > 1:\n",
        "        if hazard_type in [1, 3]:  # Volcano, Tsunami → Min Flight Time\n",
        "            best_drone = matching_drones.loc[matching_drones[\"flight_time\"].idxmin()]\n",
        "        elif hazard_type in [2, 4, 5]:  # Landslide, Fault, Earthquake → Max Flight Time\n",
        "            best_drone = matching_drones.loc[matching_drones[\"flight_time\"].idxmax()]\n",
        "        else:\n",
        "            best_drone = matching_drones.iloc[0]\n",
        "    elif len(matching_drones) == 1:\n",
        "        best_drone = matching_drones.iloc[0]\n",
        "    else:\n",
        "        return \"No suitable drone found\"\n",
        "\n",
        "    return best_drone[\"mfc_model\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWzn7as1dbbn"
      },
      "outputs": [],
      "source": [
        "# Apply drone selection\n",
        "geohazard_df[\"selected_drone\"] = geohazard_df.apply(\n",
        "    lambda row: select_best_drone(row[\"HazardType\"], row[\"distance\"], row[\"filtered_drones\"]), axis=1\n",
        ")\n",
        "\n",
        "# Drop temporary 'filtered_drones' column to clean up dataset\n",
        "geohazard_df.drop(columns=[\"filtered_drones\"], inplace=True)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGApxrQ9dbbo"
      },
      "outputs": [],
      "source": [
        "# Function to select the best drone based on geohazard distance and payload capacity\n",
        "def select_best_drone_v2(hazard_distance, sensor_weight):\n",
        "    # Step 1: Find drones with exact or closest distance match\n",
        "    matching_drones = drone_df[drone_df[\"distance_range\"] >= hazard_distance]\n",
        "\n",
        "    # Step 2: If no drone exactly matches, find the next closest available distance\n",
        "    if matching_drones.empty:\n",
        "        next_distance = drone_df[drone_df[\"distance_range\"] > hazard_distance][\"distance_range\"].min()\n",
        "        matching_drones = drone_df[drone_df[\"distance_range\"] == next_distance]\n",
        "\n",
        "    # Step 3: Filter drones that can handle the sensor payload weight\n",
        "    feasible_drones = matching_drones[matching_drones[\"max_payload_weight\"] >= sensor_weight]\n",
        "\n",
        "    # Step 4: If no drones can handle the payload, pick the next closest distance-range drone with a higher weight capacity\n",
        "    if feasible_drones.empty:\n",
        "        sorted_drones = drone_df[drone_df[\"distance_range\"] > hazard_distance].sort_values(\"distance_range\")\n",
        "        for _, drone in sorted_drones.iterrows():\n",
        "            if drone[\"max_payload_weight\"] >= sensor_weight:\n",
        "                return drone[\"mfc_model\"]\n",
        "        return \"No suitable drone found\"\n",
        "\n",
        "    # Step 5: Select the best drone (lowest distance range that fits the payload)\n",
        "    best_drone = feasible_drones.iloc[0]\n",
        "\n",
        "    return best_drone[\"mfc_model\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYVIHStAdbbp"
      },
      "outputs": [],
      "source": [
        "# Apply drone selection based on refined logic\n",
        "geohazard_df[\"selected_drone\"] = geohazard_df.apply(\n",
        "    lambda row: select_best_drone_v2(row[\"distance\"], sensor_df[sensor_df[\"sensor_name\"] == row[\"selected_sensor\"]][\"sensor_weight\"].values[0] if row[\"selected_sensor\"] in sensor_df[\"sensor_name\"].values else 0),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kETvECWBdbbp"
      },
      "source": [
        "______\n",
        "# Optimized Vectorized Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06KilEIhdbbq"
      },
      "outputs": [],
      "source": [
        "# Step 1: Default all sensors to \"Seismic\"\n",
        "geohazard_df[\"selected_sensor\"] = \"Seismic\"\n",
        "\n",
        "# Step 2: Assign \"GPR\" to Landslides with distance ≤ 100m\n",
        "geohazard_df.loc[(geohazard_df[\"HazardType\"] == 2) & (geohazard_df[\"distance\"] <= 100), \"selected_sensor\"] = \"GPR\"\n",
        "\n",
        "# Step 3: Assign \"Lidar\" to Landslides with distance > 100m\n",
        "geohazard_df.loc[(geohazard_df[\"HazardType\"] == 2) & (geohazard_df[\"distance\"] > 100), \"selected_sensor\"] = \"Lidar\"\n",
        "\n",
        "# Step 4: Merge with Sensor Data to get sensor properties\n",
        "geohazard_df = geohazard_df.merge(sensor_df, left_on=\"selected_sensor\", right_on=\"sensor_name\", how=\"left\")\n",
        "\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzgui77Ndbbq"
      },
      "outputs": [],
      "source": [
        "# Step 1: Precompute sorted drone dataset\n",
        "drone_df_sorted = drone_df.sort_values([\"distance_range\", \"max_payload_weight\"])\n",
        "\n",
        "# Step 2: Optimized drone selection function\n",
        "def fast_select_drone_v2(geohazard_df, drone_df):\n",
        "    geohazard_df = geohazard_df.copy()\n",
        "    geohazard_df[\"selected_drone\"] = None\n",
        "\n",
        "    for index, row in geohazard_df.iterrows():\n",
        "        hazard_distance = row[\"distance\"]\n",
        "        sensor_weight = sensor_df.loc[sensor_df[\"sensor_name\"] == row[\"selected_sensor\"], \"sensor_weight\"].values\n",
        "        sensor_weight = sensor_weight[0] if len(sensor_weight) > 0 else 0\n",
        "\n",
        "        # Step 1: Find the first drone that can handle short distances\n",
        "        if hazard_distance < drone_df_sorted[\"distance_range\"].min():\n",
        "            matching_drones = drone_df_sorted  # Allow all drones for very short distances\n",
        "        else:\n",
        "            # Step 2: Select drones with matching or closest higher distance\n",
        "            matching_drones = drone_df_sorted[drone_df_sorted[\"distance_range\"] >= hazard_distance]\n",
        "\n",
        "        # Step 3: Filter drones that can carry the sensor payload\n",
        "        feasible_drones = matching_drones[matching_drones[\"max_payload_weight\"] >= sensor_weight]\n",
        "\n",
        "        # Step 4: If no direct match, select the **next available drone that can carry the payload**\n",
        "        if feasible_drones.empty:\n",
        "            sorted_drones = drone_df_sorted[drone_df_sorted[\"max_payload_weight\"] >= sensor_weight]\n",
        "            if not sorted_drones.empty:\n",
        "                best_drone = sorted_drones.iloc[0]\n",
        "            else:\n",
        "                best_drone = None\n",
        "        else:\n",
        "            best_drone = feasible_drones.iloc[0]\n",
        "\n",
        "        # Assign the best drone found\n",
        "        geohazard_df.at[index, \"selected_drone\"] = best_drone[\"mfc_model\"] if best_drone is not None else \"No suitable drone found\"\n",
        "\n",
        "    return geohazard_df\n",
        "\n",
        "# Apply the optimized selection\n",
        "geohazard_df = fast_select_drone_v2(geohazard_df, drone_df)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zESyk4Vbdbbr"
      },
      "outputs": [],
      "source": [
        "# Precompute sorted drone dataset\n",
        "drone_df_sorted = drone_df.sort_values([\"distance_range\", \"max_payload_weight\"])\n",
        "\n",
        "# Optimized function for drone selection\n",
        "def fast_select_drone_v3(geohazard_df, drone_df):\n",
        "    geohazard_df = geohazard_df.copy()\n",
        "    geohazard_df[\"selected_drone\"] = None\n",
        "\n",
        "    for index, row in geohazard_df.iterrows():\n",
        "        hazard_distance = row[\"distance\"]\n",
        "        sensor_weight = sensor_df.loc[sensor_df[\"sensor_name\"] == row[\"selected_sensor\"], \"sensor_weight\"].values\n",
        "        sensor_weight = sensor_weight[0] if len(sensor_weight) > 0 else 0\n",
        "\n",
        "        # Step 1: Find exact matches\n",
        "        matching_drones = drone_df_sorted[drone_df_sorted[\"distance_range\"] == hazard_distance]\n",
        "\n",
        "        # Step 2: If no exact match, find drones within ±50% of hazard distance (only if < 70,000)\n",
        "        if matching_drones.empty and hazard_distance < 70000:\n",
        "            lower_bound = hazard_distance * 0.5\n",
        "            upper_bound = hazard_distance * 1.5\n",
        "            matching_drones = drone_df_sorted[\n",
        "                (drone_df_sorted[\"distance_range\"] >= lower_bound) & (drone_df_sorted[\"distance_range\"] <= upper_bound)\n",
        "            ]\n",
        "\n",
        "        # Step 3: For large distances (> 70,000), match with the next available `distance_range`\n",
        "        if matching_drones.empty and hazard_distance >= 70000:\n",
        "            sorted_drones = drone_df_sorted.sort_values(\"distance_range\")\n",
        "            next_distance = sorted_drones[sorted_drones[\"distance_range\"] > hazard_distance][\"distance_range\"].min()\n",
        "            matching_drones = sorted_drones[sorted_drones[\"distance_range\"] == next_distance]\n",
        "\n",
        "        # Step 4: Filter drones that can handle the sensor payload weight\n",
        "        feasible_drones = matching_drones[matching_drones[\"max_payload_weight\"] >= sensor_weight]\n",
        "\n",
        "        # Step 5: If no feasible drones found, select the **next closest drone that can carry the payload**\n",
        "        if feasible_drones.empty:\n",
        "            sorted_drones = drone_df_sorted[drone_df_sorted[\"max_payload_weight\"] >= sensor_weight]\n",
        "            if not sorted_drones.empty:\n",
        "                best_drone = sorted_drones.iloc[0]\n",
        "            else:\n",
        "                best_drone = None\n",
        "        else:\n",
        "            best_drone = feasible_drones.iloc[0]\n",
        "\n",
        "        # Assign the best drone found\n",
        "        geohazard_df.at[index, \"selected_drone\"] = best_drone[\"mfc_model\"] if best_drone is not None else \"No suitable drone found\"\n",
        "\n",
        "    return geohazard_df\n",
        "\n",
        "# Apply the optimized selection\n",
        "geohazard_df = fast_select_drone_v3(geohazard_df, drone_df)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zHz3449dbbs"
      },
      "outputs": [],
      "source": [
        "# Count occurrences of \"No suitable drone found\"\n",
        "no_suitable_drones_count = (geohazard_df[\"selected_drone\"] == \"No suitable drone found\").sum()\n",
        "\n",
        "# Display the count\n",
        "print(f\"Number of geohazards with no suitable drone: {no_suitable_drones_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw977H2sdbbt"
      },
      "outputs": [],
      "source": [
        "# Calculate percentage of \"No suitable drone found\"\n",
        "no_suitable_drones_pct = (no_suitable_drones_count / len(geohazard_df)) * 100\n",
        "\n",
        "# Display the percentage\n",
        "print(f\"Percentage of geohazards without a suitable drone: {no_suitable_drones_pct:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BBjauwXdbbt"
      },
      "outputs": [],
      "source": [
        "# Filter the dataframe to show only rows where \"No suitable drone found\"\n",
        "no_suitable_drone_df = geohazard_df[geohazard_df[\"selected_drone\"] == \"No suitable drone found\"]\n",
        "no_suitable_drone_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VIHOtbLdbbu"
      },
      "outputs": [],
      "source": [
        "max(no_suitable_drone_df['distance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEgbmofZdbbv"
      },
      "outputs": [],
      "source": [
        "# Step 1: Precompute sorted drone dataset\n",
        "drone_df_sorted = drone_df.sort_values([\"distance_range\", \"max_payload_weight\"])\n",
        "\n",
        "# Step 2: Optimized drone selection function\n",
        "def fast_select_drone_v2(geohazard_df, drone_df):\n",
        "    geohazard_df = geohazard_df.copy()\n",
        "    geohazard_df[\"selected_drone\"] = None\n",
        "\n",
        "    for index, row in geohazard_df.iterrows():\n",
        "        hazard_distance = row[\"distance\"]\n",
        "        sensor_weight = sensor_df.loc[sensor_df[\"sensor_name\"] == row[\"selected_sensor\"], \"sensor_weight\"].values\n",
        "        sensor_weight = sensor_weight[0] if len(sensor_weight) > 0 else 0\n",
        "\n",
        "        # Step 1: Find the first drone that can handle short distances\n",
        "        if hazard_distance < drone_df_sorted[\"distance_range\"].min():\n",
        "            matching_drones = drone_df_sorted  # Allow all drones for very short distances\n",
        "        else:\n",
        "            # Step 2: Select drones with matching or closest higher distance\n",
        "            matching_drones = drone_df_sorted[drone_df_sorted[\"distance_range\"] >= hazard_distance]\n",
        "\n",
        "        # Step 3: Filter drones that can carry the sensor payload\n",
        "        feasible_drones = matching_drones[matching_drones[\"max_payload_weight\"] >= sensor_weight]\n",
        "\n",
        "        # Step 4: If no direct match, select the **next available drone that can carry the payload**\n",
        "        if feasible_drones.empty:\n",
        "            sorted_drones = drone_df_sorted[drone_df_sorted[\"max_payload_weight\"] >= sensor_weight]\n",
        "            if not sorted_drones.empty:\n",
        "                best_drone = sorted_drones.iloc[0]\n",
        "            else:\n",
        "                best_drone = None\n",
        "        else:\n",
        "            best_drone = feasible_drones.iloc[0]\n",
        "\n",
        "        # Assign the best drone found\n",
        "        geohazard_df.at[index, \"selected_drone\"] = best_drone[\"mfc_model\"] if best_drone is not None else \"No suitable drone found\"\n",
        "\n",
        "    return geohazard_df\n",
        "\n",
        "# Apply the optimized selection\n",
        "geohazard_df = fast_select_drone_v2(geohazard_df, drone_df)\n",
        "geohazard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR6PjfEVdbbv"
      },
      "outputs": [],
      "source": [
        "# Count occurrences of \"No suitable drone found\"\n",
        "no_suitable_drones_count = (geohazard_df[\"selected_drone\"] == \"No suitable drone found\").sum()\n",
        "\n",
        "# Display the count\n",
        "print(f\"Number of geohazards with no suitable drone: {no_suitable_drones_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC3DCtJLdbbw"
      },
      "source": [
        "____\n",
        "# Decision Tree Model Training (Combined Approach)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGFRFxxGdbbw"
      },
      "source": [
        "## Step 1: Prepare Features (X) and Target (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t37e2E91dbbw"
      },
      "outputs": [],
      "source": [
        "# Select features for model training\n",
        "X = geohazard_df[[\"HazardType\", \"distance\"]]  # Features\n",
        "y = geohazard_df[\"selected_drone\"]  # Target (drone selection)\n",
        "\n",
        "# Encode categorical target variable (drone models)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlZUXBk8dbbx"
      },
      "source": [
        "## Step 2: Train the Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHd6z0cydbbx"
      },
      "outputs": [],
      "source": [
        "# Initialize and train Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, random_state=42)\n",
        "dt_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJQAGn5edbbx"
      },
      "source": [
        "## Step 3: Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY63Yekldbby"
      },
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report with zero_division handling\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdpvLQNjdbby"
      },
      "outputs": [],
      "source": [
        "# Initialize and train Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, random_state=42)\n",
        "dt_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIlQDUuAdbby"
      },
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report with zero_division handling\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5l2Zj6qdbbz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate confusion matrix\n",
        "y_pred_final = dt_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrlhCzyVdbbz"
      },
      "outputs": [],
      "source": [
        "# Additional Fix: Ensure All Classes Are in Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TyMHWrDdbb0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy5fS3rqdbb0"
      },
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9My0OQ3zdbb0"
      },
      "source": [
        "## Step 4: (Optional) Visualize the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69cGfGAcdbb1"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "# Print decision rules\n",
        "tree_rules = export_text(dt_model, feature_names=[\"HazardType\", \"distance\"])\n",
        "print(tree_rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_U5Jjsddbb1"
      },
      "outputs": [],
      "source": [
        "# Fix 1: Increase Tree Depth to Capture More Classes\n",
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbsrJIB4dbb1"
      },
      "outputs": [],
      "source": [
        "# Get unique predicted classes\n",
        "predicted_classes = np.unique(y_pred)\n",
        "\n",
        "# Find labels that exist in test set but were never predicted\n",
        "missing_labels = set(np.unique(y_test)) - set(predicted_classes)\n",
        "print(f\"Missing predicted labels: {missing_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzMM7FWudbb3"
      },
      "outputs": [],
      "source": [
        "# Ensure all labels are included in the classification report\n",
        "print(classification_report(y_test, y_pred, labels=np.unique(y_test), target_names=label_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSMlbQNedbb3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, stratify=y_encoded, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwJ8gkB0dbb4"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=10, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "# Predict on test set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imu2obEPdbb4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate confusion matrix\n",
        "y_pred_final = dt_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXN3C_oAdbb4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(dt_model, X, y_encoded, cv=5)\n",
        "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEr2baEOdbb5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot class distribution before balancing\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=geohazard_df[\"selected_drone\"].value_counts().index,\n",
        "            y=geohazard_df[\"selected_drone\"].value_counts().values)\n",
        "plt.xticks([], [])  # Hide x-axis labels for clarity\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution Before Balancing\")\n",
        "plt.show()\n",
        "\n",
        "# Plot class distribution after balancing (e.g., after SMOTE or downsampling)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=balanced_df[\"selected_drone\"].value_counts().index,\n",
        "            y=balanced_df[\"selected_drone\"].value_counts().values)\n",
        "plt.xticks([], [])  # Hide x-axis labels for clarity\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution After Balancing\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7DDvqv9dbb5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred_final, output_dict=True)\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display classification metrics\n",
        "import ace_tools as tools\n",
        "tools.display_dataframe_to_user(name=\"Classification Report\", dataframe=df_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oot9IsjOdbb6"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=15, class_weight=\"balanced\", random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "# Predict on test set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kVPplXkdbb7"
      },
      "outputs": [],
      "source": [
        "print(geohazard_df[\"selected_drone\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alIbVwzcdbb7"
      },
      "outputs": [],
      "source": [
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=10, class_weight=\"balanced\", random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "# Predict on test set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmw0l79zdbb8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(dt_model, X, y_encoded, cv=5)\n",
        "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z8SEVcGdbb9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, class_weight=\"balanced\", random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy1yDUacdbb-"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "# Print Decision Tree structure as text\n",
        "tree_rules = export_text(dt_model, feature_names=[\"HazardType\", \"distance\"])\n",
        "print(\"Decision Tree Structure:\")\n",
        "print(tree_rules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvAub6m9dbb_"
      },
      "source": [
        "-----\n",
        "### ----- Fix Issues -----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXqJECdGdbb_"
      },
      "source": [
        "### Step 1: Downsample dominant drones to balance the dataset size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Ch8ZuMdbb_"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvy_Avw3dbcA"
      },
      "outputs": [],
      "source": [
        "# Find the max count for the smallest class\n",
        "min_class_count = geohazard_df[\"selected_drone\"].value_counts().min()\n",
        "\n",
        "# Downsample majority classes\n",
        "balanced_df = geohazard_df.groupby(\"selected_drone\", group_keys=False).apply(lambda x: x.sample(min_class_count, random_state=42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MitK52tJdbcA"
      },
      "outputs": [],
      "source": [
        "# Use SMOTE\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OJ2FTYCdbcA"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ncj3asdbcB"
      },
      "outputs": [],
      "source": [
        "# Train the data Again\n",
        "dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=10, class_weight=\"balanced\", random_state=42)\n",
        "dt_model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_balanced = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ArcGISPro",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}